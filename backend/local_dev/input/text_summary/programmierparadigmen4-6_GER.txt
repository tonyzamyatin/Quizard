4 Dynamische Typinformation und
statische Parametrisierung
Statisch typisierte prozedurale und funktionale Sprachen unterscheiden streng
zwischen Typinformationen, die nur dem Compiler zum Zeitpunkt der Übersetzung zur Verfügung stehen und dynamischen Daten, die während der Programmausführung verwendet werden. Es gibt in diesen Sprachen keine dynamische Typinformation. Im Gegensatz dazu wird in objektorientierten Programmiersprachen dynamische Typinformation (ähnlich wie sie auch in dynamisch
typisierten prozeduralen und funktionalen Sprachen existiert) für das dynamische Binden zur Ausführungszeit benötigt. Viele objektorientierte Sprachen
erlauben den direkten Zugriff darauf. In Java gibt es zur Laufzeit Möglichkeiten, die Klasse eines Objekts direkt zu erfragen, zu überprüfen, ob ein Objekt
Instanz eines bestimmten Typs ist, sowie zur überprüften Umwandlung des
deklarierten Typs. Wir wollen in diesem Kapitel den Umgang mit dynamischer Typinformation untersuchen. Wir behandeln auch statische Formen der
Parametrisierung von Modularisierungseinheiten, gleich zu Beginn Generizität,
gegen Ende des Kapitels Annotationen und aspektorientierte Programmierung.
Oberflächlich betrachtet scheint es keinerlei Gemeinsamkeiten zwischen diesen
Themenbereichen zu geben. Tatsächlich bestehen, insbesondere in Java, starke
Verbindungen dazwischen.
4.1 Generizität
Generische Klassen, Typen und Methoden enthalten Parameter, für die Typen
eingesetzt werden. Andere Arten generischer Parameter unterstützt Java nicht.
Daher nennen wir generische Parameter einfach Typparameter.
Generizität ist ein statischer Mechanismus, der von Java erst ab Version 1.5
unterstützt wird. Dynamisches Binden wie bei Untertypen ist nicht nötig. Dieses
wichtige Unterscheidungsmerkmal zu Untertypen verspricht einen effizienten
Einsatz in vielen Bereichen, schränkt uns beim Programmieren aber manchmal
auch auf unerwartete Weise ein.
4.1.1 Wozu Generizität?
An Stelle expliziter Typen werden im Programm Typparameter verwendet. Das
sind einfach nur Namen, die später konzeptuell (oft nur scheinbar) durch Typen
ersetzt werden. Anhand eines Beispiels wollen wir zeigen, dass eine Verwendung
von Typparametern und die spätere Ersetzung durch Typen sinnvoll ist:
175
4 Dynamische Typinformation und statische Parametrisierung
Beispiel: Wir entwickeln Programmcode für Listen von Zeichenketten. Bald stellt sich heraus, dass wir auch Listen mit Elementen
vom Typ Integer brauchen. Da der existierende Code auf Zeichenketten eingeschränkt ist, müssen wir eine neue Variante schreiben.
Untertypen und Vererbung sind dabei wegen der Unterschiedlichkeit
der Typen nicht hilfreich. Aber Typparameter können helfen: Statt
für String schreiben wir den Code für Element. Dabei ist Element
kein existierender Typ, sondern ein Typparameter. Den Code für
String- und Integer-Listen könnten wir daraus erzeugen, indem
wir alle Vorkommen von Element durch diese Typnamen ersetzen.
Auf den ersten Blick schaut es so aus, als ob wir den gleichen Effekt auch erzielen könnten, wenn wir im ursprünglichen String-Listencode alle Vorkommen
von String durch Integer ersetzen würden. Leider gibt es dabei ein Problem:
Der Name String kann auch für ganz andere Zwecke eingesetzt sein, beispielsweise als Ergebnistyp der Methode toString(). Eine Ersetzung würde alle
Vorkommen von String ersetzen, auch solche, die gar nichts mit Elementtypen
zu tun haben. Daher wählen wir einen neutralen Namen wie Element, der im
Code in keiner anderen Bedeutung vorkommt. Ein Programmstück kann auch
mehrere Typparameter unterschiedlicher Bedeutungen enthalten.
Natürlich spart es Schreibaufwand, wenn wir eine Kopie eines Programmstücks anfertigt und darin alle Vorkommen eines Typparameters mit Hilfe eines
Texteditors durch einen Typ ersetzen. Aber dieser einfache Ansatz bereitet
Probleme bei der Wartung: Nötige Änderungen des kopierten Programmstücks
müssen in allen Kopien gemacht werden, was einen erheblichen Aufwand verursacht. Leichter geht es, wenn das Programmstück nur einmal existiert: Wir
schreiben das Programmstück einmal und kennzeichnen Typparameter als solche. Statt einer Kopie verwenden wir nur den Namen des Programmstücks
zusammen mit den Typen, die an Stelle der Typparameter zu verwenden sind.
Erst der Compiler erzeugt nötige Kopien oder verwendet eine andere Technik
mit ähnlichen Auswirkungen. Änderungen sind nach dem nächsten Übersetzungsvorgang überall sichtbar, wo das Programmstück verwendet wird.
In Java erzeugt der Compiler keine Kopien der Programmstücke, sondern
kann durch Typumwandlungen (Casts) den gleichen Code für mehrere Zwecke
– etwa Listen mit Elementen unterschiedlicher Typen – verwenden; daher hängt
Generizität (als rein statischer Mechanismus) mit dynamischer Typinformation
zusammen. Generizität erspart damit nicht nur Schreibarbeit, sondern kann das
übersetzte Programm auch kürzer und überschaubarer machen.
4.1.2 Einfache Generizität in Java
Generische Klassen und Interfaces haben ein oder mehrere Typparameter, die
in spitzen Klammern, durch Beistriche voneinander getrennt, deklariert sind.
Innerhalb der Klassen und Interfaces sind diese Typparameter beinahe wie normale Referenztypen verwendbar. Das erste Beispiel in Java verwendet zwei generische Interfaces mit je einem Typparameter A:
176
4.1 Generizität
public interface Collection<A> {
void add(A elem); // add elem to collection
Iterator<A> iterator(); // create new iterator
}
public interface Iterator<A> {
A next(); // get the next element
boolean hasNext(); // further elements?
}
Mit diesen Definitionen ist Collection<String> ein Interface, das durch Ersetzung aller Vorkommen des Typparameters A im Rumpf von Collection<A>
generiert wird. So enthält Collection<String> die entsprechenden generierten
Methoden void add(String elem) und Iterator<String> iterator(), wobei Iterator<String> die Methoden String next() und boolean hasNext()
enthält. Der Typparameter kann durch Referenztypen ersetzt werden, aber
nicht durch elementare Typen wie int, char oder boolean.
Hier ist eine Implementierung von Collection<A> als generische Liste:
public class List<A> implements Collection<A> {
private Node<A> head = null, tail = null;
public void add(A elem) {
if (head == null) tail = head = new Node<A>(elem);
else tail.setNext(tail = new Node<A>(elem));
}
private class ListIter implements Iterator<A> {
private Node<A> p = head;
public boolean hasNext() { return p != null; }
public A next() {
if (p == null)
throw new java.util.NoSuchElementException();
A elem = p.elem();
p = p.next();
return elem;
}
}
public Iterator<A> iterator() { return new ListIter(); }
}
class Node<T> {
private T elem;
private Node<T> next = null;
public Node(T elem) { this.elem = elem; }
public T elem() { return elem; }
public Node<T> next() { return next; }
public void setNext(Node<T> next) { this.next = next; }
}
Die generische Klasse List<A> verwendet die Hilfsklasse Node<T> für Listenknoten und enthält die innere Klasse ListIter als Iterator-Implementierung.
177
4 Dynamische Typinformation und statische Parametrisierung
Der Typparameter A der Liste ist auch in der inneren Klasse sichtbar und
wie der Name eines Typs verwendbar. Da für die Listenknoten keine geschachtelte Klasse verwendet wird, ist dafür ein eigener Typparameter nötig. Wir
könnten dafür ebenso A verwenden, aber auch jeden beliebigen anderen Namen. Wir verwenden T, um die Gültigkeitsbereiche sichtbar zu machen. Durch
interface Collection<A> wird der Typparameter A eingeführt, der innerhalb dieses Interfaces sichtbar ist. Durch interface Iterator<A> wird ein
anderer Typparameter (der auch A heißt) eingeführt, der nur innerhalb des
anderen Interfaces sichtbar ist. Ebenso wird durch class List<A> ein weiterer Typparameter namens A eingeführt, der bis zum Ende der Klasse sichtbar ist. Durch Node<T> wird der Typparameter T eingeführt. An allen anderen Stellen im Beispiel, an denen A oder T vorkommt, werden keine Typparameter eingeführt, sondern zuvor eingeführte Typparameter verwendet. In
implements Collection<A> sowie in der Variablendeklaration Node<A> head
wird der durch class List<A> eingeführte Typparameter verwendet. Wenn wir
irgendwo im Programm den Typ List<String> verwenden (wodurch der mit
List eingeführte Typparameter durch String ersetzt wird), dann implementiert List<String> das Interface Collection<String> und hat die Variable
head vom Typ Node<String>, also auch T wird durch String ersetzt. Mit dem
Wort „ersetzt“ ist dabei eine Form der Parameterübergabe gemeint (String
als Argument, A oder T als Parameter), genau so wie im λ-Kalkül die Parameterübergabe durch Ersetzung erfolgt. Wir machen nichts falsch, wenn wir das
Ersetzen einfach umgangssprachlich verstehen und uns nicht weiter um eine
formale Definition kümmern.
Konstruktoren haben wie in Node<T> die üblich Syntax Node(...){...};
es werden keine Typparameter angegeben. Bei der Objekterzeugung müssen
aber Typen angegeben werden, die die Typparameter der Klasse ersetzen, etwa
new Node<A>(...); dabei ist A der Typ der Listenelemente.
Folgendes Programmstück zeigt den Umgang mit generischen Klassen:
class ListTest {
public static void main(String[] args) {
List<Integer> xs = new List<Integer>();
xs.add(new Integer(0)); // oder xs.add(0);
Integer x = xs.iterator().next();
List<String> ys = new List<String>();
ys.add("zerro");
String y = ys.iterator().next();
List<List<Integer>> zs = new List<List<Integer>>();
zs.add(xs);
// zs.add(ys); !! Compiler meldet Fehler !!
List<Integer> z = zs.iterator().next();
}
}
178
4.1 Generizität
An ListTest fällt auf, dass statt einfacher Werte von int Objekte der Standardklasse Integer verwendet werden müssen, da gewöhnliche Zahlen keine
Referenzobjekte sind. In Java gibt es zu jedem elementaren Typ wie int, char
oder boolean einen Referenztyp wie Integer, Character oder Boolean, weil
in einigen Sprachkonstrukten nur Referenztypen erlaubt sind. Sie bieten die
gleiche Funktionalität wie elementare Typen. Ein Nachteil ist der im Vergleich
zu elementaren Werten weniger effiziente Umgang mit Objekten.
Java unterstützt Autoboxing und Autounboxing. Dabei erfolgt die Umwandlung zwischen Typen wie int und Integer bei Bedarf automatisch in beide
Richtungen. Statt xs.add(new Integer(0)) schreiben wir einfach xs.add(0).
Die automatische Umwandlung verringert nur den Schreibaufwand, nicht die
dadurch bedingte Ineffizienz zur Laufzeit.1
Das Beispiel zeigt, dass Listen auch andere Listen enthalten können. Jedoch
muss jedes Listenelement den durch den Typparameter festgelegten Typ haben. Der Compiler ist klug genug, um List<Integer> von List<String> zu
unterscheiden. Diese beiden Listentypen sind nicht kompatibel zueinander.
Generizität bietet statische Typsicherheit. Bereits der Compiler garantiert,
dass in ein Objekt von List<String> nur Zeichenketten eingefügt werden können. Der Versuch, ein Objekt eines inkompatiblen Typs einzufügen, wird als
Fehler gemeldet. Wer den Umgang mit Collections und Ähnlichem ohne Generizität gewohnt ist, kennt die Probleme mangelnder statischer Typsicherheit, bei
der Typfehler als Typkonvertierungsfehler zur Laufzeit auftreten. Generizität
sorgt dafür, dass solche Typfehler schon zur Übersetzungszeit erkannt werden.
Auch Methoden können generisch sein, wie das nächste Beispiel zeigt:
public interface Comparator<A> {
int compare(A x, A y); // x < y if result < 0
// x == y if result == 0
// x > y if result > 0
}
public class CollectionOps {
public static <A> A max(Collection<A> xs, Comparator<A> c) {
Iterator<A> xi = xs.iterator();
A w = xi.next();
while (xi.hasNext()) {
A x = xi.next();
if (c.compare(w, x) < 0)
w = x;
}
return w;
}
}
1Es stimmt nicht, dass Autoboxing in jedem Fall ein neues Objekt erzeugt. Für häufig verwendete Zahlen in der Nähe von 0 stellt das Java-Laufzeitsystem schon vorher erzeugte
Objekte bereit, die direkt übergeben werden. Das bedeutet jedoch, dass wir uns bei Autoboxing nicht auf die Objektidentität verlassen dürfen.
179
4 Dynamische Typinformation und statische Parametrisierung
Die Methode compare in Comparator<A> vergleicht zwei Objekte des gleichen
Typs und retourniert das Vergleichsergebnis als ganze Zahl. Unterschiedliche
Komparatoren, also voneinander verschiedene Objekte mit einem solchen Interface, werden unterschiedliche Vergleiche durchführen. Die statische Methode
max in CollectionOps wendet Komparatoren wiederholt auf Elemente in einem
Objekt von Collection<A> an, um das größte Element zu ermitteln. Am vor
dem Ergebnistyp von max eingefügten Ausdruck <A> ist erkennbar, dass max
eine generische Methode mit einem Typparameter A ist. Dieser Typparameter
kommt sowohl als Ergebnistyp als auch in der Parameterliste und im Rumpf der
Methode vor. In den spitzen Klammern können auch mehrere, durch Komma
voneinander getrennte Typparameter deklariert sein.
Generische Methoden haben den Vorteil, dass die für Typparameter zu verwendenden Typen nicht explizit angeben sein müssen:
List<Integer> xs = ...;
List<String> ys = ...;
Comparator<Integer> cx = ...;
Comparator<String> cy = ...;
Integer rx = CollectionOps.max(xs, cx);
String ry = CollectionOps.max(ys, cy);
// Integer rz = CollectionOps.max(xs, cy); !Fehler!
Der Compiler erkennt durch Typinferenz anhand der Typdeklarationen von xs
und cx beziehungsweise ys und cy, dass beim ersten Aufruf von max für den
Typparameter Integer und für den zweiten Aufruf String zu verwenden ist.
Außerdem erkennt der Compiler statisch, wenn der Typparameter von List
nicht mit dem von Comparator übereinstimmt.
Hier ist ein Beispiel für die Implementierung eines einfachen Komparators:
class IntComparator implements Comparator<Integer> {
public int compare(Integer x, Integer y) {
return x.intValue() - y.intValue();
}
}
Aufgrund von Autounboxing kann die dritte Zeile auch einfach durch die Anweisung return x - y; ersetzt werden. Ein Komparator für Zeichenketten wird
zwar etwas komplizierter, aber nach dem gleichen Schema aufgebaut sein.
4.1.3 Gebundene Generizität in Java
Die einfache Form der Generizität ist zwar elegant und sicher, aber für einige
Verwendungszwecke nicht ausreichend: Im Rumpf einer einfachen generischen
Klasse oder Methode ist über den Typ, der den Typparameter ersetzt, nichts
bekannt. Insbesondere ist nicht bekannt, ob Objekte dieses Typs bestimmte
Methoden oder Variablen haben.
180
4.1 Generizität
Schranken. Über manche Typparameter benötigen wir mehr Information, um
auf Objekte der entsprechenden Typen zugreifen zu können. Gebundene Typparameter liefern diese Information: In Java kann für jeden Typparameter eine
Klasse und beliebig viele Interfaces als Schranken angegeben werden. Nur Untertypen der Schranken dürfen den Typparameter ersetzen. Damit ist statisch
bekannt, dass in jedem Objekt des Typs, für den der Typparameter steht, die in
den Schranken festgelegten öffentlich sichtbaren Methoden und Variablen verwendbar sind. Objekte des Typparameters können wie Objekte der Schranken
(jede Schranke ist ein Typ der Objekte) verwendet werden:
public interface Scalable {
void scale(double factor);
}
public class Scene<T extends Scalable> implements Iterable<T> {
public void addSceneElement(T e) { ... }
public Iterator<T> iterator() { ... }
public void scaleAll(double factor) {
for (T e : this)
e.scale(factor);
}
...
}
Die Klasse Scene hat einen Typparameter T mit einer Schranke. Jeder Typ, der
T ersetzt, ist Untertyp von Scalable und unterstützt damit die Methode scale.
Diese Methode wird in scaleAll aufgerufen (für jedes Element des aktuellen
Objekts von Scene).
Schranken stehen nach dem Schlüsselwort extends innerhalb der spitzen
Klammern. Das Schlüsselwort dafür ist immer extends, niemals implements.
Pro Typparameter sind als Schranken eine Klasse sowie beliebig viele Interfaces erlaubt, jeweils durch & voneinander getrennt. Nur solche Typen dürfen den
Typparameter ersetzen, die alle diese Interfaces erweitern bzw. implementieren.
Ist ein Typparameter ungebunden, das heißt, ist keine Schranke angegeben,
wird Object als Schranke angenommen, da jede Klasse von Object abgeleitet
ist. Die in Object definierten Methoden sind daher immer verwendbar.
In obigem Beispiel erweitert Scene das in den Java-Bibliotheken vordefinierte
Interface Iterable<T>, welches die Methode iterator zur Erzeugung eines
Iterators beschreibt. In Scene wird der Iterator benötigt, um einfach mittels
for-Schleife über alle Elemente des aktuellen Objekts von Scene zu iterieren.
Rekursion. Diese Beispiels-Variante verwendet Typparameter rekursiv:
public interface Comparable<A> {
int compareTo(A that); // this < that if result < 0
// this == that if result == 0
// this > that if result > 0
}
181
4 Dynamische Typinformation und statische Parametrisierung
public class Integer implements Comparable<Integer> {
private int value;
public Integer(int value) { this.value = value; }
public int intValue() { return value; }
public int compareTo(Integer that) {
return this.value - that.value;
}
}
public class CollectionOps2 {
public static <A extends Comparable<A>>
A max(Collection<A> xs) {
Iterator<A> xi = xs.iterator();
A w = xi.next();
while (xi.hasNext()) {
A x = xi.next();
if (w.compareTo(x) < 0)
w = x;
}
return w;
}
}
Diese Klasse Integer ist eine vereinfachte Form der in Java standardmäßig
vorhandenen gleichnamigen Klasse. Integer wird von Comparable<Integer>
abgeleitet. Der Name der Klasse kommt in der Schnittstelle vor, von der abgeleitet wird. Auf den ersten Blick mag eine derartige rekursive Verwendung
von Klassennamen eigenartig erscheinen, sie ist aber klar definiert, einfach verständlich und in der Praxis sinnvoll. In der Schranke des Typparameters A von
max in CollectionOps2 kommt eine ähnliche Rekursion vor. Damit wird eine
Ableitungsstruktur wie die von Integer beschrieben. Diese Form der Generizität mit rekursiven Typparametern nennen wir F-gebundene Generizität nach
dem formalen Modell, in dem solche Konzepte untersucht wurden: System F≤,
ausgesprochen „F-bound“ [7].
Keine impliziten Untertypen. Generizität unterstützt keine impliziten Untertypbeziehungen. So besteht zwischen List<X> und List<Y> keine Untertypbeziehung wenn X und Y verschieden sind, auch dann nicht, wenn Y Untertyp
von X ist oder umgekehrt. Natürlich gibt es die expliziten Untertypbeziehungen, wie beispielsweise die zwischen Integer und Comparable<Integer>. Wir
können Klassen wie üblich ableiten:
class MyList<A> extends List<List<A>> { ... }
Dann ist MyList<String> ein Untertyp von List<List<String>>. Jedoch ist
MyList<X> kein Untertyp von List<Y> wenn Y möglicherweise ungleich List<X>
ist. Die Annahme impliziter Untertypbeziehungen ist ein häufiger Anfängerfehler. Wir müssen stets bedenken, dass es weder in Java noch in irgendeiner
anderen Sprache sichere implizite Untertypbeziehungen dieser Art geben kann.
182
4.1 Generizität
In Java können bei Verwendung von Arrays Typfehler zur Laufzeit auftreten,
da Arrays implizite Untertypbeziehungen unterstützen:
class Loophole {
public static String loophole(Integer y) {
String[] xs = new String[10];
Object[] ys = xs; // no compile-time error
ys[0] = y; // throws ArrayStoreException
return xs[0];
}
}
Diese Klasse wird unbeanstandet übersetzt, da in Java für jede Untertypbeziehung auf Typen automatisch eine Untertypbeziehung auf Arrays von Elementen
solcher Typen angenommen wird, obwohl Ersetzbarkeit verletzt sein kann. Im
Beispiel nimmt der Compiler an, dass String[] Untertyp von Object[] ist,
da String ein Untertyp von Object ist. Diese Annahme ist falsch. Generizität
schließt solche Fehler durch das Verbot impliziter Untertypbeziehungen aus:
class NoLoophole {
public static String loophole(Integer y) {
List<String> xs = new List<String>();
List<Object> ys = xs; // compile-time error
ys.add(y);
return xs.iterator().next();
}
}
Wildcards. Die Sicherheit durch Nichtunterstützung impliziter Untertypbeziehungen hat auch einen Nachteil. Zum Beispiel kann die Methode
void drawAll(List<Polygon> p) {
... // draws all polygons in list p
}
nur mit Argumenten vom Typ List<Polygon> aufgerufen werden, nicht aber
mit Argumenten vom Typ List<Triangle> oder List<Square> (entsprechend
dem Beispiel aus Abschnitt 3.2.3). Dies ist bedauerlich, da drawAll nur Elemente aus der Liste liest und nie in die Liste schreibt, Sicherheitsprobleme
durch implizite Untertypbeziehungen wie bei Arrays aber beim Schreiben auftreten. Für solche Fälle unterstützt Java gebundene Wildcards als Typen, die
Typparameter ersetzen:
void drawAll(List<? extends Polygon> p) { ... }
Das Fragezeichen steht für einen beliebigen Typ, der ein Untertyp von Polygon
ist. Nun können wir drawAll auch mit Argumenten vom Typ List<Triangle>
und List<Square> aufrufen. Der Compiler liefert eine Fehlermeldung, wenn
183
4 Dynamische Typinformation und statische Parametrisierung
die Möglichkeit besteht, dass in den Parameter p geschrieben wird. Genauer
gesagt erlaubt der Compiler die Verwendung von p nur an Stellen, für deren
Typen in Untertypbeziehungen Kovarianz gefordert ist (Lesezugriffe, siehe Abschnitt 3.1.1). Durch diese Überprüfung ist die zweite Variante von drawAll
genau so sicher wie die erste.
Gelegentlich gibt es auch Parameter, deren Inhalte in einer Methode nur
geschrieben und nicht gelesen werden:
void addSquares(List<? extends Square> from,
List<? super Square> to ) {
... // add squares from ’from’ to ’to’
}
In to wird nur geschrieben, von to wird nicht gelesen. Als Argument für to
können wir daher List<Square>, aber auch List<Polygon> und List<Object>
angeben. Als Schranke spezifiziert das Schlüsselwort super, dass jeder Obertyp
von Square erlaubt ist. Der Compiler erlaubt die Verwendung von to nur an
Stellen, für deren Typen in Untertypbeziehungen Kontravarianz gefordert ist;
das sind Schreibzugriffe.
Nebenbei sei erwähnt, dass auch nur ? als Wildcard verwendbar ist. Entsprechende Variablen und Parameter unterstützen nur das Lesen, aber gelesene Werte haben einen unbekannten Typ; <?> entspricht somit <? extends Object>.
Flexibilität durch Wildcards. In der Praxis kann die Verwendung solcher
Wildcards recht kompliziert werden, wie folgendes Beispiel zeigt:
public class MaxList<A extends Comparable<? super A>>
extends List<A> {
public A max() {
Iterator<A> i = this.iterator();
A w = i.next();
while (i.hasNext()) {
A x = i.next();
if (w.compareTo(x) < 0)
w = x;
}
return w;
}
}
Eine Schranke A extends Comparable<A> scheint auf den ersten Blick klarer
auszudrücken, dass auf den Listenelementen compareTo benötigt wird. Aber
mit der einfacheren Lösung haben wir ein Problem: Wir könnten einen Typ
MaxList<X> zwar verwenden wenn X das Interface Comparable<X> implementiert, aber für einen von X abgeleiteten Typ Y wäre MaxList<Y> nicht erlaubt, da Y nur Comparable<X> implementiert, nicht Comparable<Y>. Ein Interface darf nicht mehrfach auf unterschiedliche Weise implementiert sein, sodass Y nicht sowohl Comparable<X> als auch Comparable<Y> implementieren
184
4.2 Verwendung von Generizität
kann. Doch <A extends Comparable<? super A> erlaubt die Verwendung von
MaxList<Y>: Es reicht, wenn Y nur Comparable<X> implementiert, da X Obertyp von Y ist und ? für einen Obertyp von A steht.
Die Methode compareTo aus Comparable greift nur lesend auf ihr Argument
zu. Für lesende Zugriffe verwenden wir jedoch meist extends-Wildcards, nicht
wie im Beispiel ein super-Wildcard auf Comparable. Für diese Diskrepanz gibt
es eine Erklärung: Entscheidend sind kovariante bzw. kontravariante Parameterpositionen. Die Richtung (ko- und kontravariant) dreht sich mit jeder Klammerebene um. Das heißt, in einem Wildcard in den äußersten spitzen Klammern stimmt „lesend“ mit „kovariant“ und „schreibend“ mit „kontravariant“
überein, innerhalb von zwei spitzen Klammern „lesend“ mit „kontravariant“
und „schreibend“ mit „kovariant“, innerhalb von drei spitzen Klammern wieder so wie in den äußersten Klammern und so weiter. Als Menschen können wir
nach komplizierten Überlegungen zwar nachvollziehen, wie die Richtung mit
den Klammerebenen zusammenhängt, aber intuitiv ist das nicht. Maschinen
können damit problemloser umgehen. Am besten verlassen wir uns dabei auf
den Compiler, der zuverlässig warnt, wenn wir einen falschen Wildcard verwenden, vorausgesetzt Warnungen für Generizität sind eingeschaltet.
Einschränkungen in Java. Generizität wurde mit minimalen Änderungen der
Sprache zum ursprünglich nicht generischen Java hinzugefügt. Auf Grund von
Kompatibilitätsbedingungen mussten Kompromisse gemacht werden, die die
Verwendbarkeit von Generizität einschränken. Generell, also in anderen Sprachen als Java (und C#), treten beispielsweise keine Unterschiede in der Typsicherheit von Arrays und generischen Collections auf. Im Gegenteil: Der einfache
und sichere Umgang mit Arrays ist ein Grund für die Einführung von Generizität. Als weitere Einschränkung in Java können Typparameter nicht zur Erzeugung neuer Objekte verwendet werden. Daher ist new A() illegal wenn A
ein Typparameter ist. In der Praxis interessanter ist der Ausdruck new A[n],
der ein neues Array für n Objekte von A erzeugt. Dieser Ausdruck ist leider
nicht typsicher wenn A ein Typparameter ist; der Compiler meldet einen Fehler.
Weitere Einschränkungen der Generizität in Java gibt es bei expliziten Typumwandlungen und dynamischen Typvergleichen, wie wir später sehen werden.
Zwecks Kompatibilität zu älteren Java-Versionen werden zur Laufzeit Typprüfungen durchgeführt, obwohl der Compiler Typkonsistenz garantiert. Daher
bedingt Generizität (sehr kleine) Einbußen an Laufzeiteffizienz. In anderen Programmiersprachen hat Generizität keinen negativen Einfluss auf die Laufzeit.
4.2 Verwendung von Generizität
Wir wollen nun betrachten, wie Generizität in der Praxis einsetzbar ist. Abschnitt 4.2.1 gibt einige allgemeine Ratschläge, in welchen Fällen sich die Verwendung auszahlt. In Abschnitt 4.2.2 beschäftigen wir uns mit möglichen Übersetzungen generischer Klassen und einigen Alternativen zur Generizität, um ein
etwas umfassenderes Bild davon zu bekommen, was Generizität leisten kann.
185
4 Dynamische Typinformation und statische Parametrisierung
4.2.1 Richtlinien für die Verwendung von Generizität
Generizität ist immer sinnvoll, wenn sie die Wartbarkeit verbessert. Aber oft
ist nur schwer entscheidbar, ob diese Voraussetzung zutrifft. Wir wollen hier
einige typische Situationen als Entscheidungshilfen bzw. Faustregeln anführen:
Gleich strukturierte Klassen und Methoden. Wir sollen Generizität immer
verwenden, wenn es mehrere gleich strukturierte Klassen (oder Typen) beziehungsweise Methoden gibt. Typische Beispiele dafür sind Containerklassen wie
Listen, Stacks, Hashtabellen, Mengen, etc. und Methoden, die auf Containerklassen zugreifen, etwa Suchfunktionen und Sortierfunktionen. Alle bisher in
diesem Kapitel verwendeten Klassen und Methoden fallen in diese Kategorie.
Wenn es eine Containerklasse für Elemente eines bestimmten Typs gibt, liegt
immer der Verdacht nahe, dass genau dieselbe Containerklasse auch für Objekte
anderer Typen sinnvoll sein könnte. Falls die Typen der Elemente in der Containerklasse gleich von Anfang an als Typparameter spezifiziert sind, ist es später
leicht, die Klasse unverändert mit Elementen anderer Typen zu verwenden.
Faustregel: Containerklassen sollen generisch sein.
Es zahlt sich aus, Generizität bereits beim ersten Verdacht, dass eine Containerklasse auch für andere Elementtypen sinnvoll sein könnte, zu verwenden.
Beim Erstellen der Klasse ist es leicht, zwischen Elementtypen und anderen Typen zu unterscheiden. Im Nachhinein, also wenn eine nichtgenerische Klasse in
eine generische umgewandelt werden soll, ist diese Unterscheidung nicht immer
so einfach. Generizität kann die Lesbarkeit in komplexen Fällen beeinträchtigen,
zahlt sich aber trotzdem aus.
Wenn wir die Sinnhaftigkeit von Typparametern erst später erkennen, sollen
wir das Programm gleich refaktorisieren, also mit Typparametern versehen. Ein
Hinauszögern der Refaktorisierung führt leicht zu unnötigem Code.
Üblicher Programmcode definiert relativ wenige generische Containerklassen.
Das liegt daran, dass Programmierumgebungen mit umfangreichen Bibliotheken ausgestattet sind, welche die am häufigsten verwendeten, immer wieder
gleich strukturierten Klassen und Methoden bereits enthalten. Wir müssen diese Klassen und Methoden nicht neu schreiben.
Faustregel: Klassen und Methoden in Bibliotheken sind generisch.
In aktuellen Java-Versionen sind die Standardbibliotheken durchwegs generisch.
Generizität ist in Java so gestaltet, dass der Umstieg auf Generizität möglichst leicht ist. Übersetzte generische Klassen können auch in älteren, nichtgenerischen Java-Versionen verwendet werden, und generisches Java kann mit
nicht-generischen Klassen umgehen.
Erkennen gleicher Strukturen. Beispielsweise schreiben wir eine Klasse, die
Konten an einem Bankinstitut repräsentiert. Konten können für unterschiedliche Währungen ausgelegt sein. In der Regel werden wir einen Typ Currency
186
4.2 Verwendung von Generizität
einführen und für jede konkrete Währung wie Euro und US-Dollar einen Untertyp davon. Rechtliche Bedingungen für unterschiedliche Währungen werden sich
wahrscheinlich so stark voneinander unterscheiden, dass wir für jede Währung
tatsächlich einen eigenen Typ mit etwas unterschiedlichem Verhalten brauchen.
Im Konto haben wir eine Variable, die ein Objekt des entsprechenden Währungstyps enthält. So weit können wir unsere Konto-Klasse sehr gut mittels
Untertypbeziehungen ohne Generizität darstellen. Jetzt ergibt sich aber das
Problem, dass wir in der Kontoklasse vielleicht mehrere Variablen mit Objekten von Währungstypen benötigen, von denen einige den gleichen Währungstyp haben müssen. Es stellt sich rasch heraus, dass das über Untertypbeziehungen nicht oder nur sehr umständlich darstellbar ist, etwa weil sich automatisch die Notwendigkeit kovarianter Eingangsparameter ergibt (kovariantes
Problem). Subtyping ist dafür einfach nicht der richtige Ansatz. Mittels Generizität lässt sich diese Problematik relativ einfach in den Griff bekommen.
Wir müssen nur für jede Art von Variable, die den gleichen Währungstyp haben muss, einen Typparameter anlegen. Diese Typparameter werden jeweils
Currency als Schranke haben und können durch (möglicherweise unterschiedliche) Untertypen von Currency ersetzt werden. Trotzdem sind die notwendigen
Konsistenzbedingungen zwischen den Variablen garantiert.
Ein Konto ist auch eine Art von Container. Es geht darum, dass dies nicht
von vornherein sichtbar sein muss. Wir müssen unsere Augen dafür offen halten, wo sich Situationen ergeben, die so wie in einem Container handhabbar
sind. Die Form der Beschreibung eines Typs macht es manchmal schwer, die
Container-Eigenschaft zu erkennen. Ein deutlicher Hinweis darauf besteht darin, dass mehrere Variablen Inhalte nicht von vorne herein klar festgelegter, aber
dennoch gleicher Typen enthalten.
Faustregel: Generizität (oft gebundene Generizität) ist immer dort
sinnvoll, wo mehrere Variablen vom gleichen (aber nicht von Anfang
an fix festgelegten) Typ notwendig sind.
Abfangen erwarteter Änderungen. Mittels Generizität können wir erwartete Programmänderungen vereinfachen. Das gilt auch für Typen von formalen
Parametern, die sich entsprechend dem Ersetzbarkeitsprinzip nicht beliebig ändern dürfen. Wir sollen Typparameter für die Typen formaler Parameter verwenden, wenn wir erwarten, dass sich diese Typen im Laufe der Zeit ändern.
Es brauchen nicht gleichzeitig mehrere gleich strukturierte Klassen oder Methoden sinnvoll sein, sondern es reicht, wenn zu erwarten ist, dass sich Typen
in unterschiedlichen Versionen voneinander unterscheiden.
Faustregel: Wir sollen Typparameter als Typen formaler Parameter
verwenden, wenn Änderungen der Parametertypen absehbar sind.
Wir können obiges Beispiel zu Bankkonten etwas abwandeln. Nehmen wir an,
unsere Bank kennt anfangs nur Konten über Euro-Beträge, wodurch alle entsprechenden Variablen den Typ der Euro-Währung haben (keine Generizität
nötig). Wenn zu erwarten ist, dass künftig auch Konten über US-Dollar-Beträge
187
4 Dynamische Typinformation und statische Parametrisierung
gebraucht werden könnten, wäre es günstig, vor allem die Schnittstellen gleich
von Anfang an so zu gestalten, dass die spätere Einführung anderer Währungen vereinfacht wird. Das heißt, wie oben werden gleich Typparameter eingeschränkt auf Currency eingeführt, auch wenn diese Typparameter anfangs alle
nur durch den Typ der Euro-Beträge ersetzt werden.
Untertypbeziehungen und Generizität sind in Java miteinander verknüpft.
Die sinnvolle Verwendung gebundener Generizität setzt das Bestehen geeigneter Untertypbeziehungen voraus. Eine weitere Parallele zwischen Generizität
und Untertypbeziehungen ist erkennbar: Sowohl Generizität als auch Untertypbeziehungen helfen, notwendige Änderungen im Programmcode klein zu halten.
Generizität und Untertypbeziehungen ergänzen sich dabei: Generizität ist auch
dann hilfreich, wenn das Ersetzbarkeitsprinzip nicht erfüllt ist, während Untertypbeziehungen den Ersatz eines Objekts eines Obertyps durch ein Objekt
eines Untertyps auch unabhängig von Parametertypen ermöglichen.
Faustregel: Generizität und Untertyprelationen ergänzen sich. Wir
sollen stets überlegen, ob wir eine Aufgabe besser durch Ersetzbarkeit, durch Generizität, oder (häufig sinnvoll) eine Kombination aus
beiden Konzepten lösen.
Es sollte aber auch stets klar sein, dass nur Untertypen Ersetzbarkeit gewährleisten können. Bei Generizität bedingt eine Änderung im Server-Code in der
Regel auch Änderungen im Code aller Clients. Sinnvoll eingesetzte Untertypen
können das vermeiden.
Verwendbarkeit. Generizität und Untertypbeziehungen sind oft gegeneinander austauschbar. Das heißt, wir können ein und dieselbe Aufgabe mit Generizität oder über Untertypbeziehungen lösen. Es stellt sich die Frage, ob nicht
generell ein Konzept das andere ersetzen kann. Das geht nicht, wie wir an folgenden zwei Beispielen sehen:
Generizität ist sehr gut dafür geeignet, wie in obigen Beispielen eine Listenklasse zu schreiben, wobei ein Objekt nur Elemente eines Typs enthält und
ein anderes nur Elemente eines anderen Typs. Dabei ist statisch sichergestellt,
dass alle Elemente in einer Liste den gleichen Typ haben. Solche Listen sind
homogen. Ohne Generizität ist es nicht möglich, eine solche Klasse zu schreiben.
Zwar können wir auch ohne Generizität Listen erzeugen, die Elemente beliebiger
Typen enthalten, aber es ist nicht statisch sichergestellt, dass alle Elemente den
gleichen Typ haben. Daher können wir mit Hilfe von Generizität etwas machen,
was ohne Generizität, also nur durch Untertypbeziehungen, nicht machbar wäre.
Mit Generizität ohne Untertypbeziehungen ist es nicht möglich, eine Listenklasse zu schreiben, in der Elemente unterschiedliche Typen haben können.
Solche Listen sind heterogen. Daher können wir mit Hilfe von Untertypbeziehungen etwas machen, was ohne sie, also nur durch Generizität, nicht machbar
wäre. Generizität und Untertypbeziehungen ergänzen sich.
Diese Beispiele zeigen, was mit Generizität oder Untertypbeziehungen alleine
nicht machbar ist. Sie zeigen damit auf, in welchen Fällen wir Generizität bzw.
Untertypen zur Erreichung des Ziels unbedingt brauchen.
188
4.2 Verwendung von Generizität
Untertypbeziehungen ermöglichen durch die Ersetzbarkeit Codeänderungen
mit klaren Grenzen, welche Klassen davon betroffen sein können. Generizität
kann die von Änderungen betroffenen Bereiche nicht eingrenzen, da im ClientCode Typparameterersetzungen spezifiziert werden müssen. Wenn es um die
Entscheidung zwischen Untertypbeziehungen und Generizität geht, sollten wir
daher Untertypbeziehungen vorziehen.
Laufzeiteffizienz. Die Verwendung von Generizität hat keine oder zumindest
kaum negative Auswirkungen auf die Laufzeiteffizienz. Andererseits ist die Verwendung von dynamischem Binden im Zusammenhang mit Untertypbeziehungen immer etwas weniger effizient als statisches Binden. Aufgrund dieser Überlegungen kommt immer wieder jemand auf die Idee, stets Generizität einzusetzen,
aber dynamisches Binden nur dort zuzulassen, wo es unumgänglich ist. Da Generizität und Untertypbeziehungen oft gegeneinander austauschbar sind, ist das
im Prinzip machbar. Leider sind die tatsächlichen Beziehungen in der relativen
Effizienz von Generizität und dynamischem Binden keineswegs so einfach wie
hier dargestellt. Durch die Verwendung von Generizität zur Vermeidung von
dynamischem Binden ändert sich die Struktur des Programms, wodurch sich
die Laufzeiteffizienz wesentlich stärker (eher negativ als positiv) ändern kann
als durch die Vermeidung von dynamischem Binden. Wenn beispielsweise eine
switch-Anweisung zusätzlich ausgeführt werden muss, ist die Effizienz ziemlich
sicher schlechter geworden.
Faustregel: Wir sollen Überlegungen zur Laufzeiteffizienz beiseite
lassen, wenn es um die Entscheidung zwischen Generizität und Untertypbeziehungen geht.
Solche Optimierungen auf der untersten Ebene erfordern sehr viel Expertenwissen über Details von Compilern und Hardware und sind in der Regel nicht
portabel. Viel wichtiger ist es, auf die Einfachheit und Verständlichkeit zu achten. Wenn Effizienz entscheidend ist, müssen wir vor allem die Effizienz der
Algorithmen betrachten.
Natürlichkeit. Häufig bekommen wir auf die Frage, ob in einer bestimmten
Situation Generizität oder Subtyping einzusetzen sei, die Antwort, dass der
natürlichere Mechanismus am besten geeignet sei. Für erfahrene Leute ist diese Antwort häufig zutreffend: Mit einem gewissen Erfahrungsschatz kommt es
ihnen selbstverständlich vor, den richtigen Mechanismus zu wählen ohne die
Entscheidung begründen zu müssen. Hinter der Natürlichkeit verbirgt sich der
Erfahrungsschatz. Mit wenig einschlägiger Erfahrung sehen wir kaum, was natürlicher ist. Es zahlt sich in jedem Fall aus, genau zu überlegen, was wir mit
Generizität erreichen wollen und erreichen können. Wenn wir uns zwischen Generizität und Subtyping entscheiden sollen, ist es angebracht, auch eine Kombination von Generizität und Subtyping ins Auge zu fassen. Erst wenn diese
Überlegungen zu keinem eindeutigen Ziel führen, entscheiden wir uns für die
natürlichere Alternative.
189
4 Dynamische Typinformation und statische Parametrisierung
4.2.2 Arten der Generizität
Bisher haben wir Generizität als ein einziges Sprachkonzept betrachtet. Tatsächlich gibt es zahlreiche Varianten mit unterschiedlichen Eigenschaften. Wir
wollen hier einige Varianten miteinander vergleichen.
Für die Übersetzung generischer Klassen und Methoden in ausführbaren Code gibt es im Großen und Ganzen zwei Möglichkeiten, die homogene und die
heterogene Übersetzung. In Java wird die homogene Übersetzung verwendet.
Dabei wird jede generische Klasse, so wie auch jede nicht-generische Klasse, in
genau eine Klasse mit JVM-Code übersetzt. Jeder gebundene Typparameter
wird im übersetzten Code durch die erste Schranke des Typparameters ersetzt,
jeder ungebundene Typparameter durch Object. Wenn eine Methode ein Objekt eines Typparameters als Parameter nimmt oder zurückgibt, wird der Typ
des Objekts vor (für Parameter) oder nach dem Methodenaufruf (für Ergebnisse) dynamisch in den Typ, der den Typparameter ersetzt, umgewandelt,
wie wir in Abschnitt 4.3 sehen werden. Dies entspricht der Simulation einiger
Aspekte von Generizität. Im Unterschied zur simulierten Generizität wird die
Typkompatibilität vom Compiler garantiert.
Bei der heterogenen Übersetzung wird für jede Verwendung einer generischen
Klasse oder Methode mit anderen Typparametern eigener übersetzter Code erzeugt. Die heterogene Übersetzung entspricht also eher der Verwendung von
Copy-and-Paste, wie in Abschnitt 4.1.1 argumentiert. Dem Nachteil einer größeren Anzahl übersetzter Klassen und Methoden und der Duplizierung von
Klassenvariablen stehen einige Vorteile gegenüber: Da für alle Typen eigener
Code erzeugt wird, sind elementare Typen wie int, char und boolean ohne
Einbußen an Laufzeiteffizienz als Ersatz für Typparameter geeignet. Zur Laufzeit müssen keine Typumwandlungen und damit zusammenhängende Überprüfungen durchgeführt werden. Außerdem sind auf jede übersetzte Klasse eigene
Optimierungen anwendbar, die von den Typen abhängen. Daher bietet heterogene Übersetzung etwas bessere Laufzeiteffizienz. Heterogene Übersetzung wird
beispielsweise für Templates in C++ verwendet.
Große Unterschiede zwischen Programmiersprachen gibt es im Zusammenhang mit gebundener Generizität. Viele Sprachen (auch Java) verlangen die
Vorgabe einer Schranke, wobei nur Untertypen der Schranke den Typparameter ersetzen können. Dafür müssen geeignete Typhierarchien erstellt werden.
Vor allem bei Verwendung von Typen aus vorgefertigten Bibliotheken, deren
Untertypbeziehungen zueinander nicht mehr änderbar sind, ist das ein bedeutender Nachteil. Um beispielsweise compareTo über einen Typparameter verwenden zu können, reicht es nicht, wenn diese Methode implementiert ist; auch
Comparable<...> muss implementiert sein und als Schranke verwendet werden.
In der Theorie wäre es gar nicht nötig, dass Typparameter mit Schranken nur
durch Untertypen der Schranken ersetzbar sind. Untertypbeziehungen höherer
Ordnung (siehe Abschnitt 1.4.3) würden reichen; diese Beziehungen weisen starke Ähnlichkeit mit Untertypbeziehungen auf, garantieren jedoch keine Ersetzbarkeit, unterstützen dafür aber binäre Methoden. Solche Beziehungen würden
die Flexibilität von Generizität verbessern. Aus praktischen Gründen verzichten
190
4.2 Verwendung von Generizität
jedoch viele objektorientierte Sprachen darauf, weil eine zweite Typstruktur neben Subtyping die meisten Menschen verwirren würde. Nicht-objektorientierte
Sprachen wie Haskell haben jedoch diese zusätzliche Flexibilität (etwa durch
„Typklassen“, zwischen denen Untertypbeziehungen höherer Ordnung bestehen, jedoch keine Untertypbeziehungen).
Durch die heterogene Übersetzung von Templates müssen wir in C++ keine Schranken angeben, um Eigenschaften der Typen, die Typparameter ersetzen, verwenden zu können. Es wird einfach für jede übersetzte Klasse getrennt
überprüft, ob die Typen alle vorausgesetzten Eigenschaften erfüllen. In dieser
Hinsicht ist Generizität mit heterogener Übersetzung sehr flexibel (ähnlich den
Typklassen in Haskell, aber ohne explizite Spezifikationen). Unterschiedliche
Typen, die einen Typparameter ersetzen, müssen keinen gemeinsamen Obertyp
haben. Schranken auf Typparametern wären jedoch hilfreich, indem sie ClientCode vom Server-Code entkoppeln, sodass Clients keine versteckten Details des
Servers kennen müssen. In C++ gibt es derzeit noch nichts Entsprechendes. Dadurch haben Programmänderungen manchmal unvorhersehbare Auswirkungen
und die Qualität von Fehlermeldungen ist oft schlecht, da sie sich auf ServerCode beziehen, den ein Client gar nicht sehen soll.
Für Interessierte, nicht Prüfungsstoff. Das folgende Beispiel zeigt einen Ausschnitt aus einer generischen Klasse in C++:
template<typename T> class Pair {
public: Pair(T x, T y) { first = x; second = y; }
T sum() { return first + second; }
private: T first, second;
...
};
Die Klasse Pair verwendet T als Typparameter. Für T kann jeder Typ eingesetzt
werden, auf dessen Instanzen der Operator + definiert ist, da + in der Methode sum
verwendet wird. Im Kopf der Klasse ist diese Einschränkung nicht angeführt. Hier
sind einige Beispiele für die Verwendung von Pair:
Pair<int> anIntPair(2, 3);
Pair<Person> aPersonPair(Person("Susi"),
Person("Strolchi"));
Pair<char*> aStringPair("Susi", "Strolchi");
Die erste Zeile ersetzt T durch int und erzeugt eine Variable anIntPair, die mit
einem neuen Objekt von Pair initialisiert ist. Der Konstruktor wird mit den Argumenten 2 und 3 aufgerufen. Ein Aufruf von anIntPair.sum() liefert als Ergebnis 5,
da für + die ganzzahlige Addition verwendet wird. Ob die weiteren Zeilen korrekt
sind, hängt davon ab, ob für die Typen Person und char* (Zeiger auf Zeichen, als
String verwendbar) der Operator + implementiert wurde. (In C++ können Operatoren überladen und selbst implementiert werden.) Falls dem so ist, werden im Rumpf
von sum die entsprechenden Implementierungen von + aufgerufen. Sonst liefert der
Compiler eine Fehlermeldung.
Das nächste Beispiel zeigt eine generische Funktion in C++:
191
4 Dynamische Typinformation und statische Parametrisierung
template<typename T> T max(T a, T b) {
if (a > b)
return a;
return b;
}
...
int i, j;
char *x, *y;
Pair<int> p, q;
...
i = max(i, j); // maximum of integers
x = max(x, y); // maximum of pointers to characters
p = max(p, q); // maximum of integer pairs
Wie in Java erkennt der Compiler anhand der Typen der Argumente, welcher Typ
für den Typparameter zu verwenden ist. Im Beispiel wird vorausgesetzt, dass der
Operator > auf allen Typen, die für T verwendet werden, definiert ist, ohne diese
Eigenschaft explizit zu machen. Ende des Einschubs für Interessierte
Eine weitere Variante für den Umgang mit gebundenen Typparametern bietet
Ada: Als Schranke werden Funktionen (oder Prozeduren) angegeben, welche die
Typen, die Typparameter ersetzen, bereitstellen müssen. Auf den ersten Blick
ähnelt diese Variante der von Templates in C++. Jedoch kann bei jeder Verwendung einer generischen Einheit getrennt angegeben werden, welche konkrete
Funktion einen generischen Parameter ersetzt. Funktionen werden als generische Parameter behandelt. Ada hat den Nachteil, dass generische Funktionen
nicht einfach aufgerufen werden können, sondern zuvor daraus nicht-generische
Funktionen abgeleitet werden müssen. Gründe kommen aus der Philosophie
hinter Ada: Alles steht so weit wie möglich explizit im Programmcode.
Für Interessierte, nicht Prüfungsstoff. Eine generische Funktion in Ada [18]
soll zeigen, welche Flexibilität Einschränkungen auf Typparametern bieten können:
generic
type T is private;
with function "<" (X, Y: T) return Boolean is (<>);
function Max (X, Y: T) return T is
begin
if X < Y
then
return Y
else
return X
end if
end Max;
...
function IntMax is new Max (Integer);
function IntMin is new Max (Integer, ">");
192
4.3 Typabfragen und Typumwandlungen
Die Funktion Max hat zwei generische Parameter: den Typparameter T und den Funktionsparameter <, dessen Parametertypen mit dem Typparameter in Beziehung stehen. Aufgrund von „is (<>)“ kann der zweite Parameter weggelassen werden. In
diesem Fall wird dafür die Funktion namens < mit den entsprechenden Parametertypen gewählt, wie in C++. Die Funktion IntMax entspricht Max, wobei an Stelle von T
der Typ Integer verwendet wird. Als Vergleichsoperator wird der Kleiner-Vergleich
auf ganzen Zahlen verwendet. In der Funktion IntMin ist T ebenfalls durch Integer
ersetzt, zum Vergleich wird aber der Größer-Vergleich verwendet, sodass von IntMin
das kleinere Argument zurückgegeben wird. Anders als in C++ und Java müssen die
für Typparameter zu verwendenden Typen explizit angegeben werden.
Ende des Einschubs für Interessierte
In Java ist Ähnliches wie in Ada durch Komparatoren (siehe Abschnitt 4.1.2)
auch erzielbar, jedoch nur mit hohem Aufwand.
4.3 Typabfragen und Typumwandlungen
Wir wollen nun den Umgang mit dynamischer Typinformation untersuchen.
In Abschnitt 4.3.1 finden sich allgemeine Hinweise dazu. In den nächsten beiden Abschnitten werden spezifische Probleme durch Verwendung dynamischer
Typinformation gelöst: Abschnitt 4.3.2 behandelt simulierte Generizität und
Abschnitt 4.3.3 kovariante Probleme.
4.3.1 Verwendung dynamischer Typinformation
Jedes Objekt hat eine Methode getClass, welche die interne Repräsentation der
Klasse des Objekts (vom Typ Class) als Ergebnis zurückgibt. Diese Methode
bietet die direkteste Möglichkeit des Zugriffs auf den dynamischen Typ. Für
jedes Interface, jede Klasse, jeden elementaren Typ sowie davon abgeleiteten
Array-Typ gibt es ein eigenes Objekt vom Typ Class. Solche Objekte lassen
sich einfach mit == vergleichen, equals ist dafür nicht nötig. Objekte von Class
sind die besten Ausgangspunkte, wenn es darum geht, zur Laufzeit festzustellen,
wie der entsprechende Typ aufgebaut ist. Objekte von Class lassen sich auch
direkt durch Anhängen von .class an einen Typ ansprechen; z. B. int.class,
int[].class, Person.class und Comparable.class.
Häufig möchten wir nur wissen, ob der dynamische Typ eines Referenzobjekts
Untertyp eines gegebenen Typs ist. Dafür bietet Java den instanceof-Operator
an, wie folgendes Beispiel zeigt:
int calculateTicketPrice(Person p) {
if (p.age() < 15 || p instanceof Student)
return standardPrice / 2;
return standardPrice;
}
193
4 Dynamische Typinformation und statische Parametrisierung
Eine Anwendung des instanceof-Operators liefert true, wenn das Objekt links
vom Operator eine Instanz des Typs rechts vom Operator ist. Im Beispiel liefert die Typabfrage true wenn p vom dynamischen Typ Student, Tutor oder
StudTrainee ist (entsprechend der Typhierarchie aus Abschnitt 3.1.2). Die Abfrage liefert false wenn p gleich null oder von einem anderen dynamischen
Typ ist. Solche dynamischen Typabfragen können, wie alle Vergleichsoperationen, überall stehen, wo Boolesche Ausdrücke erlaubt sind.
Mittels Typabfragen lässt sich zwar der Typ eines Objekts zur Laufzeit bestimmen, aber Typabfragen reichen nicht aus, um auf Methoden und Variablen
des dynamisch ermittelten Typs zugreifen zu können. Wir wollen auch Nachrichten an das Objekt senden können, die nur Instanzen des dynamisch ermittelten
Typs verstehen, oder das Objekt als aktuellen Parameter verwenden, wobei der
Typ des formalen Parameters dem dynamisch ermittelten Typ entspricht. Für
diese Zwecke gibt es in Java explizite Typumwandlungen als Casts auf Referenzobjekten. Folgendes (auf den ersten Blick überzeugende, tatsächlich aber
fehlerhafte) Beispiel2 modifiziert ein Beispiel aus Abschnitt 3.1.1:
class Point3D extends Point2D {
private int z;
public boolean equal(Point2D p) {
// true if points are equal in all coordinates
if (p instanceof Point3D)
return super.equal(p) && ((Point3D)p).z == z;
return false;
}
}
In Point3D liefert equal als Ergebnis false wenn der dynamische Typ des
Arguments kein Untertyp von Point3D ist. Sonst wird die Methode aus Point2D
aufgerufen und die zusätzlichen Objektvariablen z werden verglichen. Vor dem
Zugriff auf z von p ist eine explizite Typumwandlung nötig, die den deklarierten
Typ von p von Point2D (wie im Kopf der Methode angegeben) nach Point3D
umwandelt, da z in Objekten von Point2D nicht zugreifbar ist. Syntaktisch
wird die Typumwandlung als (Point3D)p geschrieben. Um den Ausdruck sind
Klammern nötig, damit der Typ von p umgewandelt wird, nicht der Typ des
Ergebnisses von p.z == z wie in (Point3D)p.z == z.
Verbesserungen von Point2D und Point3D folgen in Abschnitt 4.3.3. Dieses
Beispiel ist typisch für in der Praxis häufig vorkommende Lösungen ähnlicher
Probleme: Obwohl der Typvergleich und die Typumwandlung hier korrekt eingesetzt sind, ergibt sich aus der Problemstellung selbst zusammen mit dem
Lösungsansatz ein unerwünschtes Programmverhalten. Alleine schon die Notwendigkeit für Typabfragen und Typumwandlungen deutet darauf hin, dass
2Versuchen Sie, Fehler in dieser „Lösung“ selbst zu finden. Die Verwendung von dynamischer Typinformation sowie die Typumwandlung ist hier korrekt. Aber vielleicht wird
eine implizite Zusicherung verletzt, wie die, dass a.equal(b) dasselbe Ergebnis liefert
wie b.equal(a). Am schnellsten wird der Fehler sichtbar, wenn wir Zusicherungen auf
Point3D und Point2D explizit machen.
194
4.3 Typabfragen und Typumwandlungen
wir es mit einer Problemstellung zu tun haben, die mit den üblichen Konzepten
der objektorientierten Programmierung nicht einfach in den Griff zu bekommen ist. Deswegen müssen wir sehr vorsichtig sein. Wir können uns nicht auf
die Intuition verlassen. Das liegt (neben der Gefährlichkeit des falschen Einsatzes von Typabfragen und Typumwandlungen) auch an der komplexen Natur
entsprechender Problemstellungen.
Typumwandlungen sind auf Referenzobjekten nur durchführbar, wenn der
Ausdruck, dessen deklarierter Typ in einen anderen Typ umgewandelt werden
soll, tatsächlich den gewünschten Typ – oder einen Untertyp davon – als dynamischen Typ hat oder gleich null ist. Im Allgemeinen ist das erst zur Laufzeit
feststellbar. Zur Laufzeit erfolgt eine entsprechende Überprüfung. Sind die Bedingungen nicht erfüllt, wird eine Ausnahme ausgelöst.
Dynamische Typabfragen und Typumwandlungen sind sehr mächtige Werkzeuge. Wir können damit einiges machen, was sonst nicht oder nur sehr umständlich machbar wäre. Allerdings kann die falsche Verwendung Fehler in einem Programm verdecken und die Wartbarkeit erschweren. Fehler werden oft
dadurch verdeckt, dass der deklarierte Typ einer Variablen oder eines formalen
Parameters nur mehr wenig mit dem Typ zu tun hat, dessen Objekte wir erwarten. Beispielsweise ist der deklarierte Typ Object, obwohl wir erwarten, dass
nur Objekte von Integer oder Person vorkommen. Einen konkreteren gemeinsamen Obertyp dieser beiden Typen als Object gibt es im System ja nicht. Um
auf Eigenschaften von Integer oder Person zuzugreifen, werden dynamische
Typabfragen und Typumwandlungen eingesetzt. Wenn in Wirklichkeit statt einem Objekt von Integer oder Person ein Objekt von Point2D verwendet wird,
liefert der Compiler keine Fehlermeldung. Erst zur Laufzeit kann es im günstigsten Fall zu einer Ausnahmebehandlung kommen. Es ist aber auch möglich,
dass einfach nur die Ergebnisse falsch sind, oder – noch schlimmer – falsche
Daten in einer Datenbank gespeichert werden. Der Grund für das mangelhafte
Erkennen dieses Typfehlers liegt darin, dass mit Hilfe von dynamischen Typabfragen und Typumwandlungen statische Typüberprüfungen durch den Compiler ausgeschaltet wurden, obwohl wir uns vermutlich nach wie vor auf statische
Typsicherheit verlassen.
Die schlechte Wartbarkeit ist ein weiterer Grund, um Typabfragen (auch ohne
Typumwandlungen) nur sehr sparsam zu nutzen:
if (x instanceof T1)
doSomethingOfTypeT1((T1)x);
else if (x instanceof T2)
doSomethingOfTypeT2((T2)x);
...
else
doSomethingOfAnyType(x);
Wie schon bekannt, lassen sich switch- und if-Anweisungen durch dynamisches Binden ersetzen. Das sollen wir tun, da dynamisches Binden wartungsfreundlicher ist. Dasselbe gilt für dynamische Typabfragen, welche die möglichen Typen im Programmcode fix verdrahten und daher bei Änderungen der
195
4 Dynamische Typinformation und statische Parametrisierung
Typhierarchie ebenfalls geändert werden müssen. Oft sind dynamische Typabfragen wie im Beispiel durch x.doSomething() ersetzbar. Die Auswahl des
auszuführenden Programmcodes erfolgt durch dynamisches Binden. Die Klasse des deklarierten Typs von x implementiert doSomething entsprechend der
Methode doSomethingOfAnyType, die Unterklassen T1, T2 und so weiter entsprechend doSomethingOfTypeT1, doSomethingOfTypeT2 und so weiter.
Manchmal ist es nicht einfach, dynamische Typabfragen durch dynamisches
Binden zu ersetzen. Dies trifft vor allem in diesen Fällen zu:
• Der deklarierte Typ von x ist zu allgemein; die einzelnen Alternativen
decken nicht alle Möglichkeiten ab. Das ist genau die oben erwähnte gefährliche Situation, in der die statische Typsicherheit von Java umgangen
wird. In dieser Situation ist eine Refaktorisierung des Programms angebracht, die Typabfragen vermeidet.
• Die Klassen, die dem deklarierten Typ von x und dessen Untertypen
entsprechen, können nicht erweitert werden, beispielsweise weil sie als
final definiert wurden und wir keinen Zugriff auf den Source-Code haben.
Als Lösung können wir parallel zur unveränderbaren Klassenhierarchie
eine gleich strukturierte Hierarchie aufbauen, deren Klassen (WrapperKlassen) die zusätzlichen Methoden beschreiben. Typabfragen ermöglichen in einfachen Fällen eine einfache Lösung. In komplexeren Fällen wird
ein Wrapper die bessere Lösung sein.
• Manchmal ist die Verwendung dynamischen Bindens schwierig, weil die
einzelnen Alternativen auf private Variablen und Methoden zugreifen. Methoden anderer Klassen haben diese Information nicht. Oft lässt sich die
fehlende Information durch Übergabe geeigneter Argumente beim Aufruf
der Methode oder durch „Call-Backs“ (also Rückfragen an das aufrufende
Objekt – sinnvoll wenn die Information nur selten benötigt wird) verfügbar machen. Diese Techniken werden in Java vor allem durch (anonyme)
innere Klassen und (seit Java 8) Lambda-Ausdrücke unterstützt.
• Der deklarierte Typ von x kann sehr viele Untertypen haben. Wenn
doSomething nicht in einer gemeinsamen Oberklasse in der Bedeutung
von doSomethingOfAnyType implementierbar ist, muss doSomething in
vielen Klassen auf gleiche Weise implementiert werden. Das bedeutet
einen Mehraufwand für die Wartung. Typabfragen scheinen eine einfachere Lösung zu bieten. Ein Grund, warum die Methode nicht in der
Oberklasse implementierbar sein könnte, liegt in der fehlenden Mehrfachvererbung. Default-Methoden in Interfaces reduzieren dieses Problem seit
Java 8: Bis auf direkte Variablenzugriffe gibt es Mehrfachvererbung.
Faustregel: Typabfragen und Typumwandlungen sollen nach Möglichkeit vermieden werden.
In wenigen Fällen ist es nötig und durchaus angebracht, diese mächtigen, aber
unsicheren Werkzeuge zu verwenden, wie wir noch sehen werden.
196
4.3 Typabfragen und Typumwandlungen
Typumwandlungen werden auch auf elementaren Typen wie int, char und
float unterstützt. In diesen Fällen haben Typumwandlungen aber eine andere
Bedeutung, da für Variablen elementarer Typen die dynamischen Typen immer gleich den statischen und deklarierten Typen sind. Bei elementaren Typen
werden tatsächlich die Werte umgewandelt, nicht deklarierte Typen. Aus einer Gleitkommazahl wird beispielsweise durch Runden gegen Null eine ganze
Zahl. Dabei kann Information verloren gehen, aber es kommt zu keiner Ausnahmebehandlung. Daher haben Typumwandlungen auf elementaren Typen eine
ganz andere Qualität als auf Referenztypen und machen im Normalfall keinerlei
Probleme. Typumwandlungen zwischen elementaren Typen und Referenztypen
werden in Java nicht unterstützt.
4.3.2 Typumwandlungen und Generizität
Die homogene Übersetzung einer generischen Klasse oder Methode in eine Klasse oder Methode ohne Generizität ist im Prinzip sehr einfach, wie wir bereits
in Abschnitt 4.2.2 gesehen haben:
• Spitze Klammern werden samt ihren Inhalten weggelassen.
• Jedes verbliebene Vorkommen eines Typparameters wird durch Object
oder, falls vorhanden, die erste Schranke ersetzt.
• Ergebnisse und Argumente werden in die nötigen deklarierten Typen umgewandelt, wenn die entsprechenden Ergebnistypen und formalen Parametertypen Typparameter sind, die durch Typen ersetzt wurden.
Aus der Listen-Klasse und den Interfaces aus Abschnitt 4.1.2 entsteht das:
public class List implements Collection {
private Node head = null, tail = null;
public void add(Object elem) {
if (head == null) tail = head = new Node((Object)elem);
else tail.setNext(tail = new Node((Object)elem));
}
private class ListIter implements Iterator {
private Node p = head;
public boolean hasNext() { return p != null; }
public Object next() {
if (p == null)
throw new java.util.NoSuchElementException();
Object elem = (Object)p.elem();
p = p.next();
return elem;
}
}
public Iterator iterator() { return new ListIter(); }
}
197
4 Dynamische Typinformation und statische Parametrisierung
class Node {
private Object elem;
private Node next = null;
public Node(Object elem) { this.elem = elem; }
public Object elem() { return elem; }
public Node next() { return next; }
public void setNext(Node next) { this.next = next; }
}
public interface Collection {
void add(Object elem);
Iterator iterator();
}
public interface Iterator {
Object next();
boolean hasNext();
}
Mangels expliziter Schranke wurden die Typparameter durch Object ersetzt.
In den Konstruktoraufrufen von Node und auf dem Ergebniswert von p.elem()
wurden nach dem gegebenen Schema automatisch Casts auf Object hinzugefügt
– Object weil die Typparameter durch Object ersetzt sind. Diese Casts sind
hier sinnlos und werden vom Compiler gleich wieder wegoptimiert. Sinnvollere
Typumwandlungen ergeben sich durch die Übersetzung der Klasse ListTest:
class ListTest {
public static void main(String[] args) {
List xs = new List();
xs.add((Integer)new Integer(0));
Integer x = (Integer)xs.iterator().next();
List ys = new List();
ys.add((String)"zerro");
String y = (String)ys.iterator().next();
List zs = new List();
zs.add((List)xs);
List z = (List)zs.iterator().next();
}
}
Die Typumwandlungen in den Aufrufen von add haben nur einen Zweck: Falls
add überladen wäre, würden die Typumwandlungen für die Auswahl der richtigen Methoden sorgen, indem sie die deklarierten Typen entsprechend anpassen.
Ein Compiler wird solche Typumwandlungen wohl wegoptimieren.
Die Typumwandlungen der Ergebnisse der Methodenaufrufe sind dagegen
von großer Bedeutung. Wenn der Ergebnistyp der Methode vor Übersetzung
198
4.3 Typabfragen und Typumwandlungen
der Generizität ein Typparameter war, wird das Ergebnis unmittelbar nach
dem Aufruf in den Typ umgewandelt, der den Typparameter ersetzt. So bekommt das Ergebnis des ersten Aufrufs von next den erwarteten deklarierten
Typ Integer, obwohl next nur ein Ergebnis vom deklarierten Typ Object
zurückgibt. Das Ergebnis des zweiten Aufrufs bekommt dagegen wie erwartet
den deklarierten Typ String, obwohl genau dieselbe Methode next aufgerufen
wird. Durch die Typumwandlungen auf den Ergebnissen kann ein und dieselbe
Methode also für unterschiedliche Typen eingesetzt werden.
Im letzten Teil des Beispiels wird nur der Typ List verwendet, obwohl eigentlich der Typ List<Integer> korrekt wäre. Die spitzen Klammern samt Inhalt
werden jedoch weggelassen. Weiter unten werden wir sehen, dass List genau
der Typ ist, der durch Übersetzung der Generizität aus List<A> erzeugt wurde.
Dessen Verwendung macht durchaus Sinn.
Abgesehen von einigen unbedeutenden Details, auf die wir hier nicht näher eingehen, ist die Übersetzung so einfach, dass wir sie auch selbst ohne
Unterstützung durch den Compiler durchführen können. Wir können gleich direkt Programmcode ohne Generizität schreiben. Allerdings hat das auch einen
schwerwiegenden Nachteil: Statt Fehlermeldungen, die bei Verwendung von Generizität der Compiler generiert, werden ohne Generizität erst zur Laufzeit Ausnahmen ausgelöst. Zum Beispiel liefert der Java-Compiler für
List<Integer> xs = new List<Integer>();
xs.add(new Integer(0));
String y = xs.iterator().next();
// Syntaxfehler: String erwartet, Integer gefunden
eine Fehlermeldung, nicht aber für den daraus generierten Code:
List xs = new List();
xs.add(new Integer(0));
String y = (String)xs.iterator().next();
// Exception bei Typumwandlung von Object auf String
Die Vorteile von Generizität liegen also in erster Linie in der besseren Lesbarkeit
und höheren Typsicherheit.
Viele ältere, nicht-generische Java-Bibliotheken verwenden Klassen, die so
aussehen, als ob sie aus generischen Klassen erzeugt worden wären. Das heißt,
Objekte, die in Listen etc. eingefügt werden, müssen in der Regel nur Untertypen von Object sein. Vor der Verwendung von aus solchen Datenstrukturen
gelesenen Objekten steht meist eine Typumwandlung. Die durchgehende Verwendung von Generizität würde den Bedarf an Typumwandlungen vermeiden
oder zumindest erheblich reduzieren.
Faustregel: Wir sollen nur sichere Formen der Typumwandlung (die
keine Ausnahmen auslösen) einsetzen.
199
4 Dynamische Typinformation und statische Parametrisierung
Sichere Typumwandlungen. Dieser Argumentation folgend ist es leicht, sich
auch bei der Programmierung in einer Sprache ohne Generizität anzugewöhnen,
nur „sichere“ Typumwandlungen einzusetzen: Typumwandlungen sind sicher
(lösen keine Ausnahmebehandlung aus) wenn
• in einen Obertyp des deklarierten Objekttyps umgewandelt wird,
• oder davor eine dynamische Typabfrage erfolgt, die sicherstellt, dass das
Objekt einen entsprechenden dynamischen Typ hat,
• oder das Programmstück so geschrieben ist, als ob Generizität verwendet würde und alle Konsistenzprüfungen, die normalerweise der Compiler
macht, vor der homogenen Übersetzung der Generizität händisch von uns
durchgeführt werden.
Im ersten Fall handelt es sich um eine völlig harmlose Typumwandlung nach
oben in der Typhierarchie (genannt Up-Cast), die aber kaum gebraucht wird.
Nur auf Argumenten ist sie manchmal sinnvoll, um zwischen überladenen Methoden zu wählen – wie die Typumwandlungen, die bei der Übersetzung der
Generizität auf Argumenten eingeführt wurden.
Die beiden anderen Fälle sind wichtiger, beziehen sich aber auf weniger harmlose Typumwandlungen nach unten – sogenannte Down-Casts.
Der zweite Punkt in obiger Aufzählung impliziert, dass es einen sinnvollen
Programmzweig geben muss, der im Falle des Scheiterns des Typvergleichs ausgeführt wird. Würden wir im alternativen Zweig nur eine Ausnahme werfen,
könnten wir nicht von einer sicheren Typumwandlung sprechen. Leider erweisen sich gerade falsche Typannahmen in alternativen Zweigen als häufige Fehlerquelle. Fehler zeigen sich oft erst später. Angenommen, ein abstrakter Typ
A hat die beiden Untertypen B und C und x ist vom deklarierten Typ A. Es ist
sehr verlockend, im else-Zweig von if(x instanceof B){...}else{...} anzunehmen, dass x vom Typ C wäre und einen vermeintlich sicheren Cast (C)x
zu verwenden. Das Testen des Programmstücks wird keinen Fehler erkennen
lassen. Wenn jedoch nachträglich ein neuer Untertyp D von A hinzugefügt wird,
ist die Annahme verletzt und der Fehler zeigt sich.
Faustregel: Bei Zutreffen des zweiten Punkts ist besonders darauf
zu achten, dass alle Annahmen im alternativen Zweig (bei Scheitern
des Typvergleichs) durch Zusicherungen abgesichert sind.
Außerdem gibt es oft mehrere alternative Zweige, die sich in geschachtelten
if-Anweisungen zeigen. Aufgrund der damit verbundenen Wartungsprobleme
sollten wir auf solche Lösungen verzichten.
Bei Zutreffen des dritten Punkts treten keine solchen Probleme auf. Stattdessen sind aufwendige händische Programmanalysen notwendig. Es muss vor
allem sichergestellt werden, dass
• wirklich alle Ersetzungen eines (gedachten) Typparameters durch einen
Typ gleichförmig erfolgen – das heißt, jedes Vorkommen des Typparameters tatsächlich durch denselben Typ ersetzt wird
200
4.3 Typabfragen und Typumwandlungen
• und keine impliziten Untertypbeziehungen vorkommen.
Vor allem hinsichtlich impliziter Untertypbeziehungen ist die Intuition leicht
irreführend, da beispielsweise sowohl List<Integer> als auch List<String>
in der homogenen Übersetzung durch List dargestellt werden, obwohl sie nicht
gegeneinander ersetzbar sind.
Faustregel: Wenn die Programmiersprache Generizität unterstützt,
soll die dritte Möglichkeit nicht verwendet werden.
Generizität ist einer dynamischen Typumwandlung immer vorzuziehen. Wenn
Generizität nicht unterstützt wird, ist der dritte Punkt dem zweiten vorzuziehen. Unnötige dynamische Typvergleiche (z. B. zur Absicherung einer Typumwandlung, obwohl die Voraussetzungen dafür gemäß dem dritten Punkt händisch überprüft wurden) sollen vermieden werden, da sie die Sicherheit nicht
wirklich erhöhen, aber die Wartung erschweren können.
Umgang mit Einschränkungen der Generizität. Generizität ist, mit einigen
Einschränkungen, auch in dynamischen Typabfragen und Typumwandlungen
einsetzbar:
<A> Collection<A> up(List<A> xs) {
return (Collection<A>)xs;
}
<A> List<A> down(Collection<A> xs) {
if (xs instanceof List<A>)
return (List<A>)xs;
else { ... } // Was machen wir hier?
}
List<String> bad(Object o) {
if (o instanceof List<String>) // error
return (List<String>)o; // error
else { ... } // Was machen wir hier?
}
In der Methode bad werden vom Compiler Fehlermeldungen ausgegeben, da es
zur Laufzeit keine Information über den gemeinsamen Typ der Listenelemente
gibt. Es ist daher unmöglich, in einer Typabfrage oder Typumwandlung dynamisch zu prüfen, ob o den gewünschten Typ hat. Die Methoden up und down
haben dieses Problem nicht, weil der bekannte Unter- beziehungsweise Obertyp
den Typ aller Listenelemente bereits statisch festlegt, falls es sich tatsächlich
um eine Liste handelt. Der Compiler ist intelligent genug, solche Situationen
zu erkennen. Bei der Übersetzung werden einfach alle spitzen Klammern (und
deren Inhalte) weggelassen. Im übersetzten Programm sind die strukturellen
Unterschiede zwischen down und bad nicht mehr erkennbar, aber bad kann zu
einer Ausnahme führen. Bei der händischen Programmüberprüfung ist auf solche Feinheiten besonders zu achten.
Java erlaubt die gemischte Verwendung von generischen Klassen und Klassen,
die durch homogene Übersetzung daraus erzeugt wurden:
201
4 Dynamische Typinformation und statische Parametrisierung
public class List<A> implements Collection<A> {
...
public boolean equals(Object o) {
if (o == null || o.getClass() != List.class)
return false;
Iterator<A> xi = this.iterator();
Iterator yi = ((List)o).iterator();
while (xi.hasNext() && yi.hasNext()) {
A x = xi.next();
Object y = yi.next();
if (!(x == null ? y == null : x.equals(y)))
return false;
}
return !(xi.hasNext() || yi.hasNext());
}
}
Im Beispiel sind List<A> und Iterator<A> generisch, List die entsprechende übersetzte Klasse und Iterator das übersetzte Interface. Übersetzte Klassen und Interfaces werden Raw-Types genannt. Wir sprechen auch von TypeErasures um darauf hinzuweisen, dass durch die Übersetzung Typinformation
weggelassen wird, die zur Laufzeit nicht mehr zur Verfügung steht. Sind Ausdrücke in spitzen Klammern angegeben, erfolgt die statische Typüberprüfung
für Generizität. Sonst prüft der Compiler Typparameter nicht.
Ein häufiges Anfänger- und Unachtsamkeitsproblem besteht darin, dass wir
bei Typdeklarationen die spitzen Klammern anzugeben vergessen. Da solche
Typen vom Compiler als Raw-Types verstanden werden, erfolgt keine Typüberprüfung der Generizität. Folglich halten wir das falsche Programm für korrekt.
Daher müssen wir stets auf das Vorhandensein der spitzen Klammern achten.
Der Java-Compiler kann in einem lokalen Kontext die Typen in spitzen Klammern, die Typparameter ersetzen, selbst ableiten (inferieren). Wir müssen diese Typen daher gar nicht selbst hinschreiben. Allerdings müssen wir in allen
Fällen leere spitze Klammern hinschreiben (z. B. List<> in einer Deklaration List<String> lst = new List<>()), damit der Compiler Typen mit derart abgeleiteten Typen von Raw-Types unterscheiden kann. Es passiert nichts
Schlimmes, wenn wir versuchen, überall Typen in spitzen Klammern wegzulassen, aber die spitzen Klammern hinschreiben. Wenn der Compiler nicht genug
Information für die Typprüfung hat, wird uns eine Fehlermeldung darauf aufmerksam machen, aber den Programmablauf beeinflusst das nicht.
4.3.3 Kovariante Probleme
In Abschnitt 3.1 haben wir gesehen, dass Typen von Eingangsparametern nur
kontravariant sein können. Kovariante Eingangsparametertypen verletzen das
Ersetzbarkeitsprinzip. In der Praxis wünschen wir uns manchmal gerade kovariante Eingangsparametertypen. Entsprechende Aufgabenstellungen heißen
202
4.3 Typabfragen und Typumwandlungen
kovariante Probleme. Zur Lösung kovarianter Probleme bieten sich dynamische
Typabfragen und Typumwandlungen an, wie folgendes Beispiel zeigt:
abstract class Food { ... }
class Grass extends Food { ... }
class Meat extends Food { ... }
abstract class Animal {
public abstract void eat(Food x);
}
class Cow extends Animal {
public void eat(Food x) {
if (x instanceof Grass) { ... }
else fallIll();
}
}
class Tiger extends Animal {
public void eat(Food x) {
if (x instanceof Meat) { ... }
else showTeeth();
}
}
Es ist ganz natürlich, Grass und Meat als Untertypen von Food anzusehen.
Grass und Meat sind offensichtlich einander ausschließende Spezialisierungen
von Food. Ebenso sind Cow und Tiger Spezialisierungen von Animal. Es entspricht dem Alltagswissen, dass Tiere im Allgemeinen Futter fressen, Rinder
aber nur Gras und Tiger nur Fleisch. Als Parametertyp der Methode eat wünschen wir uns daher in Animal Food, in Cow Grass und in Tiger Meat.
Genau diese Beziehungen aus der realen Welt sind aber nicht typsicher darstellbar. Zur Lösung des Problems bietet sich eine erweiterte Sicht der Beziehungen aus der realen Welt an: Wir können auch einem Rind Fleisch und einem
Tiger Gras zum Fressen anbieten. In diesem Fall müssen wir aber mit unerwünschten Reaktionen der Tiere rechnen. Obiges Programmstück beschreibt
entsprechendes Verhalten: Wenn dem Tier geeignetes Futter angeboten wird,
erledigen die Methoden eat die Aufgaben problemlos. Sonst führen sie Aktionen
aus, die vermutlich nicht erwünscht sind.
In obigem Programmtext sind immer dynamische Typabfragen nötig, auch
wenn Aufrufer die richtige Futterart kennen. Durch Überladen von Methoden
können wir in diesem Fall gleich den richtigen Code ausführbar machen:
class Cow extends Animal {
public void eat(Grass x) { ... }
public void eat(Food x) {
if (x instanceof Grass) eat((Grass)x);
else fallIll();
}
}
203
4 Dynamische Typinformation und statische Parametrisierung
class Tiger extends Animal {
public void eat(Meat x) { ... }
public void eat(Food x) {
if (x instanceof Meat) eat((Meat)x);
else showTeeth();
}
}
In Cow und Tiger ist eat überladen, es gibt also mehrere Methoden desselben Namens. Die Methoden mit Food als Parametertyp überschreiben jene aus
Animal, während die anderen nicht in Animal vorkommen. Es wird die Methode ausgeführt, deren formaler Parametertyp der spezifischste Obertyp des
deklarierten Argumenttyps ist. Nur wenn in einem Aufruf a.eat(f) sowohl die
Tierart durch den deklarierten Typ von a und die passende Futterart durch
den deklarierten Typ von f dem Compiler bekannt sind, wird gleich die richtige Methode ausgeführt. In allen anderen Fällen wird die Methode mit Food
als formaler Parametertyp ausgeführt, sodass eine dynamische Typabfrage nötig ist. Falls die Futterart (über den dynamischen Typ ermittelt) passt, wird
zur Laufzeit auf die richtige Methode verzweigt, wobei der deklarierte Typ des
Arguments durch einen Cast bestimmt wird.
Durch Umschreiben des Programms können wir zwar Typabfragen und Typumwandlungen vermeiden (eine Technik dafür sehen wir bald), aber die unerwünschten Aktionen bei kovarianten Problemen bleiben erhalten. Die einzige
Möglichkeit besteht darin, kovariante Probleme zu vermeiden. Beispielsweise
reicht es, eat aus Animal zu entfernen. Dann können wir zwar eat nur mehr
mit Futter der richtigen Art in Cow und Tiger aufrufen, aber wir können Tiere
nur mehr füttern, wenn wir die Art der Tiere und des Futters genau kennen.
Faustregel: Kovariante Probleme sind möglichst zu vermeiden.
Für Interessierte, nicht Prüfungsstoff. Einige Programmiersprachen bieten teilweise Lösungen für kovariante Probleme an. Betrachten wir Eiffel: In dieser Sprache
sind kovariante Eingangsparametertypen erlaubt. Wenn die Klasse Animal die Methode eat mit dem Parametertyp Food enthält, können die überschriebenen Methoden
in den Klassen Cow und Tiger die Parametertypen Grass und Meat haben. Dies
ermöglicht eine natürliche Modellierung kovarianter Probleme. Weil dadurch das Ersetzbarkeitsprinzip verletzt ist, können an Stelle dieses Parameters keine Argumente
von einem Untertyp des Parametertyps verwendet werden. Der Compiler kann jedoch
die Art des Tieres oder die Art des Futters nicht immer statisch feststellen. Wird eat
mit einer falschen Futterart aufgerufen, kommt es zu einer Ausnahme zur Laufzeit.
Tatsächlich ergibt sich dadurch derselbe Effekt, als ob wir in Java ohne vorhergehende Überprüfung den Typ des Arguments von eat auf die gewünschte Futterart
umwandeln würden. Eine echte Lösung des Problems ist das daher nicht.
Einen anderen Ansatz bieten virtuelle Typen, die derzeit in keiner gängigen Programmiersprache verwendet werden [20, 17]. Virtuelle Typen ähneln geschachtelten
Klassen wie in Java, die jedoch, anders als in Java, in Unterklassen überschreibbar
sind. Die beiden Klassenhierarchien mit Animal und Food als Wurzeln werden eng
204
4.3 Typabfragen und Typumwandlungen
verknüpft: Food ist in Animal enthalten. In Cow ist Food mit einer neuen Klasse
überschrieben, welche die Funktionalität von Grass aufweist, Food in Tiger mit einer Klasse der Funktionalität von Meat. Statt Grass und Food schreiben wir dann
Cow.Food und Tiger.Food. Der Typ Food des Parameters von eat bezieht sich immer auf den lokal gültigen Namen, in Cow also auf Cow.Food. Noch immer müssen
wir eat in Cow mit einem Argument vom Typ Cow.Food und in Tiger mit einem
Argument vom Typ Tiger.Food aufrufen; die Art des Tieres muss also mit der Art
des Futters übereinstimmen und der Compiler muss die Übereinstimmung überprüfen können. Aber wenn Animal (und daher auch Cow und Tiger) eine Methode hat,
die ein Objekt vom Typ Food als Ergebnis liefert, kann das Ergebnis eines solchen
Methodenaufrufs als Argument eines Aufrufs von eat in demselben Objekt verwendet werden. Dabei muss die Art des Tieres nicht bekannt sein und es ist trotzdem
kein Typfehler möglich. Eine ähnliche Methode können wir durch kovariante Ergebnistypen auch in Java schreiben; sie liefert in Cow ein Ergebnis vom Typ Grass und
in Tiger eines vom Typ Meat. Aber in Java können wir das Ergebnis eines solchen
Methodenaufrufs in einem unbekannten Tier nicht typsicher und ohne dynamische
Typprüfung an dieses Tier verfüttern. Mit virtuellen Typen wäre das möglich. Gerade in dieser Möglichkeit liegt der (kleine, aber doch vorhandene) inhaltliche Vorteil
virtueller Typen. Ein weiterer Vorteil könnte auf der psychologischen Ebene liegen,
da der Umgang damit sehr natürlich wirkt, sodass tief gehende Schwierigkeiten im
Umgang mit kovarianten Problemen nicht in den Vordergrund treten.
Ende des Einschubs für Interessierte
Binäre Methoden. Einen häufig vorkommenden Spezialfall kovarianter Probleme stellen binäre Methoden dar. Wie in Abschnitt 3.1 eingeführt, hat eine
binäre Methode mindestens einen formalen Parameter, dessen Typ gleich der
Klasse ist, welche die Methode enthält. Wir könnten binäre Methoden auf die
gleiche Weise behandeln wie alle anderen kovarianten Probleme, also dynamische Typabfragen verwenden. Es gibt bessere Lösungen. Hier ist eine bessere
Lösung für die binäre Methode equal in Point2D und Point3D:
abstract class Point {
public final boolean equal(Point that) {
if (that != null && this.getClass() == that.getClass())
return uncheckedEqual(that);
return false;
}
protected abstract boolean uncheckedEqual(Point p);
}
class Point2D extends Point {
private int x, y;
protected boolean uncheckedEqual(Point p) {
Point2D that = (Point2D)p;
return this.x == that.x && this.y == that.y;
}
}
205
4 Dynamische Typinformation und statische Parametrisierung
class Point3D extends Point {
private int x, y, z;
protected boolean uncheckedEqual(Point p) {
Point3D that = (Point3D)p;
return this.x==that.x && this.y==that.y && this.z==that.z;
}
}
Anders als in vorangegangenen Lösungsansätzen ist Point3D kein Untertyp von
Point2D, sondern sowohl Point3D als auch Point2D sind von einer gemeinsamen abstrakten Oberklasse Point abgeleitet. Dieser Unterschied hat nichts mit
binären Methoden zu tun, sondern verdeutlicht, dass Point3D in der Regel keine Spezialisierung von Point2D ist. Die Rolle, die bisher Point2D hatte, spielt
jetzt Point. Die Methode equal ist in Point definiert und kann in Unterklassen
nicht überschrieben werden. Wenn die beiden zu vergleichenden Punkte genau
den gleichen Typ haben, wird in der betreffenden Unterklasse von Point die Methode uncheckedEqual aufgerufen, die den eigentlichen Vergleich durchführt.
Im Unterschied zur in Abschnitt 4.3.1 angerissenen Lösung vergleicht diese Lösung, ob die Typen wirklich gleich sind, nicht nur, ob der dynamische Typ des
Arguments ein Untertyp der Klasse ist, in der die Methode ausgeführt wird.
Die Lösung in Abschnitt 4.3.1 ist falsch, da ein Aufruf von equal in Point2D
mit einem Argument vom Typ Point3D als Ergebnis true liefern kann.
Für Interessierte, nicht Prüfungsstoff. Die Programmiersprache Ada unterstützt binäre Methoden direkt: Alle Parameter, die denselben Typ wie das Äquivalent
zu this in Java haben, werden beim Überschreiben auf die gleiche Weise kovariant
verändert. Wenn mehrere Parameter denselben überschriebenen Typ haben, handelt
es sich um binäre Methoden. Eine Regel in Ada besagt, dass alle Argumente, die
für diese Parameter eingesetzt werden, genau den gleichen dynamischen Typ haben
müssen. Das wird zur Laufzeit überprüft. Schlägt die Überprüfung fehl, wird eine
Ausnahme ausgelöst. Methoden wie equal in obigem Beispiel sind damit sehr einfach programmierbar. Falls die zu vergleichenden Objekte unterschiedliche Typen
haben, tritt eine Ausnahme auf, die an geeigneten Stellen abgefangen werden kann.
Ende des Einschubs für Interessierte
4.4 Überladene Methoden und Multimethoden
Dynamisches Binden erfolgt in Java (wie in vielen anderen objektorientierten
Programmiersprachen auch) über den dynamischen Typ eines speziellen Parameters. Beispielsweise wird die auszuführende Methode in x.equal(y) durch
den dynamischen Typ von x festgelegt. Der dynamische Typ von y ist für die
Methodenauswahl irrelevant. Aber der deklarierte Typ von y ist bei der Methodenauswahl relevant, wenn equal überladen ist. Bereits der Compiler kann
anhand des deklarierten Typs von y auswählen, welche der überladenen Methoden auszuführen ist. Der dynamische Typ von y ist dafür unerheblich.
206
4.4 Überladene Methoden und Multimethoden
Generell, aber nicht in Java, ist es möglich, dass dynamisches Binden auch
den dynamischen Typ von y in die Methodenauswahl einbezieht. Dann legt
nicht bereits der Compiler anhand des deklarierten Typs fest, welche überladene Methode auszuwählen ist, sondern erst zur Laufzeit des Programms wird die
auszuführende Methode durch die dynamischen Typen von x und y bestimmt.
In diesem Fall sprechen wir nicht von Überladen, sondern von Multimethoden [9]; es wird bei einem Methodenaufruf mehrfach dynamisch gebunden.
Leider wird Überladen viel zu oft mit Multimethoden verwechselt. Das führt
zu schweren Fehlern. In Abschnitt 4.4.1 werden wir uns die Unterschiede deshalb deutlich vor Augen führen. In Abschnitt 4.4.2 werden wir sehen, dass
Multimethoden auch in Sprachen wie Java recht einfach simulierbar sind.
4.4.1 Deklarierte versus dynamische Argumenttypen
Folgendes Beispiel soll verdeutlichen, dass bei der Auswahl zwischen überladenen Methoden nur der deklarierte Typ eines Arguments entscheidend ist, nicht
der dynamische. Wir verwenden das Beispiel zu kovarianten Problemen aus
Abschnitt 4.3.3:
Cow cow = new Cow();
Food grass = new Grass();
cow.eat(grass); // Cow.eat(Food x)
cow.eat((Grass)grass); // Cow.eat(Grass x)
Wegen dynamischem Binden wird eat auf jeden Fall in der Klasse Cow ausgeführt. Der Methodenaufruf in der dritten Zeile führt die überladene Methode
mit dem Parameter vom Typ Food aus, da grass mit dem Typ Food deklariert
ist. Für die Methodenauswahl ist es unerheblich, dass grass tatsächlich ein
Objekt von Grass enthält; der dynamische Typ von grass ist Grass, da grass
direkt vor dem Methodenaufruf mit einem Objekt von Grass initialisiert wird.
Es zählt aber nur der deklarierte Typ. Der Methodenaufruf in der vierten Zeile
führt die überladene Methode mit dem Parameter vom Typ Grass aus, weil der
deklarierte Typ von grass wegen der Typumwandlung an dieser Stelle Grass
ist. Typumwandlungen ändern ja den deklarierten Typ eines Ausdrucks.
Häufig ist bekannt, dass grass ein Objekt von Grass enthält und nimmt
an, dass sowieso die Methode mit dem Parameter vom Typ Grass gewählt
wird. Diese Annahme ist falsch! Es wird stets der deklarierte Typ verwendet,
unabhängig davon, ob wir den dynamischen Typ kennen. Der Compiler darf
nur den deklarierten Typ verwenden, sogar wenn er einen spezifischeren Typ
als statischen Typ kennt.
Nehmen wir an, die erste Zeile des Beispiels sehe so aus:
Animal cow = new Cow();
Wegen dynamischen Bindens würde eat weiterhin in Cow ausgeführt. Aber zur
Auswahl überladener Methoden kann der Compiler nur deklarierte Typen verwenden. Das gilt auch für den Empfänger einer Nachricht. Die überladenen
207
4 Dynamische Typinformation und statische Parametrisierung
Methoden werden in Animal gesucht, nicht in Cow. In Animal ist eat nicht
überladen, sondern es gibt nur eine Methode mit einem Parameter vom Typ
Food. Daher wird in Cow auf jeden Fall die Methode mit dem Parameter vom
Typ Food ausgeführt, unabhängig davon, ob der deklarierte Typ des Arguments
Food oder (nach einem Cast) Grass ist. Wie das Beispiel zeigt, kann sich die
Auswahl zwischen überladenen Methoden stark von der Intuition unterscheiden
und ist von vielen Details abhängig. Daher ist besondere Vorsicht geboten.
Die Methoden eat in Cow und Tiger sind so überladen, dass es (außer für
die Laufzeiteffizienz) keine Rolle spielt, welche der überladenen Methoden aufgerufen wird. Wenn der dynamische Typ des Arguments Grass ist, wird im
Endeffekt immer die Methode mit dem Parametertyp Grass aufgerufen. Es ist
empfehlenswert, Überladen nur so zu verwenden.
Faustregel: Wir sollen Überladen nur so verwenden, dass es keine
Rolle spielt, ob bei der Methodenauswahl deklarierte oder dynamische Typen der Argumente verwendet werden.
Unter folgender Bedingung ist die strikte Unterscheidung zwischen deklarierten
und dynamischen Typen bei der Methodenauswahl nicht wichtig, das Überladen von Methoden also sicher: Für je zwei überladene Methoden gleicher
Parameterzahl
• gibt es zumindest eine Parameterposition, an der sich die Parametertypen
unterscheiden, wobei diese Typen nicht in Untertyprelation zueinander
stehen und auch keinen gemeinsamen Untertyp haben,
• oder alle Parametertypen der einen Methode sind Obertypen der Parametertypen der anderen Methode, und bei Aufruf der einen Methode wird
nichts anderes gemacht, als auf die andere Methode zu verzweigen, falls
die entsprechenden dynamischen Typen der Argumente dies erlauben.
Das Problem der Verwechslung von dynamischen und deklarierten Typen
könnte nachhaltig gelöst werden, indem zur Methodenauswahl generell die dynamischen Typen aller Argumente verwendet würden. Statt überladener Methoden hätten wir dann Multimethoden. Würde Java Multimethoden unterstützen, könnten wir die Klasse Cow im Beispiel aus Abschnitt 4.3.3 kürzer und
ohne dynamische Typabfragen und -umwandlungen schreiben:
class Cow extends Animal {
public void eat(Grass x) { ... }
public void eat(Food x) {
fallIll();
}
} // Achtung: In Java ist diese Lösung falsch !!
Die Abfrage, ob x den dynamischen Typ Grass hat, hätten wir uns erspart, da
eat mit dem Parametertyp Food bei Multimethoden nur aufgerufen wird, wenn
der dynamische Argumenttyp nicht Grass ist.
208
4.4 Überladene Methoden und Multimethoden
Als Grund für die fehlende Unterstützung von Multimethoden in vielen heute
üblichen Programmiersprachen wird häufig die höhere Komplexität der Methodenauswahl genannt. Der dynamische Typ der Argumente muss ja zur Laufzeit
in die Methodenauswahl einbezogen werden. Im Beispiel mit der Multimethode eat ist jedoch, wie in vielen Fällen, in denen Multimethoden sinnvoll sind,
kein zusätzlicher Aufwand nötig; eine dynamische Typabfrage auf dem Argument ist immer nötig, wenn der statische Typ kein Untertyp von Grass ist.
Die Multimethodenvariante von eat kann sogar effizienter sein als die Variante
mit Überladen, wenn der statische Typ des Arguments ein Untertyp von Grass
ist, nicht jedoch der deklarierte Typ. Die Laufzeiteffizienz ist daher kaum ein
Grund für fehlende Multimethoden in einer Programmiersprache.
Unter der Komplexität der Methodenauswahl verstehen wir nicht nur die
Laufzeiteffizienz: Für Menschen ist nicht gleich erkennbar, unter welchen Bedingungen welche Methode ausgeführt wird. Eine Regel besagt, dass immer
jene Methode mit den speziellsten Parametertypen, die mit den dynamischen
Typen der Argumente kompatibel sind, auszuführen ist. Wenn wir eat mit einem Argument vom Typ Grass (oder einem Untertyp davon) aufrufen, sind
die Parametertypen beider Methoden mit dem Argumenttyp kompatibel. Da
Grass spezieller ist als Food, wird die Methode mit dem Parametertyp Grass
ausgeführt. Diese Regel ist für die Methodenauswahl aber nicht hinreichend
wenn Multimethoden mehrere Parameter haben, wie folgendes Beispiel zeigt:
public void eatTwice(Food x, Grass y) { ... }
public void eatTwice(Grass x, Food y) { ... }
Mit einem Aufruf von eatTwice mit zwei Argumenten vom Typ Grass sind
beide Methoden kompatibel. Aber keine Methode ist spezieller als die andere.
Es gibt verschiedene Möglichkeiten, mit solchen Mehrdeutigkeiten umzugehen.
Eine Möglichkeit besteht darin, die erste passende Methode zu wählen; das wäre die Methode in der ersten Zeile. Es ist auch möglich, die Übereinstimmung
zwischen Parametertyp und Argumenttyp für jede Parameterposition getrennt
zu prüfen, und dabei von links nach rechts jeweils die Methode mit den spezielleren Parametertypen zu wählen; das wäre die Methode in der zweiten Zeile.
CLOS (Common Lisp Object System [19]) bietet zahlreiche weitere Auswahlmöglichkeiten. Keine dieser Möglichkeiten bietet klare Vorteile gegenüber den
anderen. Daher scheint eine weitere Variante günstig zu sein: Der Compiler
verlangt, dass es immer genau eine eindeutige speziellste Methode gibt. Wir
müssen eine zusätzliche Methode
public void eatTwice(Grass x, Grass y) { ... }
hinzufügen, die das Auswahlproblem beseitigt. Dieses Beispiel soll klar machen, dass Multimethoden für den Compiler und beim Programmieren eine
höhere Komplexität haben als überladene Methoden. In üblichen Anwendungsbeispielen haben Multimethoden aber keine höhere Komplexität als überladene
Methoden. Die Frage, ob Multimethoden in der Gesamtbetrachtung günstiger
sind als überladene Methoden, bleibt offen.
209
4 Dynamische Typinformation und statische Parametrisierung
In Java kommt es zu Fehlern, wenn wir unbewusst Überladen statt Überschreiben verwenden, wenn wir also eine Methode überschreiben wollen, die
Methode im Untertyp sich aber in den Parametertypen von der Methode im
Obertyp unterscheidet. Abhilfe schafft nur spezielle Achtsamkeit und die konsequente Verwendung von @Override-Annotationen. Nur Ergebnistypen dürfen ab Java 1.5 kovariant verschieden sein. Es sei darauf hingewiesen, dass das
Überladen von Methoden nicht mit Vererbung zusammenhängt; überladene Methoden können auch direkt in nur einer einzigen Klasse eingeführt werden.
4.4.2 Simulation von Multimethoden
Multimethoden verwenden mehrfaches dynamisches Binden: Die auszuführende
Methode wird dynamisch durch die Typen mehrerer Argumente bestimmt. In
Java gibt es nur einfaches dynamisches Binden. Trotzdem können wir mehrfaches dynamisches Binden durch wiederholtes einfaches Binden simulieren. Wir
nutzen mehrfaches dynamisches Binden für das Beispiel aus Abschnitt 4.3.3
und eliminieren damit dynamische Typabfragen und Typumwandlungen:
public abstract class Animal {
public abstract void eat(Food food);
}
public class Cow extends Animal {
public void eat(Food food) { food.eatenByCow(this); }
}
public class Tiger extends Animal {
public void eat(Food food) { food.eatenByTiger(this); }
}
public abstract class Food {
abstract void eatenByCow(Cow cow);
abstract void eatenByTiger(Tiger tiger);
}
public class Grass extends Food {
void eatenByCow(Cow cow) { ... }
void eatenByTiger(Tiger tiger) { tiger.showTeeth(); }
}
public class Meat extends Food {
void eatenByCow(Cow cow) { cow.fallIll(); }
void eatenByTiger(Tiger tiger) { ... }
}
Die Methoden eat in Cow und Tiger rufen Methoden in Food auf, die die eigentlichen Aufgaben durchführen. Hier nehmen wir an, dass alle diese Klassen
im selben Paket liegen, sodass Default-Sichtbarkeit für die zusätzlichen Methoden reicht. Scheinbar verlagern wir die Arbeit nur von den Tieren zu den
Futterarten. Dabei passiert aber etwas Wesentliches: In Grass und Meat gibt
es nicht nur eine entsprechende Methode, sondern je eine für Objekte von Cow
und Tiger. Bei einem Aufruf von animal.eat(food) wird zweimal dynamisch
210
4.4 Überladene Methoden und Multimethoden
gebunden. Das erste dynamische Binden unterscheidet zwischen Objekten von
Cow und Tiger und spiegelt sich im Aufruf von eatenByCow und eatenByTiger
wider. Ein zweites dynamisches Binden unterscheidet zwischen Objekten von
Grass und Meat. In den Unterklassen von Food sind insgesamt vier Methoden
implementiert, die alle Kombinationen von Tierarten mit Futterarten abdecken.
Statt eatenByCow und eatenByTiger hätten wir auch einen gemeinsamen
Namen wählen können (= Überladen), da sich die Typen der formalen Parameter eindeutig unterscheiden (keine gemeinsamen Untertypen).
Stellen wir uns vor, diese Lösung sei dadurch zustandegekommen, dass wir eine ursprüngliche Lösung mit Multimethoden in Java implementiert und dabei
für den formalen Parameter einen zusätzlichen Schritt dynamischen Bindens
eingeführt hätten. Damit wird klar, wie mehrfaches dynamisches Binden durch
wiederholtes einfaches dynamisches Binden ersetzbar ist. Bei Multimethoden
mit mehreren Parametern muss entsprechend oft dynamisch gebunden werden.
Sobald wir den Übersetzungsschritt verstanden haben, können wir ihn ohne
intellektuelle Anstrengung, aber mit viel Schreibaufwand, für vielfaches dynamisches Binden durchführen.
Diese Lösung kann auch dadurch erzeugt worden sein, dass in der ursprünglichen Lösung aus Abschnitt 4.3.3 if-Anweisungen mit dynamischen Typabfragen durch dynamisches Binden ersetzt wurden. Nebenbei sind auch die Typumwandlungen verschwunden. Auch diese Umformung ist automatisch durchführbar. Wir haben damit die Möglichkeit, dynamische Typabfragen genauso
wie Multimethoden aus Programmen zu entfernen und damit die Struktur des
Programms zu verbessern.
Mehrfaches dynamisches Binden wird in der Praxis benötigt. Die Lösung wie
im Beispiel entspricht dem Visitor-Pattern, einem klassischen Entwurfsmuster
– siehe Kapitel 6. Klassen wie Food nennen wir Visitorklassen, die darin enthaltenen Methoden wie eatenByCow sind Visitormethoden. Klassen wie Animal
heißen Elementklassen. Visitor- und Elementklassen sind oft gegeneinander austauschbar. Z. B. könnten die eigentlichen Implementierungen (Visitormethoden)
in den Tier-Klassen stehen, die in den Futter-Klassen aufgerufen werden.
Das Visitor-Pattern hat einen bedeutenden Nachteil: Die Anzahl der benötigten Methoden wird schnell sehr groß. Nehmen wir an, wir hätten m unterschiedliche Tierarten und n Futterarten. Zusätzlich zu den m Methoden in den Elementklassen werden m·n Visitormethoden benötigt. Noch rascher steigt die Methodenanzahl mit der Anzahl der dynamischen Bindungen. Bei k ≥ 2 dynamischen Bindungen mit ni Möglichkeiten für die i-te Bindung (i = 1 . . . k) werden
n1 ·n2 · · · nk inhaltliche Methoden und zusätzlich n1+n1 ·n2+· · ·+n1 ·n2 · · · nk−1
Methoden für die Verteilung benötigt, also sehr viele. (Wir vermeiden hier die
Begriffe Element- bzw. Visitormethode, da die Klassenhierarchien mit den Indizes i = 2 . . . k − 1 gleichzeitig Element- und Visitorklassen sind.) Für k = 4
und n1, . . . , n4 = 10 kommen wir auf 11.110 Methoden. Außer für sehr kleine
k und kleine ni
ist diese Technik nicht sinnvoll einsetzbar. Vererbung kann die
Zahl der nötigen Methoden meist nur unwesentlich verringern.
Die Anzahl der Methoden lässt sich manchmal durch kreative Ansätze deutlich reduzieren. Am erfolgversprechendsten sind Lösungen, welche die Anzahl
211
4 Dynamische Typinformation und statische Parametrisierung
der Klassen ni klein halten. Beispielsweise müssen wir nicht immer zwischen
allen möglichen Tier- und Futterarten unterscheiden, sondern kann Klassen
für Gruppen mit gemeinsamen Eigenschaften bilden. Das ist vor allem dann
leicht möglich, wenn nicht gleichzeitig auf alle Details der Tier- und Futterarten zugegriffen werden muss. So könnten wir statt eatenByCow eine Methode eatenByVegetarian schreiben, die nicht nur für Rinder, sondern auch für
Kaninchen und Elefanten verwendbar ist. Es muss auch nicht nur das VisitorPattern alleine sein. Oft hilft eine einfache Beschreibung der Rolle eines Objekts:
Dabei enthält jedes Tier oder jede Tierart eine Variable mit einer Referenz auf
eines von ganz wenigen Objekten zur Beschreibung der erlaubten Futterarten.
Wir können das verfügbare Futter an eine Methode in diesem Objekt weiterleiten, wo das Futter mit der erlaubten Futterart (zwar wieder über mehrfaches
dynamisches Binden, aber mit kleinem ni) verglichen wird.
4.5 Annotationen und Reflexion
Die Idee hinter Annotationen ist einfach: Unterschiedliche Programmteile werden mit Markierungen (die wir Annotationen nennen) versehen und das Laufzeitsystem sowie Entwicklungswerkzeuge prüfen das Vorhandensein bestimmter
Markierungen und reagieren darauf entsprechend. Ohne explizite Überprüfungen haben Annotationen keinerlei Auswirkungen auf die Programmsemantik; sie
werden einfach ignoriert. So einfach dieses Konzept zu sein scheint, so komplex
sind Details der Umsetzung. Einerseits sollte das Hinzufügen von Annotationen
zu Java die Syntax nicht allzu sehr ändern und trotzdem aus der Syntax klar
hervorgehen, dass es sich um möglicherweise ignorierte Programmteile handelt.
Andererseits muss es möglich sein, zur Laufzeit das Vorhandensein von Annotationen abzufragen. Dafür wird Reflexion eingesetzt. In Abschnitt 4.5.1 untersuchen wir, wie diese Details in Java gelöst wurden, und in Abschnitt 4.5.2
betrachten wir Anwendungsbeispiele.
4.5.1 Annotationen und Reflexion in Java
Syntax. Zur klaren Unterscheidung von anderen Sprachkonstrukten beginnt
jede Annotation in Java mit dem Zeichen „@“. Sie steht unmittelbar vor dem
Programmteil, auf den sie sich bezieht. Beispielsweise können wir die Annotation @Override vor eine Methodendefinition schreiben. Der Compiler prüft, ob
die Methodendefinition mit dieser Annotation versehen ist und verlangt nur in
diesem Fall, dass die Methode eine andere Methode überschreibt. Ein Compiler, der @Override nicht versteht, könnte diese Überprüfung theoretisch auch
weglassen. Aber praktisch jeder Compiler versteht @Override, da es sich dabei
um eine vom System vorgegebene Annotation handelt. Wir können auch eigene
Annotationen erfinden. Außerdem können Annotationen Argumente enthalten.
Eigene Annotationen müssen deklariert werden, bevor sie verwendbar sind.
Dafür wurde die Syntax von Interface-Definitionen übernommen und abgewandelt. Hier ist ein Beispiel für die Definition einer etwas komplexeren Annotation:
212
4.5 Annotationen und Reflexion
@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.TYPE})
public @interface BugFix {
String who(); // author of bug fix
String date(); // when was bug fixed
int level(); // importance level 1-5
String bug(); // description of bug
String fix(); // description of fix
}
Solche Annotationen können wir zu Klassen, Interfaces und Enums hinzufügen
um auf Korrekturen hinzuweisen. Das könnte so aussehen:
@BugFix(who="Kaspar", date="1.10.2023", level=3,
bug="class unnecessary and maybe harmful",
fix="content of class body removed")
public class Buggy { }
Die Einträge in der Definition der Annotation beschreiben Datenfelder, die in
der Annotation gesetzt werden. Auch wenn diese Einträge syntaktisch wie Methodendeklarationen aussehen, gibt es doch deutliche Unterschiede zu normalen
Methoden. Die Parameterlisten müssen leer sein und die erlaubten Ergebnistypen sind stark eingeschränkt: Nur elementare Typen (wie int), Enum-Typen,
String, Class und andere Annotationen sowie eindimensionale Arrays dieser
Typen sind erlaubt. Wie im Beispiel wird häufig String verwendet.
Die Definition von BugFix ist selbst mit zwei Annotationen versehen. An
ihnen fällt auf, dass die Argumente in den runden Klammern nicht die Form
name=wert haben, sondern nur einfache Werte darstellen. Der Name des Arguments kann weggelassen werden wenn die Annotation nur ein Argument namens
value hat. Ebenso können die runden Klammern weggelassen werden, wenn
die Annotation keine Argumente hat, etwa bei @Override. Das Argument von
@Target ist ein Array, die geschwungenen Klammern stellen also ein simples
Aggregat zur Initialisierung eines (in diesem Fall einelementigen) Arrays dar.
Bei einelementigen Arrays können wir die geschwungenen Klammern weglassen.
Annotationen auf der Definition von Annotationen haben folgende Bedeutungen: Das Argument von @Target legt fest, was annotiert werden kann. Es
ist ein Array von Werten des Enums ElementType mit Werten wie METHOD,
TYPE, PARAMETER, CONSTRUCTOR und so weiter; siehe die Schnittstellenbeschreibung von ElementType. Die gerade definierte Annotation kann an alle Sprachelemente angeheftet werden, die im Array vorkommen. Ohne @Target ist die
gerade definierte Annotation überall anheftbar.
@Retention legt fest, wie weit die gerade definierte Annotation sichtbar bleiben soll. Mit dem Wert SOURCE der Enum RetentionPolicy wird die Annotation vom Compiler genau so verworfen wie Kommentare. Solche Annotationen
sind nur für Werkzeuge, die auf dem Source-Code operieren, von Interesse. Der
Wert CLASS sorgt dafür, dass die Annotation in der übersetzten Klasse vorhanden bleibt, aber während der Programmausführung nicht mehr sichtbar ist. Das
213
4 Dynamische Typinformation und statische Parametrisierung
ist nützlich für Werkzeuge, die auf dem Byte-Code operieren. Schließlich sorgt
der Wert RUNTIME dafür, dass die Annotation auch zur Laufzeit zugreifbar ist.
Zusätzlich wären in der Definition einer Annotation die parameterlosen Annotationen @Documented und @Inherited verwendbar. Erstere sorgt dafür, dass
die Annotation in der generierten Dokumentation vorkommt, letztere dafür,
dass das annotierte Element auch in einem Untertyp als annotiert gilt.
Wir können Default-Belegungen für Parameter von Annotationen angeben.
Beispielsweise wird die Definition von BugFix um folgende Zeile (innerhalb der
geschwungenen Klammern) erweitert:
String comment() default "";
Aufgrund der Default-Belegung müssen wir bei der Verwendung kein Argument
für comment angeben. Das ist besonders sinnvoll, wenn die Zeile erst später hinzugefügt wird, also @BugFix schon vorher verwendet wurde. Schon existierende
Verwendungen können wir wegen der Default-Belegung unverändert lassen.
Verwendung zur Laufzeit. Wurde durch @Retention(RUNTIME) bestimmt,
dass eine Annotation auch zur Laufzeit zugreifbar ist, dann generiert der Compiler ein entsprechendes Interface. Dieses sieht für obiges Beispiel so aus:
public interface BugFix extends Annotation {
String who();
String date();
int level();
String bug();
String fix();
}
Wir können wie in folgendem Code-Stück auf die Annotation zugreifen:
String s = "";
BugFix a = Buggy.class.getAnnotation(BugFix.class);
if (a != null) { // null if no such annotation
s += a.who() + " fixed a level " + a.level() + " bug";
}
Die Basis für Zugriffe ist die Klasse Buggy. So wie getClass die interne Darstellung der Klasse eines Objekts als Objekt von Class ermittelt, so enthält
die Pseudovariable class jeder Klasse das entsprechende Objekt der Klasse
Class. Dieses Objekt versteht die Nachricht getAnnotation mit einem Argument, das den Typ der Annotation beschreibt. Obwohl BugFix ein Interface ist,
gibt BugFix.class ein Objekt von Class, genauer Class<BugFix> zurück, welches das Interface beschreibt. Die zweite Zeile im Code-Stück liefert das Objekt
von BugFix, mit dem die Klasse Buggy annotiert ist (oder null falls es keine
solche Annotation gibt). Auf die einzelnen in BugFix beschriebenen Methoden
wird ganz normal zugegriffen, um die Datenfelder der Annotation auszulesen.
214
4.5 Annotationen und Reflexion
Obiges Code-Stück ist nur sinnvoll verwendbar, wenn wir genau wissen, auf
welche Annotation wir zugreifen möchten. Durch getAnnotations können wir
alle Annotationen der Klasse gleichzeitig auslesen, ohne deren Typen zu kennen:
Annotation[] as = Buggy.class.getAnnotations();
for (Annotation a : as) {
if (a instanceof BugFix)
String s = ((BugFix)a).who; ...
}
Aber mit dem so erzeugten Array von Annotationen können wir meist nur dann
weiterarbeiten, wenn wir wissen, welche Annotationen wir haben möchten. Auf
die Datenfelder können wir ja nur zugreifen, wenn wir vorher einen Cast auf
den richtigen Typ der Annotation machen.
Die Technik, mit der wir zur Laufzeit auf Annotationen zugreifen, nennt sich
Reflexion bzw. Reflection oder Introspektion. Reflexion erlaubt uns, zur Laufzeit auf viele Details eines Programms zuzugreifen. Ausgangspunkt ist meist ein
Objekt vom Typ Class. Class implementiert eine Reihe von Methoden, mit denen sich die Details der Klasse ansehen lassen. So wie wir über getAnnotation
und getAnnotations Informationen über Annotationen bekommt, können wir
uns über getMethod und getMethods Informationen über Methoden und über
getField und getFields Informationen über Objekt- und Klassenvariablen
holen. Ähnliches gilt für Konstruktoren, Oberklassen, das Paket und so weiter.
Weitere Methoden erlauben beispielsweise die Erzeugung neuer Objekte der
Klasse oder fragen den Namen der Klasse ab.
Informationen über Methoden sind in Objekten des Typs Method enthalten
(die wir etwa durch getMethods über ein Objekt von Class bekommen). Wie
Class bietet Method Methoden an, um Annotationen und viel anderes Nützliches abzufragen. Wir können etwa die Typen der formalen Parameter und des
Ergebnisses sowie Annotationen auf den formalen Parametern abfragen. Über
invoke können wir die Methode auch aufrufen. Dabei müssen wir den Empfänger der Nachricht und passende Argumente bereitstellen. Wenn der Empfänger
oder ein Argument einen unpassenden Typ hat, oder wenn der Aufruf der Methode wegen eingeschränkter Sichtbarkeit nicht erlaubt ist, wird eine Ausnahme ausgelöst. Abgesehen davon, dass die Überprüfungen, die üblicherweise der
Compiler macht, erst zur Laufzeit passieren, hat ein solcher Aufruf die gleiche
Semantik wie ein normaler Methodenaufruf. Es wird auch dynamisch gebunden.
Ähnliches gilt für Informationen über Variablen in Objekten des Typs Field.
Wir können über Reflexion die Werte sichtbarer Variablen lesen und schreiben
und natürlich auch Annotationen abfragen.
Reflexion ist in der Programmierung eine äußerst mächtige Technik. Wir
können damit sehr flexibel fast alles zur Laufzeit entscheiden, was üblicherweise
schon vor dem Compilieren festgelegt werden muss; nur das Ändern von Klassen
zur Laufzeit ist in Java verboten. Genau in dieser Flexibilität liegt jedoch die
größte Gefahr der Reflexion. Das Programm wird gänzlich undurchschaubar
und kaum wartbar, wenn wir diese Freiheit auf unkontrollierte Weise nutzen.
215
4 Dynamische Typinformation und statische Parametrisierung
4.5.2 Anwendungen von Annotationen und Reflexion
Übliche Annotationen. So wie bei vielen anderen komplexeren Sprachkonzepten verhält es sich auch mit Annotationen: Sie liefern einen wesentlichen Beitrag
und sind daher heute unverzichtbar, gleichzeitig verwenden wir sie in der Praxis
(wenn überhaupt) meist nur in ihren einfachsten Formen. Der unverzichtbare
Beitrag besteht darin, dass Annotationen zusätzliche syntaktische Elemente in
Programmen erlauben, ohne dafür die Programmiersprache ändern zu müssen.
Gerade für vielseitig und in großem Umfang eingesetzte Sprachen wie Java sind
Änderungen der Syntax kaum durchsetzbar. Das gilt vor allem für Änderungen,
die nur wenige Einsatzgebiete betreffen. Annotationen ermöglichen syntaktische
Erweiterungen auch für ganz spezielle Einsatzgebiete, ohne gleichzeitig andere
Einsatzgebiete mit unnötiger Syntax zu überladen. Beim Schreiben von Programmen außerhalb dieser speziellen Gebiete werden wir kaum etwas von der
Existenz entsprechender Annotationen mitbekommen.
Häufig verwenden wir @Override. Statt dieser Annotation wäre auch ein Modifier sinnvoll gewesen, aber aufgrund der geschichtlichen Entwicklung hat sich
eine Annotation angeboten. Wir können jede Annotation als Modifier sehen,
den ein (Pre-)Compiler oder das Laufzeitsystem versteht.
Manchmal stolpern wir über eine @Deprecated-Annotation, mit der Programmelemente gekennzeichnet werden, die wir nicht mehr verwenden sollten.
Eigentlich stellt sie nur eine Form von Kommentar dar. Die Annotation ermöglicht jedoch, dass ein Compiler bei Verwendung dieser Programmelemente eine
Warnung ausgibt.
Eine gefährliche Rolle spielt @SuppressWarnings. Diese Annotation weist den
Compiler an, alle Warnungen zu unterdrücken, die im Argument durch Zeichenketten beschrieben sind. Auch wenn manche Warnung lästig ist, sollten wir von
der Verwendung solcher Annotationen Abstand nehmen. Warnungen haben ja
einen Grund, den wir nicht vernachlässigen sollten. Es kommt gar nicht so selten
vor, dass wir eine solche Annotation „vorübergehend“ in den Code schreiben,
weil wir uns erst später um ein Problem kümmern möchten und dann darauf
vergessen. Auch wenn wir genau wissen, dass sich ein Compiler mit einer Warnung irrt, kann das Abdrehen dieser Warnung die Fehlersuche erschweren, etwa
nach einer Programmänderung. Ein weiterer Grund ist fehlende Portabilität:
Unterschiedliche Compiler verwenden unterschiedliche Zeichenketten zur Beschreibung von Warnungen, sodass manche Compiler durch die Annotationen
eigenartige Warnungen generieren können.
Mit der Annotation @FunctionalInterface können seit Java 8 Interfaces
gekennzeichnet werden, die genau eine abstrakte Methode enthalten. Solche
Interfaces sind als Typen von Lambda-Ausdrücken verwendbar,3 wobei die abstrakte Methode beschreibt, wie die entsprechende Funktion aufzurufen ist.
Beispielsweise haben wir in Abschnitt 2.3.2 den Typ ToIntFunction<Point>
3Lambda-Ausdrücke können auch Interfaces mit nur einer abstrakten Methode als Typ haben, die nicht mit der Annotation @FunctionalInterface versehen sind. Die Annotation
macht nur darauf Aufmerksam, dass das Interface für diesen Einsatzzweck konzipiert wurde und auch in Zukunft für solche Verwendungen zur Verfügung stehen wird.
216
4.5 Annotationen und Reflexion
verwendet, wobei das Interface als @FunctionalInterface gekennzeichnet ist.
Es enthält (nach Übersetzung der Generizität) nur eine abstrakte Methode
int applyAsInt(Point value);
wodurch Lambda-Ausdrücke dieses Typs durch applyAsInt(...) aufrufbar
sind. Die Annotation verhindert, dass das Interface später um zusätzliche abstrakte Methoden erweitert wird. Methoden mit Default-Implementierungen
dürfen jedoch zusätzlich vorhanden sein oder später hinzugefügt werden, ohne
die Aussage der Annotation zu verletzen.
Reflexion. Reflexion ist eine Variante der Metaprogrammierung (siehe Abschnitt 1.5.3), einer schon sehr alten Programmiertechnik, mit der es viel Erfahrung gibt. Während durch Metaprogrammierung das gesamte Programm zur
Laufzeit sicht- und änderbar ist, kann Reflexion die Programmstruktur nicht
ändern. Es ist bekannt, dass mit diesen Techniken in speziellen Fällen sehr
viel erreichbar ist. Aber auch die Gefahren sind bekannt. Daher versuchen wir
meist, solche Techniken in der tagtäglichen Programmierung zu vermeiden und
greifen nur darauf zurück, wenn wir keine einfachere Lösung finden.
Hier ist ein einfaches Beispiel für den Einsatz von Reflexion:
static void execAll(String n, Object... objs) {
for (Object o : objs) {
try { o.getClass().getMethod(n).invoke(o); }
catch(Exception ex) {...}
}
}
In den als Parameter übergebenen Objekten wird jeweils eine parameterlose Methode aufgerufen, die einen ebenfalls als Parameter übergebenen Namen hat.
Dieser Name kann genauso wie die Objekte zur Laufzeit bestimmt werden. Auf
den ersten Blick geht das ganz einfach. Bei genauerem Hinsehen fällt auf, dass
bei den Aufrufen einiges passieren kann, mit dem wir vielleicht nicht rechnen –
ganz zu schweigen von der Gefahr, dass wir nicht wissen, was die mit invoke
aufgerufenen Methoden machen (möglicherweise Daten weiterleiten bzw. zerstören oder jemandem Zugang zum System verschaffen). Möglicherweise ist die
Methode nicht public, verlangt (andere) Argumente, oder existiert gar nicht.
In diesen Fällen werden Ausnahmen ausgelöst, mit denen wir umgehen müssen.
Wie das Beispiel zeigt, ist die Verwendung der Reflexion im Grunde sehr
einfach. Schwierigkeiten verursacht nur das ganze Rundherum, z. B. der notwendige Umgang mit vielen Sonderfällen, die in der normalen Programmierung
vom Compiler ausgeschlossen werden. Die Gefahr kommt hauptsächlich daher, dass wir keinerlei Verhaltensbeschreibungen der mit invoke aufgerufenen
Methoden haben. Wir haben nicht einmal intuitive Vorstellungen davon. Bei
entsprechender Organisation könnten wir alle diese Probleme lösen. Aber die
Erfahrung zeigt, dass die reflexive Programmierung dennoch gefährlich ist und
zu Wartungsproblemen führt.
217
4 Dynamische Typinformation und statische Parametrisierung
Ein Spezialbereich. Wir betrachten nun JavaBeans-Komponenten als Beispiel für den Einsatz von Reflexion und Annotationen. JavaBeans ist ein Werkzeug, mit dem grafische Benutzeroberflächen ganz einfach aus Komponenten
aufgebaut werden. Der Großteil der Arbeit wird von Werkzeugen bzw. fertigen Klassen erledigt. JavaBeans-Komponenten sind gewöhnliche Klassen, die
bestimmte Namenskonventionen einhalten.
Ein JavaBeans-Konzept sind „Properties“ – Objektvariablen, deren Werte
von außen zugreifbar sind. Properties führen wir ein, indem wir Getter und
Setter für die Objektvariablen schreiben. Existieren z. B. die Methoden
public void setProp(int x) { ... }
public int getProp() { ... }
nehmen die Werkzeuge automatisch an, dass prop eine Property des Typs int
ist. Existiert nur eine dieser Methoden, ist die Property nur les- oder schreibbar. Lesbare Properties des Typs boolean können statt mit get auch mit is
beginnen. Die grafische Benutzeroberfläche eines Werkzeugs erlaubt über Menüs
simple Zugriffe auf Properties. Dabei findet und verwendet es Properties über
Reflexion. Fast alle nötige Information steckt in den Namen, Ergebnistypen
und Parametertypen der Methoden. Zum Auffinden komplexerer Konzepte wie
„Events“ wird ähnlich vorgegangen.
Bezüglich dieser Vorgehensweise von JavaBeans-Komponenten scheiden sich
die Geister. Einerseits können solche Werkzeuge die Entwicklung grafischer Benutzeroberflächen deutlich vereinfachen. Andererseits ist ein Programmierstil,
der hauptsächlich auf Gettern und Settern aufbaut, vielleicht in der prozeduralen Programmierung akzeptabel, in der objektorientierten Programmierung
aber nicht. Entsprechend propagieren Vertreter des Einsatzes von Werkzeugen
wie JavaBeans die Verwendung von Gettern und Settern, die sich genau an die
vom Werkzeug vorgegebenen Namenskonventionen halten, während Vertreter
eines fortgeschritteneren objektorientierten Stils Getter und Setter so gut wie
möglich meiden und (sollten sie sich nicht ganz vermeiden lassen) bewusst nicht
an solche Namenskonventionen halten.
In seltenen Fällen benötigen JavaBeans Information, die nicht über Reflexion
verfügbar ist. Dafür gibt es z. B. die @ConstructorProperties-Annotation: In
übersetzten Klassen ist kaum feststellbar, welcher Parameter eines Konstruktors
welcher Property entspricht. Die Argumente einer solchen Annotation zählen
einfach die Properties entsprechend der Parameterreihenfolge auf und machen
diese Information dadurch über Reflexion zugänglich. Diese Information ist im
Zusammenhang mit JavaBeans sinnvoll. Wird die Klasse nicht als JavaBean
verwendet, stört die Annotation nicht; sie wird einfach ignoriert.
JavaBeans-Komponenten sind für den Bereich der Hobby-Programmierung
konzipiert. Die für professionelle Anwendungen ausgelegte Java-EE (EnterpriseEdition) verwendet eher fortgeschrittenere Konzepte, etwa EJB (EnterpriseJavaBeans) als Komponentenmodell mit vielen Möglichkeiten zur Darstellung
von Geschäftslogiken, hauptsächlich in Web-Anwendungen. Dabei kommen Annotationen in großem Stil zum Einsatz (mehr als 30 verschiedene). Beispielsweise legt @TransactionAttribute fest, ob eine Methode innerhalb einer Transak218
4.6 Aspektorientierte Programmierung
tion zu verwenden ist. Mittels @Stateful bzw. @Stateless wird neben weiteren Eigenschaften spezifiziert, ob eine „Session-Bean“ – ein für die Dauer einer
Sitzung existierendes Objekt – zustandsbehaftet sein soll oder nicht. Mit EJB
müssen wir uns schon intensiv auseinandersetzen, bevor wir es sinnvoll verwenden können. Über die vielen Annotationen ergibt sich beinahe schon eine eigene
Sprache innerhalb von Java.
4.6 Aspektorientierte Programmierung
Um die aspektorientierte Programmierung verstehen zu können, müssen wir
sie aus zwei gänzlich unterschiedlichen Sichtweisen betrachten. Aus der konzeptuellen Sicht wird die Denkweise und Einbettung in das objektorientierte
Paradigma auf sehr hoher Ebene deutlich, während aus Sicht der Implementierung auf niedriger Ebene in das Gefüge der Objekte eingegriffen wird. Nur
wenn wir die hohe und tiefe Ebene gleichzeitig im Auge haben, können wir die
aspektorientierte Programmierung gewinnbringend einsetzen. Wir konzentrieren uns zunächst ganz auf die konzeptuelle Sicht und bewegen uns erst später
auf die Implementierungsebene.
4.6.1 Konzeptuelle Sichtweise
Ergebnisse von Berechnungen hängen von folgenden drei Faktoren ab:
• dem Programm, das für die Berechnungen verwendet wird,
• der Semantik der Sprache, in der das Programm geschrieben ist,
• den Daten, auf die das Programm angewandt wird.
Wenn wir die Ergebnisse der Berechnungen ändern wollen, können wir das Programm oder die Daten anpassen. Beides haben wir häufig gemacht. Aber, wie
obige Aufzählung zeigt, gibt es noch eine dritte Möglichkeit: Wir können das
Programm und die Daten unverändert lassen und die Semantik der Sprache
an die Änderungswünsche anpassen. Das klingt provokant, weil wir beim Programmieren in der Regel davon ausgehen, dass die Semantik der Sprache stabil
bleibt. Dennoch strebt die aspektorientierte Programmierung genau das an: Ergebnisse von Berechnungen sollen auf gewisse Weise abgeändert werden, ohne
den Programmtext und die Daten zu ändern. Das läuft auf eine Änderung der
Sprachsemantik hinaus. Diese muss jedoch so erfolgen, dass Erwartungen beim
Programmieren nicht auf unkontrollierbare Weise verletzt werden.
Die aspektorientierte Programmierung bewegt sich in einem Graubereich,
was die genaue Zuordnung zu Programm, Daten oder Sprachsemantik betrifft.
Solche Graubereiche finden wir etwa in der Metaprogrammierung (einschließlich Reflexion), in der Programme selbst als ausführbare Daten angesehen werden und in der Precompilation, in der ein Programm umgeformt wird, bevor
es zur Ausführung kommt. Metaprogrammierung und Precompilation sind unterschiedliche Konzepte mit gemeinsamen Eigenschaften: Es handelt sich um
219
4 Dynamische Typinformation und statische Parametrisierung
äußerst mächtige (also ausdrucksstarke) und gefährliche (schwer kontrollierbare) Werkzeuge. Die aspektorientierte Programmierung verwendet zwar Metaprogrammierung und Precompilation als Hilfsmittel zur Implementierung, zielt
aber darauf ab, die damit verbundenen Gefahren (auch durch Reduktion der
Mächtigkeit) bestmöglich zu vermeiden. Metaprogrammierung und Precompilation werden hinter einem anderen konzeptuellen Ansatz versteckt. Wenn wir
Metaprogrammierung und Precompilation als nicht vorhanden betrachten, im
Hintergrund aber dennoch versteckt einsetzen, ergibt sich etwas, was wir uns
gut als Modifikation der Sprachsemantik vorstellen können. Tatsächlich bleiben alle Änderungen der Semantik immer innerhalb des durch Metaprogrammierung und Precompilation vorgegebenen Rahmens. Dieser Rahmen wird nur
zu einem kleinen Teil ausgeschöpft, nur so weit, dass die Erwartungen beim
Programmieren bestmöglich erhalten bleiben.
Betrachten wir ein abstraktes Beispiel auf hoher Ebene, um eine Vorstellung
davon zu bekommen, in welcher Form die Semantik der Sprache durch aspektorientierte Programmierung beeinflusst werden soll. Nehmen wir an, wir seien
dafür verantwortlich, dass nur autorisierte Personen Zugriff auf die Software
einer Bank bekommen. Die umfangreiche Bankensoftware enthält Funktionalität für die Verwaltung von Konten, Geldtransfers, Krediten, Wertpapieren und
Ähnlichem. Sie wurde nach den Prinzipien der objektorientierten Programmierung entwickelt, besteht also aus zahlreichen Paketen und Klassen, für jede
Funktionalität mindestens eine. Unsere Aufgabe besteht darin, ein Paket von
Klassen zu entwickeln, das für die korrekte Authentifizierung beim Einloggen
sorgt. Je nach Person werden unterschiedliche Rechte für den Zugriff auf manche
Teile der Software vergeben; Kunden bekommen weniger Rechte als Bankangestellte, für Kreditvergaben zuständige Angestellte andere Rechte als Wertpapierverkäufer und so weiter. Es ist keine leichte Aufgabe, die unterschiedlichen
Rechte richtig hinzukriegen, aber noch viel schwieriger ist es, dafür zu sorgen,
dass alle Teile der Bankensoftware vor jedem Zugriff überprüfen, ob zugreifende
Personen von uns die für den Zugriff nötigen Rechte bekommen haben. Für die
meisten der Klassen, in denen die Überprüfungen erfolgen sollen, sind wir nicht
zuständig, wir dürfen nicht darauf zugreifen und sie schon gar nicht verändern,
einige dieser Klassen sind vielleicht noch gar nicht entwickelt oder werden häufig
geändert. Das scheint eine unlösbare Aufgabe zu sein. Ein Ausweg könnte darin
bestehen, die Semantik der Programmiersprache durch aspektorientierte Programmierung so abzuändern, dass Überprüfungen der Rechte an kritischen Programmstellen automatisch erfolgen, ohne dafür die Klassen für die Verwaltung
von Konten, Geldtransfers und so weiter anfassen zu müssen. Kritische Stellen könnten beispielsweise alle Methodenaufrufe sein. Wahrscheinlich würden
dadurch aber so viele Überprüfungen der Rechte entstehen, dass die Effizienz
massiv darunter leidet. Vielleicht reicht es auch, wenn Überprüfungen nur bei
Aufrufen von Methoden erfolgen, die in anderen Paketen liegen als die Aufrufer.
Besser auf das Ziel hin ausgerichtet wären Überprüfungen an allen Stellen, an
denen auf eine Datenbank zugegriffen wird, weil die zugegriffenen Datenfelder
auch Information darüber liefern, für wen die Daten zugreifbar sein sollen. Dabei kann es passieren, dass Daten ohne weitere Datenbankzugriffe an andere
220
4.6 Aspektorientierte Programmierung
Programmteile übergeben und bei den Überprüfungen übersehen werden. Möglicherweise waren die Architekten der Bankensoftware schlau genug, bestimmte
Namenskonventionen und das Mitführen bestimmter Parameter vorzuschreiben,
sodass kritische Stellen für die Überprüfungen aus Methodennamen folgen und
Parameterwerte beim Ermitteln der nötigen Rechte helfen. Jedenfalls ist es gar
nicht notwendig, dass in allen Klassen Programmtexte für das Überprüfen der
Rechte vorhanden sind, solange die projektbezogenen Konventionen eingehalten werden. Die eigentlichen Überprüfungen können auch im Nachhinein durch
Abändern der Sprachsemantik hinzugefügt werden. Abänderungen betreffen nur
zusätzliche Überprüfungen, die, wenn nötig, vielleicht Ausnahmen auslösen, mit
deren Auftreten sowieso immer gerechnet werden muss, die Ausführung des Programms sonst aber in keiner Weise beeinträchtigen. Einzelne Klassen können
unabhängig von den Überprüfungen der Rechte weiterentwickelt werden. Auch
die Art der Prüfungen kann relativ leicht verändert werden, ohne dafür Klassen
abändern zu müssen, die nichts mit der Vergabe der Rechte zu tun haben.
Zusammengefasst: In erster Linie geht es darum, bestimmte Stellen in einem bestehenden Programm zu identifizieren. Kriterien dafür können äußerst
vielfältig sein, etwa Zugehörigkeit zu bestimmten Klassen oder Paketen, charakteristische Namensbestandteile (etwa alle Methodennamen, die mit get, set,
oder access beginnen), bestimmte Arten von Parametern und so weiter. Je
genauer und zuverlässiger Programmstellen identifizierbar sind, desto mächtiger ist das Instrument der aspektorientierten Programmierung. Außerdem muss
es möglich sein, bestimmte Informationen aus der Umgebung (als Kontext bezeichnet) identifizierter Programmstellen zu extrahieren, etwa die Information,
welche Arten von Daten an dieser Stelle bearbeitet werden, welche Rechte dafür
nötig sind und wer auf diese Daten zugreifen möchte. Schließlich muss an den
identifizierten Stellen (über Precompilation zur Übersetzungszeit bzw. Metaprogrammierung zur Laufzeit) zusätzlicher Programmcode ausgeführt werden,
der auch auf Informationen aus dem Kontext zugreifen kann.
In Abschnitt 1.3.2 haben wir Aspekte als eine statische Form der Parametrisierung eingeführt. Parametrisierung bedeutet, dass in einem Programm Lücken
gelassen werden, die erst später (in diesem Fall noch vor der Ausführung) befüllt
werden. Als Lücken können alle identifizierbaren Programmstellen betrachtet
werden, an denen der Mechanismus einhaken kann, das sind fast alle Stellen
in einem Programm. Befüllt werden die Lücken mit zusätzlichem Code, der an
identifizierten Stellen eingeschleust wird. Wie bei jeder Form der Parametrisierung besteht eine Abhängigkeit zwischen den Lücken und dem, womit die
Lücken befüllt werden. In der aspektorientierten Programmierung äußert sich
diese Abhängigkeit darin, dass bei der Identifizierung der Programmstellen und
der Beschreibung des Kontexts bestimmte Annahmen getroffen werden. Wenn
beispielsweise Namenskonventionen nicht eingehalten oder vorgeschriebene Parameter nicht mitgeführt werden, kann der Mechanismus eine Programmstelle
nicht mehr richtig identifizieren und nicht die notwendigen Daten aus dem Kontext herauslesen. Auch wenn wir es oben so dargestellt haben, als ob beliebige
Programmstellen identifizierbar wären, ist es in der Praxis so, dass schon beim
Schreiben des Programms auf die Einhaltung der getroffenen Annahmen geach221
4 Dynamische Typinformation und statische Parametrisierung
tet werden muss. Die Annahmen selbst können fast beliebig sein, aber wenn sie
einmal getroffen wurden, ist es im Nachhinein nur sehr schwer möglich, sie abzuändern. Häufig werden die Annahmen in Form projektbezogener Regeln und
Konventionen festgeschrieben. Beim Erstellen einer Klasse kommen uns manche vorgegebene Konventionen vielleicht lächerlich vor, weil wir den größeren
Zusammenhang nicht sehen. Aber die Einhaltung ist ganz wesentlich, weil andernfalls der spätere Einsatz der aspektorientierten Programmierung verhindert
wird oder dabei schwere Fehler auftreten.
In der aspektorientierten Programmierung wird eine eigene Terminologie verwendet. Allgemein verbreitet ist der Begriff Separation-of-Concerns. Das ist im
Wesentlichen das Gleiche wie der Klassenzusammenhalt. Es wird ausgedrückt,
dass unterschiedliche Belange durch unterschiedliche Klassen abgebildet sein
sollen, damit nicht eine Klasse für mehrere, unzusammenhängende Belange
verantwortlich ist. Im Zusammenhang mit der aspektorientierten Programmierung werden zwei grundsätzliche Arten von Belangen (Concerns) unterschieden: Kernfunktionalitäten (Core-Concerns) und Querschnittsfunktionalitäten
(Cross-Cutting-Concerns). Kernfunktionalitäten lassen sich bei der Faktorisierung gut und eindeutig bestimmten Klassen zuordnen und führen (wenn wir
uns ausreichend darum bemühen) zu hohem Klassenzusammenhalt bei gleichzeitig schwacher Objektkopplung. Bei Querschnittsfunktionalitäten ist es dagegen unmöglich, hohen Klassenzusammenhalt und schwache Objektkopplung
zu erzielen, weil solche Belange immer viele Klassen gleichzeitig betreffen. In
obigem Beispiel zählt die Verwaltung von Konten, Geldtransfers und so weiter
zu den Kernfunktionalitäten. Auch eine zentrale Stelle für die Überprüfung der
Zugriffsrechte ist eine Kernfunktionalität. Aber es muss an sehr vielen Stellen
eingegriffen werden um zu veranlassen, dass die zentrale Stelle die Überprüfungen der Zugriffsrechte durchführt. Das ist eine Querschnittsfunktionalität. Es ist
von Natur aus unmöglich, die Verantwortung für die Veranlassung der Überprüfung der Zugriffsrechte an nur einer Programmstelle zu konzentrieren, es sind
fast alle Klassen betroffen. Die übliche objektorientierte Programmierung kann
mit Querschnittsfunktionalitäten schlecht umgehen. Aufrufe von Methoden für
die Zugriffskontrolle sind über das gesamte Programm verteilt, wahrscheinlich
wird an vielen Stellen auf sie vergessen. Die Verständlichkeit und Sicherheit
leidet. Querschnittsfunktionalitäten lassen sich mittels aspektorientierter Programmierung besser integrieren. Auch dafür ist die Einhaltung projektspezifischer Regeln und Konventionen nötig, aber die Verständlichkeit und Sicherheit
wird verbessert.
Die aspektorientierte Programmierung darf nicht als Alternative zur objektorientierten Programmierung gesehen werden. Vielmehr handelt es sich um eine
Ergänzung (vor allem zur objektorientierten Programmierung, aber nicht darauf
beschränkt), die in speziellen Situationen (für Querschnittsfunktionalität) einen
wertvollen Beitrag liefern kann, in anderen Situationen (für Kernfunktionalität)
aber unbrauchbar ist. Kernfunktionalitäten sind der Normalfall, Querschnittsfunktionalitäten eher selten. Neben der Überprüfung von Zugriffsrechten wird
häufig das Generieren von Debug-Information oder Log-Dateien als Standardbeispiel für eine Querschnittsfunktionalität genannt.
222
4.6 Aspektorientierte Programmierung
4.6.2 AspectJ
AspectJ (www.eclipse.org/aspectj) ist ein Werkzeug für die aspektorientierte Programmierung in Java. Ausgangspunkt ist ein Java-Programm, das aus beliebig vielen Klassen bestehen kann. Zusätzlich schreiben wir Dateien, üblicherweise mit der Endung .aj, in denen alle gewünschten Änderungen der Semantik von Java festgehalten sind. Statt javac verwenden wir zur Übersetzung ajc
(AspectJ-Compiler). Alle Klassen des Java-Programms werden zusammen mit
den .aj-Dateien und der Bibliothek aspectjrt.jar gleichzeitig übersetzt. ajc
fungiert als Aspect-Weaver, der die Inhalte der .aj-Dateien zur Modifikation
der Java-Dateien einsetzt (Precompilation), die danach automatisch weiter zu
.class-Dateien übersetzt werden. Die Bibliothek aspectjrt.jar stellt Hilfsfunktionalität dafür bereit, die in manchen Fällen zur Laufzeit auch Konzepte der Metaprogrammierung einsetzt. Das ursprüngliche Java-Programm wird
nicht zerstört; um die Änderungen durch den Aspect-Weaver wieder los zu werden, müssen wir das Programm nur wieder wie üblich mittels javac übersetzen.
AspectJ baut auf folgende Begriffe auf:
Join-Point: Das ist eine zur Laufzeit identifizierbare Stelle in einem Programm,
z. B. der Aufruf einer Methode oder der Zugriff auf ein Objekt. Es handelt
sich also nicht um eine Stelle, die direkt im Programmtext steht (etwa der
Programmtext für den Aufruf einer Methode), sondern um eine einzelne
Ausführung einer solchen Programmstelle. Zur Laufzeit ist der Kontext
eines Join-Points (etwa die aktuellen Parameterwerte der aufgerufenen
Methode oder die Identität des zugegriffenen Objekts) schon bekannt.
Pointcut Das ist ein syntaktisches Element (also Programmtext) in einer .ajDatei, das einen Join-Point (bzw. eine Menge gleichartiger Join-Points)
auswählt und kontextabhängige Information dazu sammelt, z. B. die Argumente eines Methodenaufrufs oder eine Referenz auf das Zielobjekt.
Advice Das ist ist ein syntaktisches Element in einer .aj-Datei, das den Programmtext spezifiziert, der an einem Join-Point (zusätzlich) auszuführen ist. Je nach Art des Advices wird der Programmtext zusätzlich vor
(before()), zusätzlich nach (after()) oder anstatt (around()) dem JoinPoint ausgeführt, wobei im Fall von around() der Join-Point häufig irgendwo innerhalb dieses Programmtexts explizit ausgeführt wird.
Aspect Das ist ist ein zentrales syntaktisches Element in einer .aj-Datei, das
alle Teile zu einer Einheit zusammenführt (auf ähnliche Weise, wie eine
Klasse in Java alle Teile zusammenführt). Ein Aspekt enthält Deklarationen von Variablen und Definitionen von Methoden (wie eine Java-Klasse)
sowie Pointcuts und Advices.
Ein Pointcut definiert eine Menge von Join-Points. Obwohl es auch anonyme
Pointcuts gibt, werden meist benannte Pointcuts verwendet. Die Syntax sieht
folgendermaßen aus, wobei Signatur die syntaktische Darstellung eines JoinPoints als Java-Text ist, die explizit gekennzeichnete Lücken enthalten kann:
223
4 Dynamische Typinformation und statische Parametrisierung
[Sichtbarkeit] pointcut Name ([Argumente]) : Pointcuttyp(Signatur);
Das folgende Beispiel spezifiziert einen Pointcut für einen Methodenaufruf, der
alle Methoden umfasst, die mit beliebiger Sichtbarkeit im Paket javax oder
Unterpaketen davon vorkommen, deren Namen mit add beginnen, mit Listener
enden und deren einzige Argumente Untertypen von EventListener sind:
public pointcut AddListener() :
call(* javax..*.add*Listener(EventListener+));
In der Signatur steht
• * für eine beliebige Anzahl von Zeichen außer einem .,
• .. für eine beliebige Anzahl jedes beliebigen Zeichens,
• + für jeden Untertyp eines Typs,
Im Beispiel steht call für den Typ eines Pointcuts für einen Methodenaufruf.
Es gibt viele Arten von Pointcuttypen (Aufzählung unvollständig):
execution(MethodSignature) – Ausführung einer Methode
call(MethodSignature) – Aufruf einer Methode
execution(ConstructorSignature) – Ausführung eines Konstruktors
call(ConstructorSignature) – Aufruf eines Konstruktors
get(FieldSignature) – lesender Zugriff auf Objekt- oder Klassenvariable
set(FieldSignature) – schreibender Zugriff auf Objekt- oder Klassenvariable
staticinitialization(TypeSignature) – Initialisierung einer Klasse
preinitialization(ConstructorSignature) – erster Schritt der Initialisierung
eines Objekts
initialization(ConstructorSignature) – Initialisierung eines Objekts
handler(TypeSignature) – Ausführung einer Ausnahmenbehandlung
this(TypeOrId) – das aktuelle Objekt (innerhalb einer Objekt-Methode oder
eines Konstruktors) ist vom gegebenen Typ oder identisch zum angegebenen Wert
target(TypeOrId) – der Empfänger einer Nachricht oder das Ziel eines Variablenzugriffs ist ein Objekt vom gegebenen Typ oder identisch zum angegebenen Wert
args(TypeOrId, . . . ) – die Argumente in der Argumentliste sind von den gegebenen Typen oder identisch zu den angegebenen Werten
224
4.6 Aspektorientierte Programmierung
Zum Beispiel werden alle schreibenden Zugriffe auf eine private Variable vom
Typ float der Klasse Account mit dem Namen balance durch den Pointcut set(private float Account.balance) spezifiziert. Das ist ein anonymer
Pointcut (enthält nur den Teil nach dem Doppelpunkt). Solche (anonyme)
Pointcuts können über folgende Operatoren miteinander verknüpft werden, wodurch nach dem Doppelpunkt in einem benannten Pointcut auch mehrere, über
Operatoren verknüpfte Pointcuts stehen können:
• ! (Negation) für alle Join-Points außer dem spezifizierten,
• || für die Vereinigungsmenge von Join-Points und
• && für die Durchschnittsmenge von Join-Points.
Beispielsweise ist SpecificAddListener die Durchschnittsmenge zweier Arten
von Join-Points:
public pointcut SpecificAddListener(EventListener el) :
call(* javax..*.add*Listener(EventListener)) && args(el);
Hier kommt ein Argument ins Spiel. Ausgewählt werden nur jene Join-Points
mit entsprechender Syntax, bei denen das übergebene Argument identisch zu
el ist. Normalerweise ist el allerdings nicht spezifiziert; dadurch werden alle
Join-Points passender Syntax gewählt und der Wert von el im Join-Point wird
zurückgegeben. Bei Anwendung der Pointcuts (siehe unten) wird der Wert von
el weitergeleitet. Auf diese Weise lässt sich Information aus dem Kontext des
Join-Points ermitteln. So wie dies args(...) für Argumente macht, geschieht
das auch bei target(...) für Empfänger von Nachrichten oder Objekten, in
denen auf Variablen zugegriffen wird, sowie bei this(...)4
für Objekte, in
denen Methodenaufrufe oder Variablenzugriffe erfolgen.
Folgende Arten von Pointcuttypen sind kontrollflussbasiert, das heißt, sie
betreffen alle ausgeführten Join-Points im angegebenen Bereich:
cflow(Pointcut) alle dem Kontrollfluss entsprechenden Join-Points eines Pointcuts inklusive dem äußersten; bezieht sich Pointcut z. B. auf einen Methodenaufruf, dann alle während der Ausführung der Methode ausgeführten
Anweisungen inklusive dem Methodenaufruf
cflowbelow(Pointcut) wie cflow, aber exklusive dem äußersten Join-Point
(z. B. exklusive Methodenaufruf)
Mit einem solchen Pointcut werden sehr viele Join-Points gewählt. Häufig wird
diese Menge durch Bildung der Durchschnittsmenge mit einem anderen Pointcut reduziert. Das gilt auch für folgende Arten von Pointcuttypen, die sichtbarkeitsbasiert sind:
within(Typepattern) alle Join-Points innerhalb des lexikalischen Sichtbereichs
einer Klasse oder eines Aspekts
4this(...) hat die gleiche Syntax wie ein Konstruktoraufruf als erste Anweisung in einem
Konstruktor. Da Pointcuts nicht in Konstruktoren stehen, ist die Syntax aber eindeutig.
225
4 Dynamische Typinformation und statische Parametrisierung
withincode(Method/ConstructorSignature) alle Join-Points im lexikalischen
Sichtbereich der Methode oder des Konstruktors
Der folgende anonyme Pointcut schließt alle Pointcuts innerhalb der Klasse
oder des Aspekts TraceAspect von der spezifizierten Menge der Pointcuts (alle
Aufrufe von Methoden aus PrintStream, die mit print beginnen) aus.
call(* java.io.PrintStream.print*(..)) &&
!within(TraceAspect)
In einem Advice wird angegeben, welche Anweisungen an den ausgewählten
Join-Points ausgeführt werden sollen. Ein Advice hat die Form
[Sichtbarkeit] before([Argumente]) : Pointcut {Programmtext}
In diesem Fall wird der Programmtext vor jedem durch den Pointcut bestimmten Join-Point ausgeführt. Mit after() statt before() wird der Programmcode
nach dem Pointcut ausgeführt. Es gibt die Variante after() returning, die
nur zutrifft, wenn der Join-Point ohne Auftreten einer Ausnahme beendet wird,
sowie after() throwing, die nur im Fall einer ausgelösten Ausnahme zutrifft.
Mit around() wird Programmcode statt dem Pointcut ausgeführt, wobei der
Code des Join-Points komplett umgangen oder (z. B. mit anderen Argumenten)
irgendwo zwischen drin ausgeführt wird.
Im folgenden Programmstück wird ein Advice mit einem anonymen Pointcut
und einer mit einem Namen versehenen Pointcut gezeigt:
before() : call(* Account.*(..)) { checkUser(); }
pointcut connectionOperation(Connection connection) :
call(* Connection.*(..) throws SQLException)
&& target(connection);
before(Connection connection) :
connectionOperation(connection) {
System.out.println("Operation auf " + connection);
}
Der Advice { checkUser(); } wird vor jedem Aufruf einer Methode mit beliebigem Ergebnistyp und beliebiger Signatur der Klasse Account ausgeführt.
Der zweite Advice zeigt das Weiterreichen von Information über ein Argument
eines Pointcuts und Advices: connection ist das Objekt, auf dem die Methode
ausgeführt wird; connectionOperation beschreibt alle Aufrufe von Methoden
der Klasse Connection, die eine SQLException auslösen können. Wie wir sehen, wird Information über Parameter hier auf andere Weise weitergereicht als
in Java: Der Join-Point bestimmt den Wert von connection, also den Empfänger der (unbekannten) Nachricht. Nach Weiterreichung über den Pointcut und
Advice wird der Wert in der println-Anweisung verwendet.
Ein Aspekt fasst Pointcuts und Advices sowie ganz normale Variablendeklarationen und Methodendefinitionen, wie sie in jeder Java-Klasse vorkommen
226
4.6 Aspektorientierte Programmierung
könnten, zu einer Einheit zusammen. Die Variablen und Methoden werden vor
allem in den Advices verwendet. Die Definition sieht wie die einer Klasse aus,
bis auf aspect statt class. Sie steht meist in einer Datei mit der Endung .aj,
obwohl eine Datei mit der Endung .java auch funktioniert.
public aspect JoinPointTraceAspect {
private int callDepth = -1;
pointcut tracePoints(): !within(JoinPointTraceAspect);
before() : tracePoints() {
callDepth++;
print("Before", thisJoinPoint);
}
after() : tracePoints() {
callDepth--;
print("After", thisJoinPoint);
}
private void print(String prefix, Object message) {
for(int i=0, spaces=callDepth*2; i<spaces; i++) {
System.out.print(" ");
}
System.out.println(prefix + ": " + message);
}
}
Der Aspekt JoinPointTraceAspect gibt alle Join-Points eines Programms aus.
Die Ausgabe wird der Schachtelungstiefe entsprechend eingerückt. In einem
before-Advice wird die Einrücktiefe erhöht, in einem after-Advice wieder erniedrigt und die Art des Join-Points ausgegeben. Dabei ist thisJoinPoint ein
Zeiger auf das Join-Point-Objekt mit allen Informationen über einen Join-Point;
der Wert dieser Pseudovariable wird automatisch gesetzt. Am besten gleich an
einem eigenen Java-Programm ausprobieren. Achtung: Es wird viel Output produziert, daher nur an einem kleinen, kurz laufenden Programm ausprobieren.
Hier wurde nur ein Bruchteil der Sprachelemente von AspectJ vorgestellt.
Weitergehende Informationen und der Compiler ajc finden sich auf der Homepage von AspectJ (eclipse.org/aspectj) und in der Literatur (z. B. AspectJ
in Action von Ramnivas Laddad [21]).
227

5 Applikative Programmierung und
Parallelausführung
Unterstützung für die applikative Programmierung als eine fortgeschrittene
Form der funktionalen Programmierung wurde vergleichsweise spät in Java integriert, später als in die meisten anderen objektorientierten Sprachen. Dennoch
(oder vielleicht gerade deswegen) hat sich ein entsprechender Programmierstil
in sehr kurzer Zeit durchgesetzt. Ein bedeutender Auslöser für den Wunsch nach
Integration funktionaler und applikativer Programmiertechniken in objektorientierte Sprachen liegt darin, dass sich die funktionale und applikative Programmierung als recht erfolgversprechende Basis für nebenläufige und parallele
Programmierung erwiesen hat. Die rasch zunehmende und breite Verfügbarkeit
paralleler Recheneinheiten und der große Bedarf nach Big-Data-Anwendungen
lassen eine solche Entwicklung logisch erscheinen, auch wenn dadurch Programmierparadigmen miteinander kombiniert werden, die von Natur aus in Widerspruch zueinander stehen. In diesem Kapitel geht es also nicht nur darum,
welche Mechanismen Java für die funktionale und applikative Programmierung
zur Verfügung stellt und wie diese zusammen mit speziell für Nebenläufigkeit
entwickelten Mechanismen für die nebenläufige und parallele Programmierung
einsetzbar sind, sondern auch darum, wie wir mit den Widersprüchen in den
Paradigmen umgehen können.
5.1 Lambdas und Java-8-Streams
Ein Beispiel mit Lambdas und Java-8-Streams haben wir in Abschnitt 2.3.2 gesehen. Nun betrachten wir diese Konzepte aus einem anderen Blickwinkel. Zunächst betrachten wir Lambdas zusammen mit anonymen inneren Klassen, damit deren Leistungsfähigkeit und Einbettung in Java besser verständlich wird.
Danach beschäftigen wir uns mit den Grundkonzepten der Java-8-Streams und
Richtlinien für deren Einsatz in der applikativen Java-Programmierung.
5.1.1 Anonyme innere Klassen und Lambdas
Lambdas ähneln Objekten innerer Klassen, siehe Abschnitt 3.4.1. Eine anonyme
innere Klasse ist eine innere Klasse ohne einen von uns vorgegebenen Namen.
Sie kombiniert die Syntax zur Objekterzeugung mit jener zur Definition einer
Klasse: Nach new, dem Namen eines Typs (der auch eine abstrakte Klasse oder
ein Interface sein kann) sowie runden Klammern steht ein Klassen-Rumpf. In
folgendem Beispiel enthält eine return-Anweisung eine anonyme innere Klasse:
229
5 Applikative Programmierung und Parallelausführung
public class List<A> implements Collection<A> {
private Node<A> head = ...; // as in Section 4.1.2
public Iterator<A> iterator() {
return new Iterator<A>() {
private Node<A> p = head;
public boolean hasNext() { return p != null; }
public boolean next() { ... }
}
}
...
}
Der Klassenrumpf wird wie jede andere innere Klasse (die auch an fast beliebigen Programmstellen definiert werden kann) vom Compiler übersetzt, wobei
der Compiler für die Klasse einen internen Namen wählt, der sonst nirgends vorkommt (z. B. List$1). Über Reflexion kann dieser Name im Programm sichtbar
werden. Der Typ nach new ist ein Obertyp der Klasse; falls dieser Obertyp eine
(abstrakte) Klasse ist, können die runden Klammern Argumente enthalten, die
wie durch eine super-Anweisung in einem Konstruktor an den Konstruktor der
Oberklasse übergeben werden. Bei Ausführung von new wird ein Objekt der anonymen inneren Klasse erstellt. Das Ergebnis ist vom deklarierten Obertyp, im
Beispiel also Iterator<A>. Anonyme innere Klassen erweitern die Fähigkeiten
von Java gegenüber normalen inneren Klassen in keiner Weise. Sie stellen nur
eine Syntaxvereinfachung für den häufig vorkommenden Fall dar, dass Objekte
einer inneren Klasse nur an genau einer Stelle im Programm erzeugt werden.
Obiges Beispiel entspricht dem in Abschnitt 4.1.2, abgesehen vom nicht eingeführten Namen der dortigen Klasse ListIter.
Wir machen nicht viel falsch, wenn wir Lambdas als weitere Syntaxvereinfachung anonymer innerer Klassen betrachten, wobei jede soche Klasse nur genau
eine Methode definiert, sonst nichts. Da der angegebene Obertyp die Signatur
genau einer entsprechenden Methode spezifizieren muss, können wir den Methodennamen, den Ergebnistyp und die Typen der Parameter weglassen; diese
müssen mit der Signatur übereinstimmen.1 Ein solcher Obertyp muss immer
existieren, wo ein Lambda verwendet wird, aber er muss nicht immer auf den
ersten Blick als solcher erkennbar sein. Häufig werden Lambdas als Argumente
an Methoden übergeben; dann entsprechen die Obertypen den Parametertypen.
In anderen Fällen werden Lambdas in Variablen abgelegt; dann entsprechen
Obertypen den deklarierten Variablentypen. Solche Obertypen müssen immer
Interfaces sein, weil es keine Klasse mit nur einer Methode geben kann (da
mehrere Methoden von Object geerbt werden). Konkret muss der Obertyp ein
funktionales Interface mit genau einer abstrakten Methode sein, die vom Lambda implementiert wird; daneben kann es beliebig viele Methoden mit Default1Hinsichtlich Subtyping könnte der Ergebnistyp im Untertyp kovariant verändert, also spezieller sein als in der Signatur. Das würde aber keinen Sinn ergeben. Generell ist die
Forderung nach einer übereinstimmenden Signatur ein technischer Kunstgriff, der Typinferenz ermöglicht. Wäre der Obertyp beliebig, würde Subtyping Typinferenz verhindern.
230
5.1 Lambdas und Java-8-Streams
Implementierungen, statische Methoden und Konstantendefinitionen enthalten.
Eine weitere Einschränkung bei Lambdas (im Gegensatz zu abstakten inneren
Klassen) besteht darin, dass im Rumpf nur unveränderliche Variablen aus der
Umgebung zugreifbar sind, das sind solche, die als final deklariert sind oder so
verwendet werden, als ob sie als final deklariert wären. Das soll die gefürchtete
unkontrollierte Kommunikation über Variablen im Zaum halten. Parameter der
Lambdas oder innerhalb des Rumpfs von Lambdas deklarierte lokale Variablen
sind dagegen uneingeschränkt änderbar.
Wenn wir schon beim Vereinfachen der Syntax sind, ist leicht zu verstehen,
dass auch die geschwungenen Klammern um einen Methoden-Rumpf mit nur
einer Anweisung und das Schlüsselwort return weggelassen werden kann, falls
der Rumpf nur aus einer return-Anweisung besteht. Das Weglassen von runden
Klammern um einen einzigen Parameter ist nur mehr eine Kleinigkeit. Schließlich müssen wir noch das Symbol -> zwischen Parameterliste und Rumpf zur
Kennzeichnung von Lambdas einführen, damit die Syntax eindeutig wird. Dieses Symbol bietet sich an, weil es aufgrund der C-Syntax von Java ohnehin
reserviert war und in neueren funktionalen Sprachen üblicherweise zur Kennzeichnung von Funktionstypen dient, also eine inhaltliche Nähe besteht.
Um Beispiele zu betrachten, brauchen wir passende Interfaces als Obertypen.
Wir könnten dafür eigene Interfaces einführen. Einfacher geht es, wenn wir
Interfaces verwenden, die in den Java-Standard-Bibliotheken für diesen Einsatzzweck vordefiniert sind. Viele davon sind im Paket java.util.function
zusammengefasst. Dort gibt es das generische Interface Function<T,R> mit der
abstrakten Methode R apply(T t), wobei T für den Typ des einzigen Parameters und R für den Ergebnistyp steht. Das Interface BiFunction<T,U,R>
mit der abstrakten Methode R apply(T t, U u) ist ähnlich, aber mit einem
zweiten Parameter vom Typ U. Das Interface Consumer<T> hat die Methode
void accept(T t) ohne Ergebnis. Keine dieser Methoden ist mit Zusicherungen versehen, die besagen, wofür sie stehen. Außer den Signaturen ist nichts
über die Methoden bekannt; wir haben es (trotz benannter Interfaces) im Wesentlichen mit struktureller Abstraktion zu tun, nicht mit der üblichen nominalen Abstraktion. Jedes Interface in diesem Paket ist mit der Annotation
@FunctionalInterface versehen, die den Compiler anweist, eine Fehlermeldung auszugeben, falls es sich nicht um ein Interface mit genau einer abstrakten Methode handelt. Das ist eine reine Vorsichtsmaßnahme, die, abgesehen von
einer möglichen Fehlermeldung, keinerlei Konsequenzen hat. Viele dieser Interfaces enthalten auch Methoden mit Default-Implementierungen und statische
Methoden, die im entsprechenden Kontext hilfreich sein könnten.
Hier sind einige einfache Beispiele für Lambdas und ihre Ausführungen:
Consumer<String> p = s -> System.out.println(s);
p.accept("Hello world.");
Function<Integer,String> value = i -> "value = " + i;
p.accept(value.apply(8));
BiFunction<String,Boolean,String> opt = (s,b) -> b ? s : "";
p.accept(opt.apply("maybe", true));
231
5 Applikative Programmierung und Parallelausführung
Ein Blick lässt erkennen, dass Lambdas zwar kurz, kompakt und intuitiv sein
können und wie Funktionsdefinitionen aussehen, die Kürze aber nur durch umfangreiche deklarierte Typen und die Informationen in Interfaces ermöglicht
wird. Die Verwendungen der Lambdas machen deutlich, dass es sich dabei nicht
um Funktionen handelt, sondern um Objekte, die Methoden enthalten. In folgender Fortsetzung obiger Programmzeilen wird die Variable value geändert:
value = i -> { String r = "value = ";
r += i;
p.accept(r);
return r;
};
value.apply(6);
Während Methoden zur Laufzeit unveränderlich sind, lassen sich Variablen,
die Lambdas enthalten, sehr einfach ändern. Darin liegt ein Vorteil gegenüber
Methoden. Die Anweisung p.accept(r); greift auf die Variable p aus der Umgebung des Lambdas zu. Das geht nur, weil p unveränderlich ist. Der Compiler
meldet einen Fehler, wenn wir versuchen, einen neuen Wert an p zuzuweisen.
Die lokale Variable r kann dagegen beliebig geändert werden. Lambdas können,
wie alle Methoden in Java, uneingeschränkt Seiteneffekte haben.
Tatsächlich sind Lambdas keine inneren Klassen, sondern eigenständige Konstrukte, für deren Einführung die JVM erstmals in der Geschichte erweitert
wurde. Der Hauptgrund dafür liegt in der unzureichenden Effizienz im Umgang
mit einer großen Zahl sehr kleiner Klassen. Ein Großteil der Komplexität im
Umgang mit Klassen ist für Lambdas unnötig. Die Semantik von Lambdas orientiert sich stark an der von anonymen inneren Klassen, sodass es kein Fehler
ist, Lambdas als Spezialfall anonymer innerer Klassen anzusehen, wobei die
Einschränkungen die gröbsten Probleme geschachtelter Klassen beseitigen.
In Abschnitt 1.1.2 haben wir gesehen, dass der untypisierte λ-Kalkül die
Mächtigkeit einer Turing-Maschine mit sehr einfachen Mitteln erreicht. Viel
mehr als λ-Abstraktion ist dazu nicht nötig. Es stellt sich die Frage, ob Lambdas in Java auch so mächtig sind. Eine gute Antwort darauf ist vielschichtig
und komplex, da es einen fundamentalen Unterschied gibt: Alle Parameter und
Ergebnisse von Lambdas in Java haben einen deklarierten Typ. Eine einfach
typisierte Variante des λ-Kalküls, die große Ähnlichkeit zu Java-Lambdas hat,
erreicht nicht mehr die Mächtigkeit der Turing-Maschine, macht Programme
dafür aber einfacher verständlich. Der Grund liegt darin, dass wir keine unendlich großen Typen aufbauen können, die wir bräuchten, um mit den Mitteln
des λ-Kalküls Rekursion darzustellen. Das ist nicht tragisch, weil wir die Ursache des Problems kennen. Einer typisierten Variante des λ-Kalküls können wir
wieder die Mächtigkeit der Turing-Maschine verleihen, indem wir eine weitere
Regel hinzufügen, die rekursive Aufrufe ermöglicht2
(natürlich nur auf Kosten
der Einfachheit). Bei Lambdas in Java ist es ähnlich: Es spielt keine Rolle, wie
2Genau genommen handelt es sich um eine mit einem Typ parametrisierte, also generische
Regel, was äquivalent zu einer Familie von Regeln ist, häufig Y-Kombinator genannt.
232
5.1 Lambdas und Java-8-Streams
mächtig die Lambdas für sich genommen sind, weil die Mächtigkeit der Sprache
von anderen Sprachelementen wie rekursiven Methodenaufrufen oder Schleifen
bestimmt wird. Natürlich können wir in Java Interpreter für beliebige Varianten des λ-Kalküls implementieren. Für die Mächtigkeit der Sprache ist es kein
Nachteil, dass Lambdas nur Objekte stark eingeschränkter Klassen sind. Die
Einschränkungen wurden so gewählt, dass Lambdas in der Praxis viel einfacher
handhabbar sind als vollständige Klassen. Erst die Vereinfachung ermöglicht
Abstraktionen auf sehr hoher Ebene, wie wir sie im applikativen Programmierstil benötigen.
Es gibt eine weitere syntaktische Variante zur Spezifikation von Lambdas:
Klassenname::Methodenname steht für eine Methode mit dem genannten Namen in der genannten Klasse (oder für die Erzeugung eines Objekts der Klasse,
wenn statt dem Methodennamen new verwendet wird). Genau wie bei Lambdas, die mittels -> spezifiziert werden, muss ein Obertyp (funktionales Interface) gegeben sein, der für die passende Auswahl sorgt, wenn Methoden und
Konstruktoren überladen sind oder Typparameter benötigt werden. Es hängt
von der Art (Objektmethode, Klassenmethode oder Konstruktor) ab, wofür ein
derartiges Lambda genau steht, wie folgende Beispiele zeigen:
BiFunction<String,String,Integer> cmp = String::compareTo;
// entspricht cmp = (s,t) -> s.compareTo(t);
BiFunction<Object,Object,Boolean> eq = Objects::equals;
// entspricht eq = (a,b) -> Objects.equals(a,b);
Function<StringBuilder,String> mk = String::new;
// entspricht mk = sb -> new String(sb);
Im Fall einer Objektmethode erhöht sich die Anzahl der Parameter um eins,
weil als erster Parameter der Empfänger der Nachricht dazukommt. Der einzige
Grund für die Existenz dieser Form von Lambdas ist die gute Lesbarkeit.
5.1.2 Java-8-Streams
Der Begriff „Java-8-Stream“ klingt nach einem sehr speziellen Konzept in einer
ganz bestimmten Java-Version und ist das auch. Es fehlt uns ein allgemeinerer
Begriff. Am ehesten können wir das Konzept als Form eines Iterators betrachten.
In der objekorientierten Programmierung häufig eingesetzte externe Iteratoren (Objekte von Iterator mit den Methoden next und hasNext) iterieren
mittels einer außerhalb des Iterators gelegenen Schleife über die Elemente und
verändern den Zustand des Iterators dabei wiederholt durch Aufrufe von next.
Iteratoren verlagern die Kontrolle von den Stellen, an denen Iteratoren erzeugt
werden, an die Stellen, an denen next aufgerufen wird. Diese imperative Vorgehensweise ist aufgrund der Seiteneffekte nicht mit einem funktionalen Programmierstil vereinbar. Funktionale und applikative Programme, insbesondere
in neueren funktionalen Sprachen wie Haskell, setzen interne Iteratoren ein,
bei denen innerhalb des Iterators mittels Rekursion über die Elemente iteriert
wird. Ein interner Iterator ist eine Funktion höherer Ordnung (eine Funktion,
die eine weitere Funktion als Parameter nimmt), die die übergebene Funktion
233
5 Applikative Programmierung und Parallelausführung
erst bei Bedarf auf jedes Element anwendet. In erster Näherung erfüllen externe
und interne Iteratoren den gleichen Zweck, aber externe Iteratoren sind besser
kontrollierbar, interne semantisch einfacher und nicht auf Seiteneffekte angewiesen. Durch Lazy-Evaluation kann der Unterschied zwischen internen und externen Iteratoren sehr klein sein oder verschwinden. Java-8-Streams betten für
Haskell-Programme typische Abläufe einschließlich Lazy-Evaluation zusammen
mit Iteratoren (die wie interne Iteratoren ausschauen, aber wie externe Iteratoren ausgeführt werden) in Java ein. Trotz des Namens sind Java-8-Streams also
kein Java-typisches Konzept. Allerdings mussten für die Einbettung zahlreiche
Erweiterungen in vielen Java-Standard-Klassen vorgenommen und das Konzept an die Gegebenheiten einer objektorientierten Sprache angepasst werden,
sodass der Begriff doch nicht falsch gewählt ist.
Wie in Abschnitt 2.3.2 erläutert, sind Java-8-Streams Objekte der Klassen
Stream<T> (Datenstrom mit Elementen des generischen Typs T), IntStream,
LongStream und DoubleStream (Datenströme mit Elementen der entsprechenden elementaren Typen), die jeweils als sequentielle oder parallele Datenströme
verwendbar sind. Im Mittelpunkt stehen die zahlreichen Methoden, die auf den
Datenströmen operieren. Wir unterscheiden drei Arten solcher Methoden:
Stream-erzeugende Operationen: Das sind Methoden, die einen neuen Datenstrom erzeugen und die Elemente, über die iteriert werden soll, in den
Datenstrom füttern. Standard-Klassen, die das Interface Iterable<T>
implementieren (also iterierbar sind) unterstützen auch die Methoden
stream() und parallelStream(), die jeweils einen (sequentiellen oder
parallelen) neuen Datenstrom mit den iterierbaren Elementen erzeugen.
Das sind vor allem Klassen aus dem Collections-Framework. Die StreamKlassen selbst bieten statische Methoden zum Erzeugen neuer Streams an,
vor allem to aufgerufen mit den Elementen, über die iteriert werden soll,
oder einem Array dieser Elemente. Die Methoden iterate und generate
zum Erzeugen unendlich vieler Elemente in einem Stream (mit etwas unterschiedlichen Techniken) sind Funktionen höherer Ordnung, übernehmen also Lambdas als Argumente, die die Elemente produzieren. Die
Klasse StreamSupport stellt statische Methoden bereit, um neue Streams
aus Spliteratoren zu erzeugen. Ein Objekt vom Typ Spliterator<T> ist
eine erweiterte Form eines (sowohl internen als auch externen) Iterators,
der Unterstützung für das Aufteilen der Elemente auf mehrere Datenblöcke (das sind selbst wieder Spliteratoren) hat, sodass parallele Ströme unabhängig voneinander auf unterschiedlichen Datenblöcken arbeiten
können. Das Interface Iterable<T> hat die Methode spliterator() mit
einer Default-Implementierung (die meist zu überschreiben ist), die die
Elemente, über die iteriert wird, in ein Objekt vom Typ Spliterator<T>
füttert, wodurch Spliteratoren leicht verfügbar sind.
Stream-modifizierende Operationen: Das sind von den Stream-Klassen bereitgestellte Objekt-Methoden, die Operationen auf den Elementen des
Streams ausführen und Ergebnisse wieder in einen Stream füttern. Ergebnisse dieser Methoden sind von einem Stream-Typ. Viele dieser Methoden
234
5.1 Lambdas und Java-8-Streams
dienen als Funktionen höherer Ordnung, denen Lambdas als Parameter
übergeben werden. Beispielsweise gibt es die Methode map, die eine Operation (als Lambda frei wählbar) auf jedes Element anwendet und die
Ergebnisse weiterreicht, wobei Element-Typ und Ergebnistyp verschieden
sein können; der Strom an Daten nach der Anwendung von map kann einen
anderen Typ haben als davor.3 Methoden wie filter belassen einige Elemente im Strom und filtern andere heraus. Einige Methoden kümmern
sich um Spezialfälle, z. B. limitiert limit die Anzahl der Elemente, sorgt
sorted für eine sortierte Reihenfolge und vermeidet distinct Duplikate.
Stream-abschließende Operationen: So wie modifizierende Operationen sind
auch abschließende Operationen Objekt-Methoden, die von den StreamKlassen bereitgestellt und auf Elementen des Streams ausgeführt werden.
Ergebnisse werden jedoch nicht mehr in einen Stream gefüttert, sondern
der Stream wird abgeschlossen und Elemente werden auf andere Weise (außerhalb des Streams) weiterverarbeitet. Ergebnisse sind nicht von
einem Stream-Typ, außer in Sonderfällen, z. B. wenn Stream-Elemente
wieder Streams sind, wobei es sich um andere Streams handelt. Häufig
verwenden wir reduce (in verschiedenen Varianten), um die einzelnen
Elemente im Stream durch Anwendung von Lambdas zu einem einzigen
Wert zusammenzufassen, etwa eine Zahlensumme zu bilden. Ebenso häufig dient collect (in verschiedenen Varianten) dazu, Elemente im Stream
in irgendeiner Art von Collection abzulegen, was konzeptuell mit reduce
eng verwandt ist. Die vielleicht allgemeinste Form des Abschlusses ist
forEach, eine Methode, die irgendeine Aktion auf jedem Element ausführt (z. B. Ausgabe oder Abspeichern in einer Collection bzw. Addieren
zu einer Summe). Spezielle abschließende Operationen sind z. B. allMatch
und anyMatch, die ein Boolean zurückgeben, das besagt, ob alle Elemente oder irgendein Element eine bestimmte (über ein Lambda festgelegte)
Eigenschaft erfüllt, sowie count, das einfach nur die Elemente zählt.
Die Ausführung der Stream-Operationen erfolgt mittels Lazy-Evaluation, wie
in Abschnitt 2.3.3 demonstriert. Hinter jeder Operation, die einen Stream erzeugt oder modifiziert, steht ein Iterator und die Ausführung erfolgt in mehreren
Schritten: Bei Ausführung der Stream-erzeugenden und Stream-modifizierenden
Methoden in einem ersten Schritt passiert noch keine inhaltliche Berechnung,
sondern es werden nur die dahinter stehenden Iteratoren erzeugt und miteinander verknüpft. Erst die Ausführung einer Stream-abschließenden Operation
stößt die eigentlichen Berechnungen an. Auf fast die gleiche Weise, wie wir bei
Anwendung eines externen Iterators durch Aufrufe von next wiederholt auf das
3Hier ergibt sich ein terminologisches Problem: Sollen wir von nur einem Datenstrom sprechen, in dem die Daten während des Durchfließens transformiert werden, oder ist der
Datenstrom vor der Ausführung von map ein anderer als danach? Formal betrachtet und
aus der Implementierungssicht müssen wir jedenfalls von unterschiedlichen Strömen sprechen, weil nicht einmal die Typen übereinstimmen müssen. Aber der Ablauf wird einfacher
verständlich, wenn wir nur einen Strom sich ändernder Daten im Kopf haben.
235
5 Applikative Programmierung und Parallelausführung
jeweils nächste Element zugreifen, holt sich eine abschließende Operation wiederholt das nächste Element aus dem davor stehenden Iterator, solange noch
weitere Elemente benötigt werden und der Stream (das ist der Iterator) noch
weitere Elemente liefern kann. Zunächst erfolgt der Aufruf in dem Iterator, der
der Operation direkt vor der abschließenden Operation entspricht, der leitet den
Aufruf gegebenenfalls an den Iterator weiter, der der davor stehenden Operation
entspricht und so weiter, bis zur erzeugenden Operation. Die Ergebnisse werden
jeweils nach Ausführung der modifizierenden Operationen zurückgegeben. Hinter Lazy-Evaluation steckt also keine Hexerei und auch kein undurchschaubar
komplizierter Mechanismus, sondern das ist das ganz normale Programmverhalten, das wir bekommen, wenn wir mehrere Iteratoren hintereinanderschalten.
Die Iteratoren, die hinter den Stream-Operationen stecken, sind vom Typ
Spliterator<T>, den wir oben schon im Zusammenhang mit der Erzeugung
von Streams gesehen haben. Wir können die Fähigkeiten von Streams selbst
erweitern, indem wir neue Spliteratoren schreiben (das Interface Spliterator
implementieren). Über die Klasse StreamSupport werden Spliteratoren in Streams eingebunden. Wir erhalten einen modifizierenden Operator, wenn unser
Spliterator über Elemente iteriert, die zuvor aus einem anderen Spliterator gelesen wurden; andernfalls erhalten wir einen erzeugenden Operator. Jede Methode, die Elemente aus einem Spliterator liest, kann als abschließende Operation verstanden werden. Die Einteilung der Methoden in die drei Kategorien (erzeugen, modifizieren, abschließen) ergibt sich ganz natürlich, ebenso
wie Lazy-Evaluation. Wir müssen jedoch bedenken, dass Spliteratoren nur aus
der Sicht der Implementierung existieren. Beim Programmieren mit Streams
bleiben Spliteratoren meist versteckt; die Abstraktion über Iteratoren ist ja
ein wesentlicher Grund, warum wir Java-8-Streams überhaupt verwenden. Das
Verhalten bezüglich Lazy-Evaluation wird nur aus der klaren Unterscheidung
zwischen erzeugenden, modifizierenden und abschließenden Operationen ablesbar. Beschreibungen der Methoden müssen in dieser Hinsicht deutlich sein.
Es folgt ein einfaches Beispiel für die Faktorielle-Berechnung. Wir gehen
bei allen Beispielen implizit davon aus, dass der Programmtext mit importAnweisungen für java.util.* und java.util.stream.* beginnt.
public static long fact(int n) {
return LongStream.rangeClosed(2, n).reduce(1, (i,j) -> i*j);
}
Faktorielle ist nichts anderes als die Reduktion einer fortlaufenden Zahlensequenz über Multiplikation. Das zu erkennen ist die Magie, die hinter Java-8-
Streams steckt. Wir müssen eine solche Zahlensequenz erzeugen können. Wie
in Abschnitt 2.3.3 könnten wir eine eigene Methode dafür schreiben, aber meist
zahlt es sich aus, stattdessen in den Stream-Klassen nach passenden vorgefertigten Methoden zu suchen. Über Iteratoren und andere Implementierungsdetails
müssen wir dabei kaum nachdenken – eine abstrakte Form des Programmierens.
Folgende Methode zeigt das Aufspalten und Zusammenfassen von Einträgen
in Streams. Der Parameter sales stellt eine Ansammlung von Verkäufen dar,
236
5.1 Lambdas und Java-8-Streams
die jeweils aus einer Menge von Produkten (als Strings) bestehen. Das Methodenergebnis bildet jedes Produkt auf eine Map ab, die angibt, welche anderen
Produkte wie häufig zusammen mit diesem verkauft wurden.
public static Map<String, Map<String, Long>>
toMap(Collection<Set<String>> sales) {
return sales.stream()
.flatMap(set -> set.stream()
.flatMap(p -> set.stream()
.filter(q -> !p.equals(q))
.map(q -> new AbstractMap.SimpleEntry<>(p, q))
)
)
.collect(Collectors.groupingBy(e -> e.getKey(),
Collectors.groupingBy(e -> e.getValue(),
Collectors.counting())));
}
So wie map aus jedem Eintrag genau einen neuen Eintrag macht, macht flatMap
aus jedem Eintrag beliebig viele (auch keinen) neuen Eintrag. Im Beispiel wird
mittels flatMap zwei Mal ineinander geschachtelt über die Produkte pro Verkauf iteriert, wobei set für die Menge der Produkte eines Verkauf steht, p (aus
einer Iteration) und q (aus einer anderen Iteration) für je ein Produkt innerhalb
eines Verkaufs. Über filter werden jene q entfernt, die gleich den entsprechenden p sind, weil nur gezählt werden soll, wie viele andere Produkte q zusammen
mit p verkauft wurden. Über map werden die p und q zu Paaren zusammengefasst. Da es in Java keine standardmäßig vordefinierten Klassen für Paare gibt
und wir die Einführung eigener Klassen vermeiden wollen, verwenden wir dafür
AbstractMap.SimpleEntry, eine Klasse, die eigentlich für Key-Value-Paare in
Maps vorgesehen ist. Weil wir am Ende Objekte von Map erzeugen wollen, ist
das nicht ganz unpassend. Aufgrund von flatMap entsteht ein einziger Strom
mit p-q-Paaren, unabhängig davon, aus welchem Verkauf ein Paar stammt.
Schließlich müssen wir die Ergebnisse nur mehr über collect zusammenfassen.
Zu diesem Zweck bietet die Klasse Collectors umfangreiche Unterstützung.
Es hat sich bewährt, sich bei der Auswahl geeigneter Methoden vom gewünschten Typ des Ergebnisses leiten zu lassen. Wir brauchen ein Ergebnis vom Typ
Map, was die Auswahl erheblich reduziert. Bei genauerer Betrachtung bleibt nur
die Methode groupingBy, deren beide Parameter beschreiben, wie der Schlüssel und der damit assoziierte Wert berechnet werden. Der Schlüssel soll das p
in einem p-q-Paar sein, das wir mittels getKey aus dem Paar auslesen. Der
zweite Parameter von groupingBy iteriert für jedes p über das entsprechende
p-q-Paar. Die Werte unserer Map sollen wieder Objekte von Map sein, was zu
einer weiteren Anwendung von groupingBy führt. Nun sind die Schlüssel die q
in jedem p-q-Paar, die wir mittels getValue auslesen. Schließlich müssen wir
noch den Wert des Integer aus einem Strom an p-q-Paaren ermitteln, wobei
jedes p und jedes q für die Ermittlung eines Werts gleich ist. Dafür könnten
237
5 Applikative Programmierung und Parallelausführung
wir die Methode reducing aus Collectors mit einem geeigneten Lambda verwenden. Es geht aber einfacher: Die Methode Collectors.counting zählt die
Paare und ermittelt damit genau das Ergebnis, das wir haben wollen.
Das Programm ist kurz und mit etwas Erklärung leicht nachvollziehbar. Aber
viele Leute, die mit der prozeduralen Programmierung vertraut sind, nicht jedoch mit der applikativen, werden das Gefühl haben, dass Wesentliches in der
Beschreibung fehlt. Was ist das Argument von collect? Es bringt keinen Erkenntnisgewinn, zu wissen, dass es ein Collector ist. Das, was dahinter steckt,
bleibt abstrakt. An solche Abstraktionen müssen wir uns in der applikativen
Programmierung gewöhnen. Wir müssen auch nicht wissen, welche Art von Map
von groupingBy erzeugt wird. Vorteile ergeben sich vor allem dann, wenn wir
gar nicht zu verstehen versuchen, wie die abstrakten Programmteile funktionieren, so lange sie das tun, was wir von ihnen erwarten.
Folgendes Beispiel löst zum Vergleich die gleiche Aufgabe auf ähnliche Weise
mit Lambdas, aber ohne Streams:
public static Map<String, Map<String, Long>>
toMap2(Collection<Set<String>> sales) {
Map<String, Map<String, Long>> res = new HashMap<>();
sales.forEach(set ->
set.forEach(p -> {
Map<String, Long> map = res.computeIfAbsent(p,
k -> new HashMap<>());
set.forEach(q -> {
if (!p.equals(q))
map.compute(q, (k,v) -> v==null ? 1 : v+1);
});
})
);
return res;
}
Statt Schleifen werden forEach-Methoden verwendet, die im Wesentlichen das
Gleiche machen wie Schleifen, aber nicht auf Seiteneffekte angewiesen sind.
Anders als mit Streams, die auf Lazy-Evaluation beruhen, verwenden wir hier
Eager-Evaluation, also die sofortige Berechnung. Zum schrittweisen Aufbau
brauchen wir eine Datenstruktur wie res daher von Anfang an, nicht erst am
Ende. Diese Lösung ist nicht frei von Seiteneffekten, weil Daten in die HashTabellen gefüllt und bestehende Daten verändert werden. Aber alle Seiteneffekte sind auf abstrakte Datentypen (Hash-Tabellen) beschränkt, von denen wir
wissen, dass Kommunikation über Variablen nur über entsprechende Zugriffsmethoden möglich ist. Es gibt keine destruktive Zuweisung in der Methode
selbst, auch weil Lambdas das erzwingen, da wir sonst in den Lambdas nicht
auf die Variablen zugreifen könnten. Aus diesem Grund verwenden wir Methoden wie computeIfAbsent und compute für Zugriffe auf die Hash-Tabellen; mit
üblichen Methoden wie put und get könnten wir das Gleiche nur zusammen
238
5.1 Lambdas und Java-8-Streams
mit destruktiven Veränderungen von Variablen erreichen. Lambdas in Methoden wie compute ziehen Berechnungen, die bei Verwendung von put und get
außerhalb erfolgen müssten, in die Hash-Tabelle hinein.
Es stellt sich die Frage, was wir mit Streams machen können, was ohne sie
nicht geht. Die Antwort ist ähnlich wie bei den Lambdas: Nichts. Es geht nicht
ums Erhöhen der Mächtigkeit der Sprache, sondern darum, eine zusätzliche Abstraktionsebene einzuziehen. Mit entsprechender Erfahrung kann das Denken
in Streams und den dahinter stehenden Mustern Komplexität aus Aufgaben
nehmen, sodass sie effizienter lösbar sind. So wie die strukturierte Programmierung das Programmieren auf das Kombinieren weniger einfacher Denkmuster
reduziert, können Streams das Programmieren auf andere, vor allem für algorithmisch komplexe Aufgaben noch einfachere Denkmuster reduzieren.
5.1.3 Applikative Programmierung in der Praxis
Fassen wir einige Erfahrungen bei der Programmierung mit Java-8-Streams und
Lambdas zusammen:
• Die Abarbeitung folgt einem fixen Schema: Ausgangspunkt ist eine Ansammlung an Daten, Einträge sind weitgehend unabhängig voneinander.
Einträge werden in beliebig vielen Schritten umgeformt, jeder Eintrag für
sich (allgemein als Map bezeichnet). Die umgeformten Einträge werden
am Ende aufgesammelt und in das gewünschte Format gebracht (als Reduce bezeichnet). Das gesamte Schema nennt sich daher Map-Reduce.
• Viele Programmieraufgaben sind nach dem Map-Reduce-Schema lösbar.
• Es reicht eine (nach einem gewissen Einlernaufwand) überschaubar kleine
Menge an vorgefertigten Funktionen höherer Ordnung angewandt auf vergleichsweise einfache Lambdas, um nur damit (ohne komplexe eigene Methoden schreiben zu müssen) eine große Zahl von Map-Reduce-Aufgaben
zu lösen – Kombinieren bestehender Funktionen statt Entwickeln eigener
Funktionen. Das ergibt eine sehr effiziente Form der Programmierung.
• Map-Reduce basiert auf dem funktionalen Paradigma. Häufig müssen andere Methoden eingesetzt werden, als die sonst in Java üblichen, weil
veränderliche Variablen aus der Umgebung in Lambdas nicht verwendbar
sind (in Map etwa compute statt einer Kombination aus get und put).
• Generizität spielt eine große Rolle. Typparameter und Typen, die Typparameter ersetzen, stehen nur an wenigen Stellen explizit im Programm,
die meisten werden über Typinferenz ermittelt und auf Korrektheit geprüft. Erst in einer fertig ausprogrammierten Stream-Anwendung sind die
Typen in sich konsistent. In unvollständigen Ausdrücken kann eine IDE
oft keinen Sinn erkennen, Methoden nicht den richtigen Typen zuordnen
und keine brauchbaren Vorschläge machen.
239
5 Applikative Programmierung und Parallelausführung
• Wenn Ausdrücke so weit ausgereift sind, dass alle Typen in sich konsistent
sind, dann sind diese Ausdrücke häufig auch inhaltlich fehlerfrei. Typkonsistenz ist in diesem Fall (wegen der komplexen Typabhängigkeiten) ein
recht zuverlässiger Hinweis darauf, dass alles zusammenpasst. Fehlende
Typkonsistenz kann Hinweise darauf liefern, was noch zu verbessern ist,
kann aber auch zu Fehlinterpretationen führen.
• Funktionale Interfaces, die für Lambdas stehen, enthalten keine über Signaturen hinausgehende Informationen über das erwartete Verhalten der
Lambdas, also keine Zusicherungen. Stattdessen sind alle der Signatur entsprechenden Lambdas akzeptabel. Nur auf diese Weise ist Typkonsistenz
ein guter Indikator für Korrektheit. Aufgrund umfangreicher Typinferenz
wäre es praktisch unmöglich, die Konsistenz von Zusicherungen händisch
zu prüfen (strukturelle Abstraktion 6= nominale Abstraktion und daher
funktionale Abstraktion 6= objektorientierte Abstraktion).
• Das Map-Reduce-Schema ist nicht die einzig mögliche Form der applikativen Programmierung, wenn auch eine wichtige. So wie Java-8-Streams
auf Map-Reduce zugeschnitten sind, kann zu jedem beliebigen Programmierschema (nicht notwendigerweise auf Iteratoren beruhend) eine Menge von Klassen mit Funktionen höherer Ordnung entwickelt werden, die
dieses Schema auf abstrakte Weise unterstützen. Häufig sind das sehr
anwendungsspezifische Schemata. Die Entwicklung derartiger Funktionen
höherer Ordnung in der nötigen Qualität kann sehr aufwändig und fordernd sein, allerdings wird die Programmierung im entsprechenden Schema damit möglicherweise stark vereinfacht. Es entsteht quasi eine eigene
Sprache innerhalb der Programmiersprache. Jedes Schema hat andere Eigenheiten, aber alle oben genannten Punkte, die sich nicht direkt auf
Map-Reduce beziehen, werden in jedem Schema zutreffen.
Ein bekanntes Sprichwort besagt: „Wer (nur) einen Hammer hat, sieht in
jedem Problem einen Nagel.“ Das lässt sich leicht umformen in: „Wer (nur)
mit Java-8-Streams umgehen kann, betrachtet jedes Problem als Map-ReduceProblem.“ Fast jede Aufgabe lässt sich mehr oder weniger gut nach diesem
Schema lösen, weil ja die meisten Programme Input aufsammeln und auf Output abbilden bzw. zu Output reduzieren. Wer es gewohnt ist, mit Streams zu
arbeiten, ist in der Regel auch sehr kreativ darin, Wege zu finden, um Aufgaben
nur mit vorhandenen Methoden und kleinen Ergänzungen über Lambdas nach
dem Map-Reduce-Schema recht effizient zu lösen. Von dieser Kreativität kommt
die Mächtigkeit des eigentlich simplen Werkzeugs, gleichzeitig ist das aber auch
das größte Manko: Leute, die das Programm lesen, können die kreativen Ideen
dahinter nur schwer erkennen und das Programm kaum verstehen.
Faustregel: In nichttrivialen applikativen Programmteilen sollen wir
Ideen hinter Vorgehensweisen durch Kommentare skizzieren. Zusicherungen auf dabei verwendeten kleinen Hilfsmethoden (Lambdas)
sind dagegen zu vermeiden.
240
5.1 Lambdas und Java-8-Streams
Auch wenn der Zweck der Beschreibung von Ideen nachvollziehbar ist, scheint
diese Faustregel auf den ersten Blick in krassem Widerspruch zu den Faustregeln
zu stehen, die wir im Zusammenhang mit der objektorientierten Programmierung betrachtet haben. Dort sind Zusicherungen auf Methoden ein wesentlicher
Programmteil, während Kommentare zur Beschreibung des Programmablaufs
häufig unnötig sind. Auf den Inhalt bezogen ähneln die Faustregeln einander
jedoch: Das, was wir in der applikativen Programmierung unter der „Idee“ verstehen, haben wir in der objektorientierten Programmierung als Abstraktion
bezeichnet; genau das ist in jedem Paradigma klar zu beschreiben. Während
Abstraktionen in der objektorientierten Programmierung deutlich sichtbar als
Klassen mit ihren Methoden (und Variablen) dargestellt werden, haben wir in
der applikativen Programmierung keine entsprechend eindeutig identifizierbaren Programmstellen, an denen die Abstraktion passiert. Die Umsetzung einer
Idee besteht ja nur aus Aufrufen vorgefertigter Funktionen, weswegen die Beschreibung der Idee nur bei diesen Aufrufen stehen kann. In gewisser Weise
übernehmen Funktionen höherer Ordnung die Rolle von Kontrollstrukturen in
der imperativen Programmierung und Lambdas entsprechen Ausdrücken oder
Anweisungen in den Kontrollstrukturen. In der objektorientierten Programmierung vermeiden wir meist Kommentare auf einzelnen Teilen von Kontrollstrukturen (ausgenommen eventuell komplexere Schleifeninvarianten) weil diese Teile
in der Regel auch ohne Kommentare gut lesbar sind und Kommentare den Lesefluss stören würden. Die gleiche Argumentation trifft auch auf Lambdas zu.
Zusätzlich ergibt sich bei Lambdas das Problem, dass wir nicht im Detail wissen, wie die Funktionen höherer Ordnung diese Lambdas verwenden, sodass ein
als Zusicherung zu verstehender Kommentar von uns fast gar nicht überprüfbar wäre. Der andere Umgang mit Kommentaren ist eine direkte Folge einer
anderen Form von Abstraktion, nicht nur eine Konvention, die sich im Laufe
der Zeit herausgebildet hat.
Faustregel: Im Umfeld applikativer Programmteile sind Variablen so
zu verwenden, als ob sie final wären.
Destruktive Zuweisungen könnten sich unkontrollierbar negativ auf scheinbar
nicht betroffene Programmteile auswirken. Beim Einsatz von Lambdas wird
das deutlich, weil sie nicht auf änderbare Variablen aus der Umgebung zugreifen dürfen. Ausgeführt werden Lambdas ja an anderen Stellen und zu anderen
Zeitpunkten als sie eingeführt werden. Diese Faustregel impliziert, dass destruktive Zuweisungen auch auf Variablen, die in keinen Lambdas verwendet werden,
vermieden werden sollen. Einerseits führen Programmänderungen leicht dazu,
dass Variablen später doch in Lambdas benötigt werden, andererseits geht es
um die Denkweise. Eine auf Zustandsänderungen durch direkte Zuweisungen
beruhende Denkweise verträgt sich kaum mit der Verwendung von Lambdas.
Faustregel: Meist ist es vorteilhaft, entweder ganz in einer funktionalen (nicht auf Zustandsänderungen ausgelegten) oder ganz in einer
prozedural-objektorientierten Denkweise zu bleiben.
241
5 Applikative Programmierung und Parallelausführung
In Abschnitt 5.1.2 haben wir zwei Lösungen der gleichen Aufgabe gesehen, die
Methode toMap beruhend auf Java-8-Streams, die Methode toMap2 ohne Streams. Die Variante mit Streams können wir uneingeschränkt dem funktionalen Paradigma zuordnen. Obwohl Methoden aus Objekten aufgerufen werden,
müssen wir bei keinem einzigen Methodenaufruf damit einhergehende Zustandsänderungen bedenken. Dabei spielt es keine Rolle, ob im Hintergrund möglicherweise doch Zustandsänderungen erfolgen. Möglicherweise zählt equals die
Anzahl der Aufrufe mit, aber solche Zustandsänderungen bleiben uns verborgen. Die Variante toMap2 ohne Streams entspricht dagegen einer prozeduralen
Denkweise (obwohl in der Methode selbst keinerlei destruktive Zuweisungen erfolgen), weil der Algorithmus zur Gänze auf schrittweisen Zustandsänderungen
der Datenstruktur beruht. Die Aufgabe ist in beiden Denkweisen gut lösbar.
Eine Schwierigkeit der Variante mit Streams besteht darin, Paare von Strings
zu bilden, die in der anderen Variante nicht nötig sind. Eine Schwierigkeit der
Variante ohne Streams besteht darin, häufig Inhalte von Hash-Tabellen ändern
zu müssen, was in der anderen Variante nicht nötig ist. Die Erfahrung zeigt,
dass es oft eine schlechte Entscheidung ist, einen Teil eines Algorithmus’ mit
Streams und einen anderen Teil ohne Streams zu lösen, weil dann die Schwierigkeiten beider Ansätze gleichzeitig zu lösen wären. Häufig entstehen dennoch
Methoden, die beide Denkansätze mischen, einfach weil kein besserer Lösungsansatz in den Sinn kommt. Eine nachträgliche Überarbeitung solcher Methoden
kann die Qualität manchmal erheblich verbessern.
Um Verwirrungen zu vermeiden, wollen wir die Begriffe etwas klarer abgrenzen: Von einer applikativen Denkweise sprechen wir, wenn es darum geht, ganze
Programme nur aus vorgefertigten Funktionen zusammenzusetzen. Das kann
gut gelingen, wenn wir auf destruktive Zuweisungen verzichten und Lambdas
einsetzen. Da dabei Funktionen eingesetzt werden, gibt es natürlich einen Bezug zur funktionalen Programmierung. Aber nicht jede applikative Denkweise
ist notwendigerweise funktional, sie kann auch prozedural (oder objektorientiert) sein. Von einer funktionalen Denkweise sprechen wir, wenn keinerlei Zustandsänderungen mitbedacht werden müssen. Das impliziert natürlich auch
den Verzicht auf destruktive Zuweisungen und den Einsatz von Lambdas. In
einer prozeduralen Denkweise müssen Zustandsänderungen mitbedacht werden,
unabhängig davon, ob auf direkte destruktive Zuweisungen verzichtet wird und
Lambdas zum Einsatz kommen. Es stimmt nicht, dass eine funktionale Denkweise immer gut und eine prozedurale immer schlecht ist. Aber es stimmt,
dass es in einer applikativen und gleichzeitig funktionalen Denkweise leichter
ist, Programme nur aus vorgefertigten Funktionen zusammenzusetzen als in einer applikativen prozeduralen Denkweise; in einer nicht-applikativen Denkweise
hätten wir das nicht als Ziel. Wenn das Zusammensetzen für eine Aufgabe in
einer prozeduralen Denkweise gut gelingt, kann diese Lösung gegenüber einer
funktionalen auch vorteilhaft sein.
Faustregel: Funktionen (höherer Ordnung) sollen so allgemein wie
möglich sein und Zustandsänderungen lokal halten.
Funktionen in den Stream-Klassen sind mächtig, weil sie sehr allgemein gehalten
242
5.2 Funktionen höherer Ordnung
und auf vielfältige Weise parametrisiert sind. Sie sind hochgradig generisch und
verwenden Lambdas zur Festlegung einzelner Schritte. Die Funktionen lassen
alles offen, was entweder beim Methodenaufruf festgelegt werden kann (Typen
für Typparameter sowie Lambdas) oder als Implementierungsdetail dem Aufrufer nicht bekannt sein muss (etwa die Art der zurückgegebenen Collection).
Dadurch sind die Funktionen nicht nur vielseitig anwendbar, sondern Typprüfungen können auch einen hohen Grad an Zuverlässigkeit garantieren, weil (fast)
keine Annahmen gemacht werden, die über die vom Compiler prüfbaren Informationen in Typen hinausgehen. Damit wird es möglich, sich beim Kombinieren
von Funktionen von der Typkonsistenz leiten zu lassen. Wir wissen, dass Streams intern auf Iteratoren beruhen und daher zustandsbehaftet sind. Aber die
Zustände werden bei üblichen Stream-Anwendungen nicht von außen sichtbar.
Methoden in üblichen Objekten können nicht ganz so allgemein sein, weil die
dahinter stehenden Abstraktionen (etwa über Zusicherungen) festgelegt werden
müssen, sodass statisch prüfbare Typen nur einen Teil der für die Typkonsistenz
nötigen Informationen enthalten. Sie können auch Zustände (je nach Abstraktion) nicht gänzlich verbergen. Dennoch sollten wir auch diese Methoden durch
Parametrisierung so allgemein wie möglich halten, so wie wir das am Beispiel
von compute in Map gesehen haben. Die Existenz dieser Methode zeigt auch,
wie Zustandsänderungen lokal gehalten werden können, obwohl Aufrufer von
den Zuständen wissen und Zustandsänderungen bewusst herbeiführen: Der Ort
der Zustandsänderungen wird über Lambdas vom Aufrufer hin zur aufgerufenen Methode verschoben. Damit werden Seiteneffekte in der Umgebung des
Aufrufers vermieden und die aufgerufene Methode bekommt Kontrolle über den
Zeitpunkt der Zustandsänderung und die dabei verwendeten Werte (Argumente, mit denen Lambdas aufgerufen werden). Das ist in mehrerlei Hinsicht vorteilhaft, passt sehr gut zur objektorientierten Programmierung und ermöglicht
applikative Denkweisen. Dennoch erfordert dies einen Umdenkprozess, weil an
die Stelle der einfachen prozeduralen Denkweise eine auf die applikative Programmierung ausgelegte (prozedurale) Denkweise treten muss.
5.2 Funktionen höherer Ordnung
Java-8-Strems haben in der praktischen Java-Programmierung heute einen so
hohen Stellenwert, dass daneben die zahlreichen anderen Möglichkeiten von
Lambdas beinahe untergehen. Wir wollen uns nun damit beschäftigen, wie wir
Lambdas als Funktionen höherer Ordnung auch ohne Streams einsetzen können.
Damit entwickeln wir etwas, das Kontrollstrukturen in üblichen Programmiersprachen recht nahe kommt, sich aber nicht darauf beschränkt, was Programmiersprachen uns vorgeben.
5.2.1 Nachbildung typischer Kontrollstrukturen
Bedingte Anweisungen zählen zu den wichtigsten Kontrollstrukturen von Java
und fast allen anderen Sprachen, die sehr tief in die Sprache integriert sind.
243
5 Applikative Programmierung und Parallelausführung
Zunächst zeigen wir, dass wir in Java (und allen objektorientierten Sprachen)
auch ohne vordefinierten Typ boolean und ohne vorgegebene if-Anweisungen
und ähnliche Kontrollstrukturen in der Lage sind, mit Booleschen Ausdrücken
(in einem weiteren Sinn) zu arbeiten. Wir werden aber auch sehen, dass dies
einen tiefen Einschnitt in die Sprache bedeutet und wir besonders vorsichtig
agieren müssen, um semantische Details korrekt darzustellen. Die Basis für
Fallunterscheidungen bildet natürlich dynamisches Binden:
interface Bool {
<A> A ifThenElse(A t, A f);
default Bool negate() {
return ifThenElse(False.VALUE, True.VALUE);
}
default Bool and(Bool b) {
return ifThenElse(b, False.VALUE);
}
default Bool or(Bool b) {
return ifThenElse(True.VALUE, b);
}
default Bool isEqual(Bool b) {
return ifThenElse(b, b.negate());
}
}
final class True implements Bool {
private True() {}
public static final True VALUE = new True();
public <A> A ifThenElse(A t, A f) { return t; }
}
final class False implements Bool {
private False() {}
public static final False VALUE = new False();
public <A> A ifThenElse(A t, A f) { return f; }
}
Die Konstruktoren von True und False sind private, damit außer True.VALUE
und False.VALUE keine weiteren Objekte dieser Klassen erzeugt werden können.
Die Implementierungen des bedingten Ausdrucks ifThenElse ist sehr einfach:
In True wird der eine Parameter zurückgegeben, in False der andere. DefaultImplementierungen typischer Boolescher Operationen im Interface Bool werden
durchwegs auf ifThenElse zurückgeführt.
Wenn wir Bool praktisch einsetzen, erkennen wir ein Problem: Wir müssen
in jedem Aufruf von ifThenElse zwei Argumente spezifizieren, die beide sofort,
noch vor Ausführung von ifThenElse ausgewertet werden. Das ist nicht die übliche Semantik einer bedingten Anweisung. Wir erwarten, dass nur eines der beiden Argumente ausgewertet wird, für True das erste und für False das zweite.
Entsprechendes gilt auch für die Methoden and und or, die in der gegebenen Implementierung das Verhalten der in Java vordefinierten Operatoren & und | auf
244
5.2 Funktionen höherer Ordnung
boolean haben, nicht das der meist eingesetzten Kurzschlussoperatoren && und
||. Mit Funktionen höherer Ordnung ist dieses Problem lösbar. Beispielsweise fügen wir die Anweisung „import java.util.function.Supplier;“ und
folgende Methoden zu Bool hinzu:
default <T> T getIfThenElse(Supplier<T> t, Supplier<T> f) {
return ifThenElse(t, f).get();
}
default Bool andThen(Supplier<Bool> b) {
return getIfThenElse(b, () -> False.VALUE);
}
default Bool orElse(Supplier<Bool> b) {
return getIfThenElse(() -> True.VALUE, b);
}
Das funktionale Interface Supplier<T> enthält nur die parameterlose Methode
T get(). Einem Aufruf von getIfThenElse übergeben wir nicht direkt die Werte, zwischen denen gewählt werden soll, sondern zwei parameterlose Lambdas,
die die entsprechenden Werte zurückgeben. Der Aufruf von ifThenElse wählt
eines der Lambdas aus, erst der Aufruf von get() bringt das gewählte Lambda
zur Ausführung. Damit entspricht getIfThenElse viel eher einer if-Anweisung
in Java und andThen sowie orElse entsprechen den Kurzschlussoperatoren &&
und ||. Beispielsweise gibt ein Aufruf
True.VALUE.orElse(() -> False.VALUE)
.getIfThenElse(() -> "True", () -> "False")
als Ergebnis "True" zurück, ohne ()->False.VALUE und ()->"False" auszuwerten. Dieser Ansatz führt zu vielen Funktionen. Wir kommen unvermeidlich
in den Bereich der funktionalen Programmierung.
Bool ist nur eine Nachbildung von boolean, nicht äquivalent zu boolean.
Die vielen vordefinierten Operatoren und Methoden, die auf boolean beruhen,
sind nicht automatisch für Bool verfügbar. Für eine vollständige Nachbildung
müssten wir alle diese Operatoren und Methoden neu schreiben. Auf diesen Aufwand verzichten wir gerne. Die Beispiele sollen nur ein Gefühl dafür vermitteln,
wie solche Nachbildungen aussehen könnten. Simple Konvertierungsfunktionen
können eine Brücke zwischen Bool und boolean schlagen (innerhalb von Bool):
default boolean toBoolean() {
return this == True.VALUE;
}
static Bool fromBoolean(boolean b) {
return b ? True.VALUE : False.VALUE;
}
Lambdas spielen in getIfThenElse eine ähnliche Rolle wie Iteratoren in Java8-Streams: Sie sorgen dafür, dass Ergebnisse nicht gleich berechnet werden, sondern erst später auf Anfrage, wenn sich ein Bedarf dafür ergibt. Ergibt sich kein
245
5 Applikative Programmierung und Parallelausführung
Bedarf, bleiben Ausdrücke unausgewertet. Der Zeitpunkt der Auswertung ist in
getIfThenElse und damit auch in andThen und orElse fix festgelegt, um eine größtmögliche Nähe zur Semantik einer if-Anweisung in Java herzustellen.
Da wir nun schon einfache Möglichkeiten zur Verschiebung von Ausführungszeitpunkten kennen, lassen sich die Zeitpunkte auch deutlich weiter, beinahe
beliebig weit nach hinten schieben. Davon wird in der funktionalen Programmierung häufig Gebrauch gemacht. Das folgende Interface kann als Variante
von Bool mit Lazy-Evaluation gesehen werden:
import java.util.function.*;
@FunctionalInterface
interface LazyBool extends Supplier<Bool> {
static final LazyBool TRUE = () -> True.VALUE;
static final LazyBool FALSE = () -> False.VALUE;
default <T> Supplier<T> ifThenElse(Supplier<T> t,
Supplier<T> f) {
return () -> get().ifThenElse(t, f).get();
}
default LazyBool negate() {
return () -> get().ifThenElse(False.VALUE, True.VALUE);
}
default LazyBool and(LazyBool b) {
return () -> get().ifThenElse(b, FALSE).get();
}
default LazyBool or(LazyBool b) {
return () -> get().ifThenElse(TRUE, b).get();
}
default LazyBool isEqual(LazyBool b) {
return () -> get().ifThenElse(b, b.negate()).get();
}
}
Eine Konsequenz aus der Verwendung von Lazy-Evaluation ist, dass fast alle
Werte, die im Programm vorkommen, Funktionen bzw. Lambdas sind, so wie
TRUE ein Lambda ist. Wer einen entsprechenden Programmierstil gewohnt ist,
findet daran nichts Ungewöhnliches. Ein Großteil aller Berechnungen besteht
daraus, ein Netzwerk an Verbindungen zwischen Funktionen aufzubauen, die
erst am Ende (wenn für eine Ausgabe konkrete Werte, die keine Funktionen
sind, benötigt werden) zur Ausführung kommen.
Faustregel: Es gibt zwei sinnvolle Ausführungszeitpunkte für Funktionen: so früh wie möglich (Eager-Evaluation) oder so spät wie
möglich (Lazy-Evaluation). Andere Zeitpunkte sind eher zu meiden.
In dieser Faustregel nehmen wir an, dass zur Erhaltung der Semantik nötige Verschiebungen der Ausführungszeitpunkte wie in getIfThenElse, andThen und
orElse noch zu Eager-Evaluation zählen, frühere Ausführungszeitpunkte also
246
5.2 Funktionen höherer Ordnung
nicht möglich sind. Eager-Evaluation ist damit begründbar, dass wir beim Programmieren die genauen Ausführungszeitpunkte stets im Kopf haben und stets
wissen, wann was passiert. So werden Programme verständlich und der Verwaltungsaufwand auf ein Minimum reduziert (was häufig zu guter Laufzeiteffizienz
führt). Bei Lazy-Evaluation verzichten wir dagegen auf das Nachverfolgen der
genauen Ausführungszeitpunkte, wir haben nur die logischen Zusammenhänge im Kopf. Ein Verzicht auf die Kontrolle der Zeitpunkte macht Programme
einfach verständlich, der höhere Verwaltungsaufwand wird oft dadurch kompensiert, dass keine unnötigen Berechnungen ausgeführt werden (was häufig auch
zu ausreichend guter Laufzeiteffizienz führt). Andere Ausführungszeitpunkte
sind meist schlecht gewählt, da sie Programme schwerer verständlich machen
(Ausführungszeitpunkte müssen kontrolliert werden, sind aber nur schwer kontrollierbar) und die Laufzeiteffizienz oft schlecht ist (viel Verwaltungsaufwand,
unnötige Berechnungen nicht vollständig eliminiert).
Erkenntnisse aus der Nachbildung bedingter Ausführungen lassen sich auf
andere Kontrollstrukturen übertragen. Besonders einfach ist die Nachbildung
der Hintereinanderausführung durch Zusammensetzen von zwei Lambdas zu
einem (hier als Klassenmethode in irgendeiner Klasse):
public static <T,V,R> Function<T,R>
compose(Function<V,R> f, Function<T,V> g) {
return t -> f.apply(g.apply(t));
}
Das dabei verwendete funktionale Interface Function<T,R> aus dem Paket
java.util.function enthält die Methode R apply(T t). Zurück kommt ein
Lambda, das zuerst g auf das Argument t des Lambdas anwendet, danach f
auf das Ergebnis davon. Beispielsweise führt
compose(String::length, String::trim).apply(" a ")
" a ".trim().length() aus und gibt 1 zurück. Der Ausführungszeitpunkt des
durch compose erzeugten Lambdas, das ist der Zeitpunkt, an dem apply ausgeführt wird, lässt sich beliebig weit in die Zukunft verschieben.
Neben sequenzieller und bedingter Ausführung ist die wiederholte Ausführung ein wesentliches Element der strukturierten Programmierung. Mangels
destruktiver Zuweisung in der funktionalen Programmierung bieten sich dafür
wiederholte Iterationen durch Rekursion an:
public static <T> Function<T,T>
loopWhile(Function<T,Bool> cond,
Function<T,T> iter) {
Function<T,T> doIt = i -> loopWhile(cond, iter)
.apply(iter.apply(i));
Function<T,T> done = i -> i;
return init -> cond.apply(init)
.ifThenElse(doIt, done).apply(init);
}
247
5 Applikative Programmierung und Parallelausführung
Die Schleifenbedingung cond und eine Funktion iter, die einen Iterationsschritt
festlegt, werden als Parameter an loopWhile übergeben. Das Ergebnis ist ein
Lambda, das durch einen Aufruf von apply mit einem Anfangswert init als
Parameter zur Ausführung gebracht wird. Erfüllt init die in cond festgelegte
Bedingung, wird doIt auf init angewandt, sonst done. Dabei ist done ein
Lambda, das einfach nur das Argument unverändert zurückgibt; doIt macht
dagegen den rekursiven Aufruf von loopWhile angewandt auf das Ergebnis einer
Anwendung von iter auf init. Insgesamt wird also wiederholt immer wieder
iter angewandt, bis eine Anwendung von cond als Ergebnis False liefert. Hier
ist ein Beispiel für eine Anwendung von loopWhile:
loopWhile((String s) -> Bool.fromBoolean(s.charAt(0)==’ ’),
s -> s.substring(1))
.apply(" a")
Die Schleifenbedingung ist erfüllt, solange das erste Zeichen der Zeichenkette im
Parameter ein Leerzeichen ist; jeder Iterationsschritt entfernt dieses. Angewandt
auf " a" wird also "a" zurückgegeben. In diesem Beispiel ist es notwendig, in
zumindest einem der beiden Lambdas den Typ des Parameters hinzuschreiben, weil Typinferenz über die Typparameter nur feststellen kann, dass beide
Parameter vom gleichen Typ sind, aber nicht von welchem. Ohne explizite Deklaration von String könnten wir nicht auf die Methoden von String zugreifen.
5.2.2 Funktionale Elemente in Java
Wir haben Kontrollstrukturen nachgebildet, um den Zusammenhang mit Funktionen höherer Ordnung zu sehen und einige dabei eingesetzte Programmiertechniken kennenzulernen. Praktisch werden wir kaum bestehende Kontrollstrukturen nachbilden, sondern neue Funktionalität hinzufügen. Wir müssen
uns nicht auf die funktionale Programmierung beschränken, da beliebige Methoden Lambdas verwenden können; nur die Lambdas selbst sollten sich an der
funktionalen Programmierung orientieren. Hier ist ein Beispiel, das ein Lambda
auf jeden Array-Eintrag anwendet und das Array dabei verändert:
public static <T> void arrayMap(T[] xs, Function<T,T> f) {
for (int i = 0; i < xs.length; i++)
xs[i] = f.apply(xs[i]);
}
Es ist zwar nicht schwer, Methoden wie diese zu schreiben, aber häufig ist das
gar nicht nötig. Sehr viele sinnvolle Methoden sind schon in Standardbibliotheken vordefiniert. Eine Methode wie arrayMap gibt es zwar nicht genau in dieser
Form, aber eine vordefinierte Methode lässt sich auf diese Weise verwenden:
public static <T> void arrayMap2(T[] xs, Function<T, T> f) {
Arrays.setAll(xs, i -> f.apply(xs[i]));
}
248
5.2 Funktionen höherer Ordnung
In Arrays unterscheidet sich setAll von unserem arrayMap im Wesentlichen
nur dadurch, dass das Lambda als Parameter den Index des Array-Eintrags
erwartet, nicht den Wert an diesem Index. Solche kleinen Unterschiede lassen
sich beim Aufruf leicht anpassen.
Faustregel: Vor dem Implementieren einer eigenen Funktion höherer Ordnung sollten wir uns vergewissern, dass nicht eine ähnliche
Methode schon standardmäßig vordefiniert ist. Die vordefinierte Methode ist zu bevorzugen.
Tatsächlich sind viele solche Methoden vorimplementiert. Der Grund liegt darin, dass Funktionen höherer Ordnung von Natur aus meist allgemein gehalten,
also nicht anwendungsspezifisch sind. Da immer wieder gleiche oder ähnliche
Funktionen höherer Ordnung gebraucht werden (im Gegensatz zu anwendungsspezifischen Methoden), ist eine überschaubare Menge entsprechender Methoden ausreichend. Vordefinierte Methoden sind von hoher Qualität, weil sie in
allen Details durchdacht und sehr ausgiebig, auch im Praxiseinsatz, getestet
wurden. Die Schwierigkeit liegt darin, dass eben nur ähnliche Methoden vorimplementiert sind, nicht genau die erwarteten. Wir brauchen etwas Fantasie,
um die Ähnlichkeit zu erkennen. Lambdas lassen sich leicht anpassen, wodurch
eine schwach ausgeprägte Ähnlichkeit ausreicht und eine einzige Methode ein
breites Anwendungsspektrum erschließen kann. Wer die wichtigsten vordefinierten Funktionen höherer Ordnung kennt und in der Lage ist, Ähnlichkeiten
richtig zu erkennen, kann sehr effizent programmieren und dabei Programme
von hoher Qualität schreiben. Sowohl das Kennen der Methoden (deren Menge
ständig erweitert wird) als auch das Erkennen von Ähnlichkeiten hängt von der
Erfahrung ab.
Optional. Die Verfügbarkeit von Funktionen höherer Ordnung lässt Programmiertechniken, die bislang nur in der funktionalen Programmierung verbreitet
waren, auch in die Java-Programmierung und allgemein in die objektorientierten Programmierung einsickern. Java-8-Streams sind ein Beispiel dafür. Nun
wollen wir im Zusammenhang mit der vordefinierten Klasse Optional eine
weitere solche Programmiertechnik betrachten. Ein Objekt von Optional<T>
enthält einfach nur ein Objekt vom Typ T oder ist leer, was im Wesentlichen
gleichbedeutend damit ist, dass das enthaltene Objekt null ist. Methoden von
Optional bieten, ohne das direkt zu sagen, eine Reihe von Möglichkeiten für
den Umgang mit null an. Beispielsweise gibt die Methode isPresent() genau
dann true zurück, wenn das enthaltene Objekt nicht null ist. Diese Methode
wird meist als Bedingung in einer bedingten Verzweigung eingesetzt, etwa in
der gleichen Bedeutung wie x!=null auf einem enthaltenen Wert x. Interessanter sind Methoden von Optional, die eine Weiterverarbeitung ohne (direkt
sichtbare) bedingte Programmverzweigung ermöglichen. So liefert die Methode T orElse(T other) als Ergebnis das enthaltene Objekt x falls es existiert,
andernfalls den Wert other; für other!= null bekommen wir also immer ein
249
5 Applikative Programmierung und Parallelausführung
Ergebnis ungleich null. Die Variante orElseGet nimmt statt other ein Lambda und gibt bei x==null das Ergebnis einer Ausführung des Lambdas zurück.
Die Variante orElseThrow nimmt ebenfalls ein Lambda, das bei x==null eine
Exception wirft. Die Methode ifPresent liefert kein Ergebnis, sondern führt
bei x!=null einfach nur das als Parameter übergebene Lambda aus. Praktisch
von größerer Bedeutung ist die Methode map mit einem Parameter (Lambda) vom Typ Function<T,U> (etwas vereinfacht), die ein neues Objekt von
Optional<U> zurückgibt; das im Ergebnis-Optional enthaltene Objekt ist das
Ergebnis einer Anwendung des Lambdas auf das Objekt im ursprünglichen Optional (falls ein solches Objekt existiert) oder sonst ein leeres Optional. Mit
Hilfe von map können wir umfangreiche Berechnungen auf Werten durchführen,
ohne jemals darauf zu achten, ob diese Werte überhaupt existieren.
Optional ist eine einfache Klasse mit recht simpler Funktionalität, die dennoch von großer praktischer Bedeutung ist. Wie wir in Abschnitt 5.2.1 gesehen
haben, sollen im Zusammenhang mit der funktionalen Programmierung und
Lazy-Evaluation Ausführungszeitpunkte so weit wie möglich auf später verschoben werden. Eine Programmverzweigung verlangt, dass wir die Bedingung,
etwa x==null, ausführen, um feststellen zu können, welcher Programmzweig
zu wählen ist. Optional bietet, vor allem zusammen mit map, eine einfache
Möglichkeit, diese Entscheidung auf später zu verschieben. Es ist eine gängige
Praxis, in der funktionalen Programmierung in Java auf den expliziten Umgang mit null so weit wie möglich zu verzichten und stattdessen Optional
einzusetzen. Das erleichtert Lazy-Evaluation. Außerdem kann Optional dazu
dienen, den Zeitpunkt des Werfens einer Exception auf später zu verschieben
oder gänzlich zu vermeiden (weil der Programmteil, in dem die Exception auftreten würde, gar nicht zur Ausführung kommt).
Faustregel: Zusammen mit Lazy-Evaluation soll auf den expliziten
Umgang mit null verzichtet und stattdessen Optional eingesetzt
werden. Zusammen mit Eager-Evaluation ist Optional wenig sinnvoll und ein expliziter Umgang mit null vorteilhaft.
Da wir in einem Programmteil entweder nur Lazy-Evaluation oder nur EagerEvaluation (nicht gemischt) einsetzen, ist es sinnvoll, entweder nur Optional
einzusetzen oder nur explizit mit null umzugehen (nicht gemischt).
Folgendes Beispiel setzt Optional zusammen mit einem Stream ein:
public static Optional<FileReader> openFile(String... path) {
return Stream.of(path)
.map(String::trim)
.reduce((s, t) -> s + "/" + t)
.map(s -> {try{return new FileReader(s);}
catch(java.io.IOException e){return null;}});
}
Die einzelnen Elemente von path werden im Stream über das erste map bearbeitet (Leerzeichen am Rand entfernt) und danach über reduce zu einer
250
5.2 Funktionen höherer Ordnung
Zeichenkette mit "/" zwischen den Elementen reduziert. Diese Variante von
reduce verwendet als Anfangswert das erste Stream-Element, wodurch ein leerer Stream nicht bearbeitbar ist. Daher gibt reduce ein Ergebnis vom Typ
Optional<String> zurück. Das zweite map wird im Optional-Objekt ausgeführt. Dabei wird die von reduce erzeugte Zeichenkette als Datei-Pfad interpretiert und ein FileReader geöffnet. Falls keine Datei öffenbar ist, gibt
das Lambda in map nach Abfangen der Exception null zurück, was zu einem
leeren Optional führt. Das Ergebnis von map und damit auch von openFile
ist ein Optional-Objekt, das entweder einen FileReader enthält, oder leer ist,
wenn path leer ist (Lambda in map nicht aufgerufen) oder keine Datei öffenbar ist (Lambda in map liefert null). Ein Aufrufer von openFile kann mit dem
Optional-Objekt weiterarbeiten, vielleicht durch einen weiteren Aufruf von map.
Currying. Wie schon in Abschnitt 1.1.2 ausgeführt, sind Funktionen mit nur
einem Parameter ausreichend, um Funktionen mit beliebig vielen Parametern
darzustellen. Die Technik dahinter ist als Currying bekannt, benannt nach Haskell Curry, einem Mathematiker, der viel zu den Grundlagen der funktionalen Programmierung beigetragen hat; auch die Programmiersprache Haskell ist
nach ihm benannt. Die Technik ist einfach: Statt einer Funktion mit zwei Parametern schreiben wir eine Funktion mit nur einem Parameter, die als Ergebnis
eine Funktion zurückgibt, die den zweiten Parameter hat und das eigentliche
Ergebnis berechnet. Wiederholt angewandt lässt sich die Zahl der Parameter
damit beliebig erhöhen. Die beiden folgenden Funktionen f und g machen inhaltlich das Gleiche, aber f hat zwei Parameter und g verwendet Currying:
BiFunction<String,String,String> f = (s, t) -> s + t;
Function<String,Function<String,String>> g = s -> t -> s + t;
Wir sehen hier, dass BiFunction inhaltlich große Ähnlichkeit zu zwei geschachtelten Vorkommen von Function hat. Tatsächlich sind die Typen verschieden,
da es sich um nominale Typen handelt, die nicht in einer Untertypbeziehung
zueinander stehen. Wir können f also nicht dort verwenden, wo g erwartet
wird und g nicht dort, wo f erwartet wird. Aber wir können frei entscheiden,
welche der beiden Varianten wir einsetzen wollen, weil sie inhaltlich das Gleiche machen. Die beiden entsprechenden Lambda-Ausdrücke verursachen etwa
den gleichen Schreibaufwand. Hinsichtlich der Auswertungen dieser Lambdas
ergeben sich jedoch Unterschiede:
String s = f.apply("a", "b");
String t = g.apply("a").apply("b");
Mit Currying werden zwei Funktionen aufgerufen, nicht nur eine. Wir können
aus dieser Gegenüberstellung eine Reihe von Schlussfolgerungen ableiten:
• In Java sind keine funktionalen Interfaces für Funktionen mit mehr als
zwei Parametern vordefiniert, weil wir auch mit Funktionen mit nur einem Parameter alles ausdrücken können. Funktionale Interfaces für zwei
251
5 Applikative Programmierung und Parallelausführung
Parameter gibt es, weil sich viele Funktionen so auf gewohnte Weise ausdrücken lassen, nicht weil sie nötig sind. Wenn wir wollen, können wir
funktionale Interfaces für beliebig viele Parameter schreiben. Das ist aber
kaum sinnvoll. Currying ist die bessere Alternative. Spezielle funktionale Interfaces für parameterlose „Funktionen“ sind dagegen schon sinnvoll
und auch vorhanden; allerdings ist der Begriff „Funktion“ dafür nicht
passend, Namen wie Supplier also sicher besser gewählt.
• Die Syntax von Lambdas ist so ausgelegt, dass Currying keinen zusätzlichen Schreibaufwand verursacht (keine Klammerung nötig) und, wenn
man den Umgang damit gewohnt ist, ganz natürlich aussieht. Ausdrücke
wie a -> b -> ... -> ... sind genau so leicht als Aneinanderreihung
mehrerer Parameter vor einem Rumpf lesbar wie als Ineinanderschachtelung so vieler Lambdas wie -> vorhanden sind. Es besteht kein Unterschied zwischen diesen beiden Lesarten.
• Bei der Auswertung von Lambdas ist die Variante mit Currying etwas
aufwändiger, weil für jeden Parameter ein eigener Aufruf nötig ist. Auch
der Ressourcenverbrauch hinsichtlich Speicher und Laufzeit ist mit Currying etwas größer. Das ist ein Nachteil dieser Technik, der aber durch
optimierende Compiler verkleinert werden kann.
• Currying erhöht die Flexibilität bei der Auswertung. Es wird nicht verlangt, dass alle Argumente, die nötig sind, gleichzeitig an einer bestimmten Stelle im Programm vorliegen, wie das bei einem einzigen Methodenaufruf nötig wäre. Wir können die Aufrufe auch schrittweise an verschiedenen Programmstellen machen. Beispielsweise übergeben wir an einer
Programmstelle nur ein Argument und reichen das Ergebnis (ein Lambda)
an eine andere Programmstelle weiter, wo das nächste Argument vorliegt
und übergeben wird. Eine derartige Vorgehensweise kann die Gesamtzahl
der Parameter in einem Programm reduzieren und effizient sein. Es erfordert jedoch viel Programmiererfahrung, um Programme so organisieren
zu können, dass solche Effekte zum Tragen kommen.
• Typen von Lambdas können zusammen mit Currying sehr umfangreich
und komplex werden. Wenn generische Typen im Wesentlichen nur vom
Compiler durch Typinferenz ermittelt werden, ist das kein Problem. Allerdings kann es aufwändig sein, komplexe Typen etwa bei Variablendeklarationen hinzuschreiben. var-Deklarationen helfen dabei nicht.4
• Komplizierte Typen haben auch Vorteile: Wenn es gelingt, Programme
mit nicht-trivialen Lambdas so zu gestalten, dass alle Typen in sich kon4Seit Java 10 ist es möglich, initialisierte lokale Variablen ohne Typangabe zu deklarieren;
statt dem Typ wird das Schlüsselwort var verwendet. Meist ist das kein Problem, weil der
Typ ohnehin direkt aus der Initialisierung ersichtlich ist. Gerade für komplizierte Typen
sollten wir var jedoch nicht einsetzen, weil die explizite Typinformation die Lesbarkeit
deutlich erhöhen kann. Zusammen mit Lambdas ist var nicht einsetzbar, weil Lambdas
ihre Typinformation aus den expliziten Typdeklarationen beziehen.
252
5.2 Funktionen höherer Ordnung
sistent sind, dann sind diese Programme auch inhaltlich ausreichend gut
durchdacht, um eine Vielzahl möglicher Fehler zu vermeiden.
Kurz zusammengefasst: Wir brauchen keine Angst vor Currying haben. Wer sich
daran gewöhnt hat, wird auf die damit verbundene Flexibilität und gleichzeitig
Sicherheit (durch statische Typisierung) nicht mehr verzichten wollen. Wer die
Programmierung in einer neueren funktionalen Sprache gewohnt ist, wird sich
eine Programmierung ohne Currying kaum vorstellen können. Wer sich aber
nicht daran gewöhnen möchte, kommt in Java derzeit auch noch ohne Currying
ganz gut zurecht.
Pattern-Matching. Aus neueren funktionalen Sprachen ist Pattern-Matching,
vor allem bei Funktionsaufrufen, nicht mehr wegzudenken. Dabei bestimmen
Werte in Parametern, welche Funktion auszuführen ist. Es besteht eine Nähe
zu Multimethoden (Abschnitt 4.4), aber Parameter sind nicht durch Typen,
sondern konkrete Werte festgelegt. Wenn es in Java Pattern-Matching gäbe,
könnte ein Beispiel zur Berechnung der Länge einer Zeichenkette so aussehen:
int strLength("") {return 0;}
int strLength([char c, String s] c+s) {return 1+strLength(s);}
Wir könnten das Programmstück so lesen: Wenn der Parameter gleich dem Literal "" ist, wird die erste Methode ausgeführt und 0 zurückgegeben. Andernfalls
muss der Parameter eine nicht-leere Zeichenkette sein, die als Zusammenfügung
eines Zeichens mit einer Zeichenkette verstehbar ist. Wir müssen nur mehr die
Länge 1 des Zeichens zur Länge der restlichen Zeichenkette addieren. So funktioniert das in Java natürlich nicht, nicht nur aufgrund der für Pattern-Matching
fehlenden Syntax. Wenn wir das Beispiel nach Java übersetzten, würde etwa
folgende, recht ineffiziente Methode entstehen:
int strLength(String s) {
return s.equals("") ? 0 : 1 + strLength(s.substring(1));
}
Problematisch ist, dass strLength kaum zur Abstraktion durch String passt.
Keine Implementierung außerhalb von String kann direkt auf die benötigten
Variablen zugreifen. Innerhalb von String wäre die Methode einfach und effizient zu implementieren; length ist ohnehin vorimplementiert. Der wichtigste
Grund, warum es in Java und den meisten objektorientierten Sprachen kein
Pattern-Matching gibt, ist ein gänzlich anderer Umgang mit Abstraktionen als
in funktionalen Sprachen. Funktionale Sprachen machen die Struktur der Daten
öffentlich sichtbar, wodurch es leicht ist, von überall aus direkt (ohne Methodenaufrufe) auf die einzelnen Zeichen einer Zeichenkette zuzugreifen. Weil die
bestehenden Daten nicht änderbar sind, ist das in der funktionalen Programmierung ein viel kleineres Problem als in der imperativen Programmierung. In
der objektorientierten Programmierung ist Datenabstraktion so wesentlich, dass
es unsinnig wäre, für eine schönere Syntax darauf zu verzichten. In einer abgespeckten Variante beruhend auf Literalen (die ohnehin überall sichtbar sind)
wäre Pattern-Matching natürlich auch in Java denkbar, etwa in dieser Form:
253
5 Applikative Programmierung und Parallelausführung
int strLength("") {return 0;}
int strLength(String s) {return 1 + strLength(s.substring(1));}
Das ist nur eine andere Syntax für bedingte Verzweigungen, Sichtbarkeit bleibt
unberührt, die Ineffizenz nicht beseitigt. Überlegungen zu Multimethoden aus
Abschnitt 4.4 kommen zum Tragen. Wenn wir an dynamisches Binden denken,
löst sich das Problem von alleine: Angenommen, "" wäre das einzige Objekt
eines Untertyps von String; dann könnte die erste Methode in diesem Untertyp
und die zweite in String implementiert sein. Es bleibt nur das Problem, dass
die beiden Methoden an unterschiedlichen Stellen stehen würden.
5.3 Nebenläufige Programmierung in Java
Grundlegende Mechanismen für das Erzeugen von Threads und die Synchronisation in Java haben wir schon in Abschnitt 2.5 betrachtet. Zum besseren Verständnis behandeln wir diese Mechanismen hier noch einmal auf andere Weise.
In der Praxis werden für die nebenläufige Programmierung häufig Sprachmechanismen auf einer etwas höheren Ebene eingesetzt, die wir uns im Anschluss
daran vor Augen führen.
5.3.1 Thread-Erzeugung und Synchonisation in Java
Folgendes Beispiel soll ein Synchronisationsproblem demonstrieren:
public class Counter {
private int i = 0, j = 0;
public void flip() { i++; j++; }
}
Die Variablen i und j sollten stets die gleichen Werte enthalten. Wenn wir jedoch in mehreren nebenläufigen Threads flip in demselben Objekt von Counter
wiederholt aufrufen, kann es vorkommen, dass sich i und j plötzlich voneinander unterscheiden. Den Grund dafür finden wir in der fehlenden Synchronisation: Bei Ausführung des ++-Operators wird der Wert der Variablen aus dem
Speicher gelesen, um eins erhöht und wieder in den Speicher geschrieben. Wird
nun flip in zwei Threads annähernd gleichzeitig ausgeführt, wird von beiden
Threads der gleiche Wert aus der Variablen gelesen, jeweils um eins erhöht,
und von beiden Threads derselbe Wert zurückgeschrieben. Das ist nicht das,
was wir haben wollen, da sich ein Variablenwert bei zwei Aufrufen nur um eins
erhöht hat. Unterschiede zwischen den Werten von i und j ergeben sich, wenn
das nur beim Ändern einer der beiden Variablen passiert.
In einer synchronized-Methode kann das nicht passieren:
public synchronized void flip() { i++; j++; }
In jedem Objekt wird zu jedem Zeitpunkt höchstens eine synchronized Methode ausgeführt. Wenn mehrere Threads flip auf dem gleichen Objekt annähernd
254
5.3 Nebenläufige Programmierung in Java
gleichzeitig aufrufen, werden alle bis auf einen Thread solange blockiert, bis dieser eine aus flip zurückkehrt. Dann darf der nächste Thread flip ausführen
und so weiter. Die oben beschriebenen Synchronisationsprobleme sind damit
beseitigt. Die Methode wird atomar, also wie eine nicht weiter in Einzelteile
zerlegbare Einheit ausgeführt.
Faustregel: In nebenläufigen Programm(teil)en sollen alle Methoden,
die auf Objekt- oder Klassenvariablen zugreifen, synchronized sein.
Wie in flip werden dadurch Inkonsistenzen verhindert. Das gilt vor allem für
ändernde Zugriffe wie im Beispiel. Auch bei nur lesenden Zugriffen ist häufig
Synchronisation notwendig, um zu verhindern, dass inkonsistente Daten gelesen
werden (z. B. i schon erhöht, j aber noch nicht).
Faustregel: synchronized Methoden sollen nur kurz laufen.
Die Einhaltung dieser Faustregel verringert sowohl die Wahrscheinlichkeit für
das Blockieren von Threads als auch die durchschnittliche Dauer von Blockaden.
Überlegungen zur Synchronisation sind aufwändig. Daher werden manchmal
nur wichtige, große Methoden synchronisiert und in kleinen Hilfs-Methoden,
die nur von synchronized Methoden aus aufgerufen werden, darauf verzichtet.
Das widerspricht jedoch der Forderung nach kurz laufenden Methoden und ist
kein guter Programmierstil. Richtig ist es, die Granularität der Synchronisation so zu wählen, dass kleine, logisch konsistente Blöcke entstehen, in deren
Ausführung man vor Veränderungen durch andere Threads geschützt ist. Oft
bilden Methoden solche logischen Blöcke, aber große Methoden sind nicht selten in kleinere logische Blöcke aufzuteilen. Um diese Aufteilung zu erleichtern,
gibt es in Java neben synchronisierten Methoden auch synchronisierte Blöcke:
public void flip() {
synchronized(this) { i++; }
synchronized(this) { j++; }
}
Die Ausführungen der Befehle i++ und j++ werden getrennt voneinander synchronisiert. Die Methode als ganze braucht nicht synchronisiert zu werden, da
in ihr außerhalb von synchronized-Blöcken nirgends auf Objekt- oder Klassenvariablen zugegriffen wird. In dieser Variante von flip ist es zwar möglich,
dass i und j kurzfristig unterschiedliche Werte enthalten (z. B. weil mehrere
Threads, die im nächsten Schritt i erhöhen, früher an die Reihe kommen als
jene, die j erhöhen), aber am Ende des Programms sind i und j gleich; es wird
keine Erhöhung vergessen.
Zur Synchronisation verwendet Java Locking. Ein „Lock“ kann in jedem Objekt auf einen bestimmten Thread gesetzt sein um zu verhindern, dass ein anderer als dieser Thread auf das Objekt zugreift. Das Argument des synchronizedBlocks bestimmt das Objekt, dessen Lock zu setzen ist. Bei synchronized Methoden ist das immer das Objekt, in dem die Methode aufgerufen wird, also
255
5 Applikative Programmierung und Parallelausführung
this. Dieser Mechanismus erlaubt rekursive Aufrufe: Da Locks bereits auf die
richtigen Threads gesetzt sind, müssen sich rekursive Aufrufe nicht mehr um
Synchronisation kümmern.
Einzelne Schreib- und Lesezugriffe auf volatile Variablen (also solche, die
mit diesem Modifier deklariert wurden) sind atomar. Das reicht nicht, wenn
wie in i++ mehrere Variablenzugriffe erfolgen. Aber einige Klassen wie etwa AtomicInteger bieten Methoden an, die Werte einzelner Variablen ohne
synchronized atomar ändern.
Manchmal soll die Ausführung von Threads von weiteren Bedingungen abhängen, die Threads unter Umständen für längere Zeit blockieren. Die Methode
onOff in folgender Klasse schaltet einen Drucker online bzw. offline und steuert
damit, ob Druckaufträge an den Drucker weitergeleitet oder Threads, die den
Drucker verwenden wollen, blockiert werden:
public class PrinterDriver {
private boolean online = false;
public synchronized void print(String s) {
while (!online) {
try { wait(); }
catch(InterruptedException ex) { return; }
}
... // send s to printer
}
public synchronized void onOff() {
online = !online;
if (online) notifyAll();
}
...
}
Die Methode print stellt sicher, dass online den Wert true hat, bevor das
Argument an den Drucker weitergeleitet wird. Andernfalls wird wait aufgerufen. Diese in Object vordefinierte Methode blockiert (bei freigegebenem Lock)
den aktuellen Thread so lange, bis er wieder aufgeweckt wird, oder mit einem
entsprechenden Argument für eine bestimmte Zeit. Die Überprüfung erfolgt
in einer Schleife, da nach Aufwecken des Threads über notifyAll in onOff
durch einen weiteren Aufruf von onOff die Bedingung schon wieder verletzt
sein kann, bevor der Thread an die Reihe kommt. Es ist immer, auch ohne
Grund, damit zu rechnen, dass ein Thread aus dem Wartezustand aufwacht.
Daher erfolgen solche Überprüfungen fast immer in Schleifen. Ebenso muss die
Ausnahme InterruptedException abgefangen werden, die vom System bei
vorzeitiger Beendigung des wartenden Threads ausgelöst wird.
Wie wir in Abschnitt 2.5 gesehen haben, laufen nebenläufige Threads in einer Methode namens run meist in einer Endlosschleife. Objekte der folgenden
Klasse erzeugen nach Aufruf von run immer wieder neue Zeichenketten und
schicken diese an den im Konstruktor festgelegten Druckertreiber:
256
5.3 Nebenläufige Programmierung in Java
public class Producer implements Runnable {
private PrinterDriver t;
public Producer(PrinterDriver t) { this.t = t; }
public void run() {
String s = ....
for (;;) {
... // produce new value in s
t.print(s); // send s to the printer server
}
}
}
Das vordefinierte Interface Runnable spezifiziert nur run. Objekte von Klassen
wie Producer, die Runnable implementieren, können wie in folgendem Codestück zur Erzeugung neuer Threads verwendet werden:
PrinterDriver t = new PrinterDriver(...);
for (int i = 0; i < 10; i++) {
Producer p = new Producer(t);
new Thread(p).start();
}
Jeder Aufruf von new Thread(p) erzeugt einen neuen Thread, der nach Aufruf
von start() zu Laufen beginnt. Der Parameter p ist ein Objekt von Runnable;
der Aufruf von start() bewirkt die Ausführung von p.run() im neuen Thread.
Im Beispiel produzieren zehn Objekte von Producer ständig neue Zeichenketten und schicken sie an denselben Druckertreiber, der nebenläufige Zugriffe auf
den Drucker synchronisiert. Objekte von Thread bieten viele Möglichkeiten zur
Kontrolle der Ausführung des Threads, beispielsweise zum Abbrechen, kurzfristigen Unterbrechen, und so weiter. Beachten Sie, dass einige dieser Methoden
veraltet („deprecated“) sind und nicht mehr verwendet werden sollten.
5.3.2 Nebenläufigkeit in der Praxis
Die grundlegenden Sprachkonzepte für die nebenläufige Programmierung werden nur selten verwendet. Gründe sind einerseits prinzipielle Schwierigkeiten
im Umgang mit Nebenläufigkeit, andererseits eine Reihe vorgefertigter Lösungen für die häufigsten Aufgaben, die die nebenläufige Programmierung auf eine
höhere Ebene verschieben.
Die wichtigsten vorgefertigten Lösungen finden wir in diesen Java-Paketen:
java.util.concurrent und java.util.concurrent.atomic. Zum Teil handelt es sich um gut durchdachte und effiziente Implementierungen von Programmteilen, die wir mit entsprechendem Wissen selbst schreiben könnten, zum
Teil (vor allem in java.util.concurrent.atomic) aber auch um Lösungen,
die heute übliche Hardwareunterstützung für Synchronisation nutzbar machen.
Dahinter stecken bekannte Verfahren im Umgang mit Nebenläufigkeit und Parallelität, die in fortgeschritteneren Lehrveranstaltungen thematisiert werden.
Wir wollen nur exemplarisch einige wenige Möglichkeiten aufzeigen.
257
5 Applikative Programmierung und Parallelausführung
Aufgaben und Threads. Vor allem aus der funktionalen Programmierung mit
Nebenläufigkeit stammt ein Konzept namens Future. Das ist eine Variable, in
der das Ergebnis einer Berechnung abgelegt wird. Das Besondere daran ist, dass
die Berechnung, die dieses Ergebnis liefert, im Hintergrund abläuft, während
im Vordergrund gleichzeitig andere Berechnungen durchgeführt werden. Nachdem die Berechnung im Hintergrund fertig ist, kann das Ergebnis ganz normal
aus der Variablen gelesen werden. Wenn wir von der Variablen lesen bevor das
Ergebnis der Hintergrundberechnung vorliegt, wird der lesende Thread so lange
blockiert, bis das Ergebnis da ist. Wir haben also eine sehr einfache Möglichkeit,
um eine Hintergrundberechnung anzustoßen und mit den Berechnungen im Vordergrund zu synchronisieren. Das geht nur, wenn die Hintergrundberechnung
unbeeinflusst von anderen Berechnungen abläuft. In Java gibt es dafür die Klasse FutureTask und das Interface Future im Paket java.util.concurrent.
Generell müssen in der nebenläufigen Programmierung oft verschiedenste
Aufgaben (Tasks) erledigt werden, die unabhängig voneinander irgendwann
(ohne vorgegebene Zeitpunkte), aber möglichst effizient ablaufen sollen. Die
Darstellung einzelner Elemente in einem Webbrowser ist ein Beispiel dafür. Aus
Effizienzgründen ist es häufig nicht sinnvoll, für jede dieser manchmal kleinen
Aufgaben einen eigenen Thread zu erzeugen, aber eine reine Hintereinanderausführung würde die Hardware schlecht auslasten. In solchen Fällen kann ein
Executor (Interface aus java.util.concurrent) sinnvoll sein. Je nach Implementierung des Executors werden die Aufgaben auf verfügbare Threads aufgeteilt. Es gibt mehrere standardmäßige Implementierungen von Executor, z. B.
ThreadPoolExecutor. Über zahlreiche Parameter kann gesteuert werden, wann
und wo welche Aufgaben auszuführen sind. Einige Implementierungen erlauben
auch das regelmäßig wiederholte Ausführen bestimmter Aufgaben.
Java-8-Streams. Streams bieten eine effizente und einfache Möglichkeit für
den Umgang mit großen Datenmengen, auch zusammen mit Nebenläufigkeit:
HashSet<String> nums = ...; // "1", "2", ...
int sum = nums.parallelStream()
.mapToInt(Integer::parseInt)
.reduce(0, (i, j) -> i + j);
Die in nums in Form von Zeichenketten dargestellten Zahlen werden zu intZahlen umgewandelt und mittels reduce aufaddiert. Wegen parallelStream()
werden die Operationen auf dem Stream als Tasks über einen Thread-Pool (also
unter Verwendung mehrerer Threads mithilfe von ThreadPoolExecutor) abgearbeitet, wobei wir uns nicht um Details kümmern müssen. Der Thread-Pool
bestimmt die Anzahl der dabei verwendeten Threads; es wird also nicht für jedes Datenelement ein eigener Thread erstellt. Eine Voraussetzung ist, dass die
einzelnen Elemente (wie ganz allgemein bei Verwendung von Strömen) unabhängig voneinander sind, also keine gemeinsamen Variablen haben. Die Aufteilung der Daten erfolgt im Hintergrund über den Spliterator. Wir können die
Aufteilung beeinflussen, indem wir einen eigenen Spliterator implementieren,
258
5.3 Nebenläufige Programmierung in Java
hauptsächlich über die Methode trySplit() mit einigen anderen dazu passenden kleinen Methoden. Vordefinierte Klassen wie HashSet enthalten schon einen
gut angepassten Spliterator. Methoden wie map (hier in der Variante mapToInt)
operieren ohnehin nur auf jeweils einem Element, sodass Nebenläufigkeit keinen
Unterschied macht. Methoden wie sorted() und distinct() erfordern spezielle Algorithmen für den Umgang mit Nebenläufigkeit, vor allem distinct()
kann mit Nebenläufigkeit ineffizient werden. Auch abschließende Operationen
müssen für Nebenläufigkeit ausgelegt sein. Lambdas in reduce müssen assoziativ sein. Dadurch kann jeder parallele Datenblock für sich reduziert werden,
erst danach werden die Teilergebnisse über das gleiche Lambda zusammengefasst. Ein großer Teil der Komplexität von collect hat mit Nebenläufigkeit
zu tun. Es reicht nicht, nur eine Datensammlung vorzugeben, in die Elemente eingefügt werden. Daher benötigt die Standardvariante von collect (ohne
Collector) drei Lambdas als Parameter: Ein Lambda erzeugt eine neue Datensammlung, da pro Datenblock eine eigene Datensammlung benötigt wird. Das
zweite Lambda fügt ein Element in die Datensammlung ein. Das dritte Lambda
fügt zwei Datensammlungen der gleichen Art zu einer zusammen, wodurch bei
wiederholter Anwendung am Ende nur eine Datensammlung entsteht. Über die
Klasse Collector werden verschiedene vorgefertigte Varianten entsprechender
Methoden (Lambdas) bereitgestellt, die uns von den Details abschirmen.
Thread-sichere Datenstrukturen. Eine Reihe von Klassen im Java-Paket
java.util.concurrent stellt synchronisierte Varianten üblicher Datenstrukturen dar. So ähnelt ConcurrentHashMap einer normalen HashMap, erlaubt jedoch
gleichzeitige Zugriffe mehrerer Threads. Tatsächlich ist ConcurrentHashMap
sehr effizient wenn viele Threads gleichzeitig darauf zugreifen, da diese Implementierung ohne Locks auskommt. Es sind unbeschränkt viele gleichzeitige
Lesezugriffe und eine einstellbare Zahl gleichzeitiger Schreibzugriffe erlaubt.
Auch parallele Ströme und Spliteratoren sind darauf vergleichsweise effizient.
Auf Objekte von HashMap darf dagegen, außer über parallele Ströme, nicht
gleichzeitig von mehreren Threads aus zugegriffen werden (würde zu Fehlern
führen), aber bei nur einem Thread ist HashMap natürlich effizienter. Es gibt
noch weitere Varianten: Beispielsweise erzeugt
Collections.synchronizedMap(new HashMap(...))
eine über einen einfachen Lock synchronisierte Variante von HashMap, die von
mehreren Threads aus sicher verwendbar ist. Solange Threads nur selten gleichzeitig zugreifen wollen, ist diese Variante effizienter als ConcurrentHashMap.
In frühen Java-Versionen gibt es statt HashMap nur Hashtable. Diese Klasse
wird heute selten verwendet, da HashMap einen größeren Funktionsumfang hat
und ohne Nebenläufigkeit effizienter ist. Allerdings ist Hashtable von Haus aus
synchronisiert und bietet bei Nebenläufigkeit ähnliche Effizienz wie HashMap
synchronisiert über synchronizedMap. Aus praktischer Sicht sind oft die kleinen Unterschiede im Funktionsumfang ausschlaggebend dafür, welche Klasse
wir einsetzen. Beispielsweise können wir in einem Objekt von HashMap auch
259
5 Applikative Programmierung und Parallelausführung
den Wert null ablegen, in einem Objekt von Hashtable aber nicht. Die Klasse ConcurrentHashMap ist aus Effizienzgründen hinsichtlich des Funktionsumfangs sehr stark an Hashtable angelehnt, nicht an HashMap.
Für die meisten Datenstrukturen gilt Ähnliches. Auf in java.util definierte Datenstrukturen dürfen meist nicht mehrere Threads gleichzeitig zugreifen,
weil nicht synchronisiert wird. Durch Methoden wie synchronizedMap und
synchronizedList in der Klasse Collections können diese Datenstrukturen
mit Synchronisation ausgestattet werden. Allerdings sind diese Datenstrukturen
bei gleichzeitigen Zugriffen durch viele Threads nur wenig effizient. Vor allem
sind Iteratoren (im Gegensatz zu Spliteratoren5
) über diesen Datenstrukturen
bei Nebenläufigkeit nicht robust, das heißt, nach Änderungen der Datenstrukturen funktionieren sie nicht mehr vernünftig. In java.util.concurrent gibt es
Varianten dieser Datenstrukturen, die auch bei gleichzeitigen Zugriffen durch
viele Threads noch effizient sind und robustere Iteratoren bieten. Allerdings
unterscheiden sich die auf Nebenläufigkeit ausgelegten Datenstrukturen in vielen Details von den Varianten aus java.util. Darin spiegelt sich die Tatsache
wider, dass für die nebenläufige Programmierung andere Datenstrukturen und
Algorithmen zum Einsatz kommen als in der sequentiellen Programmierung.
Vorgehensweise. Sowohl in der nebenläufigen als auch parallelen Programmierung lassen wir uns bei der Suche nach passenden Zerlegungen einer Aufgabe
in Teilaufgaben meist davon leiten, ob die Teilaufgaben voneinander unabhängig
sind. Wenn die Teilaufgaben nicht voneinander abhängen, sind parallele Ströme,
aber auch Executor sinnvoll mit guter Effizienz einsetzbar. Wenn Teilaufgaben
auf gemeinsame Daten zugreifen, führt das nicht nur zu Ineffizienz wegen der
nötigen Synchronisation, sondern es steigt auch die semantische Komplexität
und damit die Fehlerwahrscheinlichkeit gewaltig an.
Oft lässt sich das Ziel der Unabhängigkeit nicht ganz erreichen. Dann müssen
wir für möglichst wenige gleichzeitige Zugriffe, vor allem Schreibzugriffe auf gemeinsame Daten sorgen. Klassen wie ConcurrentHashMap können in diesem Fall
einen Ausweg bieten. Allerdings muss sichergestellt sein, dass die gemeinsamen
Daten keine Einschränkungen in der Ausführungsreihenfolge der Teilaufgaben
bedingen, die Daten also nicht auf zu komplexe Weise voneinander abhängen.
Wir wissen ja nicht, wann genau welche Teilaufgabe ausgeführt wird.
Sind Abhängigkeiten in der Ausführungsreihenfolge unvermeidlich, wird es
schwierig. Wir können versuchen, Struktur in die Einschränkungen der Ausführungsreihenfolge zu bringen, sodass Klassen wie Phaser einsetzbar werden, die
es erlauben, Teilaufgaben in mehreren Phasen auszuführen. Sobald wir auf solche Formen der Synchronisation angewiesen sind, können wir die Zuteilung der
Teilaufgaben an Threads nicht mehr einem vordefinierten Executor überlassen,
sondern müssen uns selbst darum kümmern. Jeder Versuch, die Ausführungsreihenfolge zu kontrollieren, lässt den Schwierigkeitsgrad rasant ansteigen. Auch
wenn wir die zahlreichen Synchronisationsmöglichkeiten auf höherer Ebene nüt5Spliteratoren werden meist nur dadurch robust, dass Änderungen der Datenstrukturen
verboten sind, während darüber iteriert wird.
260
5.3 Nebenläufige Programmierung in Java
zen, ist bald die gleiche oder eine höhere Komplexität erreicht, als wir durch
den Einsatz der primitiven Sprachkonstrukte für Nebenläufigkeit hätten. Ganz
überflüssig sind die primitiven Sprachkonstrukte daher noch nicht.
Ein Ausweg steht offen: Wenn es zu schwierig wird, eine Aufgabe über Nebenläufigkeit zu lösen, können wir sie sequentiell lösen. Obwohl es stark vereinfachend klingt, liegt im Kern dieser Aussage viel Potential für eine gute Zerlegung einer Aufgabe in Teilaufgaben. Logische Handlungsstränge lassen sich
gleichzeitig und trotzdem sequentiell abarbeiten, indem jeder Handlungsstrang
in eine Folge von einzelnen Tätigkeiten zerlegt wird. Die Tätigkeiten werden
beispielsweise als Daten in je einer Queue pro Handlungsstrang abgelegt. Zur
sequentiellen Abarbeitung werden die jeweils ersten Tätigkeiten in den Queues
ausgeführt, wobei jene Queues übersprungen werden, deren erste Tätigkeiten
noch nicht zur Ausführung bereit sind (etwa noch auf das Eintreffen von Daten warten). Diese Vorgehensweise lässt sich auf vielfältige Weise verbessern,
etwa dadurch, dass mehrere Threads die jeweils ersten Tätigkeiten in Queues
bearbeiten, sofern sie unabhängig voneinander sind, oder einige Queues gegenüber anderen bevorzugt werden. Im Wesentlichen machen alle Mechanismen für
Nebenläufigkeit auf höherer Ebene genau das, jeweils auf etwas unterschiedliche Weise und auf unterschiedlichen Annahmen beruhend (z. B. müssen Daten
für viele Mechanismen unabhängig voneinander sein). Wenn wir es nicht (ohne
unnatürliche Verrenkungen wie extrem aufwändige Synchronisation) schaffen,
die einem bestimmten Mechanismus zugrunde liegenden Annahmen zu erfüllen,
müssen wir auf diesen Mechanismus verzichten. Vielleicht können wir aber einen
anderen Mechanismus mit anderen Annahmen einsetzen. Wenn wir keinen problemlos einsetzbaren Mechanismus finden, bleibt noch immer der hier skizzierte
Ausweg über eine sequentielle Abarbeitung der Tätigkeiten in den Handlungssträngen. Oft reicht es schon, uns diesen letzten Ausweg bewusst vor Augen
zu führen, um zu erkennen, wo es bei Einsatz einer bestimmten Technik hakt,
wodurch sich manchmal eine nebenläufige Lösung fast von selbst aufdrängt,
manchmal aber auch der Verzicht auf Nebenläufigkeit nahegelegt wird.
Faustregel: Synchronisation muss einfach gehalten werden.
Wenn die nötige Synchronisation zu aufwändig wäre, würde Nebenläufigkeit
weder hinsichtlich der Nutzung paralleler Hardware noch hinsichtlich der Einfachheit der gesamten Programmstruktur irgendwelche Vorteile bringen. Statt
übermäßig aufwändig zu synchronisieren ist es fast immer besser, auf Nebenläufigkeit zu verzichten. Gerade der Verzicht auf Nebenläufigkeit in einem Bereich
kann dazu führen, dass Nebenläufigkeit in einem anderen Bereich effektiv nutzbar wird. Schließlich kommt es nur auf Abhängigkeiten zwischen Daten und darauf ausgeführten Tätigkeiten an. Manche Bereiche in einem Programm können
frei von Abhängigkeiten bleiben, wenn andere Bereiche sich darum kümmern.
5.3.3 Synchronisation und die objektorientierte Sicht
Umgang mit Synchronisationsproblemen. Java hat zwar schon von Anfang
an Nebenläufigkeit unterstützt, aber im Laufe der Zeit hat sich diesbezüglich
261
5 Applikative Programmierung und Parallelausführung
viel verändert. Das hat zu kleinen Inkonsistenzen geführt, auf die wir beim praktischen Programmieren besonders achten müssen. Beispielsweise kümmern sich
die Klassen Vector und Hashtable selbst um Synchronisation, die ähnlichen
Klassen LinkedList und HashMap aber nicht. Wir müssen das Synchronisationsverhalten der von uns verwendeten Klassen gut kennen, da eine Fehlannahme
in jede Richtung zu schwerwiegenden Fehlern im Programmablauf führen kann.
Zu viel Synchronisation macht sich folgendermaßen negativ bemerkbar: Die
gleichzeitige Ausführung von Threads wird verhindert und die Laufzeit des Programms vielleicht (aber nicht bei jeder Ausführung gleich) verlängert. In Extremfällen wird die Ausführung so stark verzögert, dass überhaupt kein Fortschritt mehr möglich ist. Gefürchtet sind Liveness-Probleme wie Deadlock, Livelock und Starvation. Eine übliche Technik zur Vermeidung von Deadlocks besteht in der Verhinderung von Zyklen beruhend auf einer linearen Anordnung
aller Objekte im System; Locks dürfen nur in dieser Reihenfolge angefordert
werden, das heißt, wenn wir in einer synchronized-Methode in einem Objekt
y sind, dürfen wir keine synchronized-Methode in einem Objekt x aufrufen,
wenn entsprechend der linearen Anordnung x vor y steht. Leider ist eine lineare
Anordnung in der Praxis recht einschränkend: Dadurch werden alle Arten von
zyklischen Strukturen verhindert, bei deren Abarbeitung Synchronisation nötig sein könnte. Nicht selten nehmen wir für solche Strukturen die Gefahr von
Deadlocks in Kauf, ebenso wie die Gefahr von Livelocks und Starvation.
Manchmal wird empfohlen, Liveness-Eigenschaften wie nicht-funktionale Eigenschaften eines Programms zu behandeln. Das bedeutet, dass wir uns beim
Schreiben des Programms zunächst nicht darum kümmern, sondern erst durch
ausgiebiges Testen Verletzungen geforderter Eigenschaften zu finden versuchen.
Treten beim Testen keine Probleme auf, wird die Eigenschaft als erfüllt angenommen. Allerdings ist es kaum möglich, Programme mit Nebenläufigkeit ausreichend intensiv zu testen, weil Probleme bei wiederholten Aufrufen unter einander ähnlichen Bedingungen häufig auch einander ähnliche Ergebnisse liefern,
aber bestimmte Umgebungsbedingungen, die beim Testen nur schwer herstellbar sind (bestimmte Hardware, anderes Land, andere Betriebssystemversion,
Kombination mit anderer Software, etc.), gravierende Fehler zeigen können.
Heute gibt es Werkzeuge (auch für Java, vorwiegend auf Model-Checking beruhend), die in der Lage sind, bestimmte Eigenschaften von Programmen formal
zu beweisen. So ist es auch möglich zu beweisen, dass keine Deadlocks auftreten.
Leider können diese Werkzeuge nicht alles. Bei größeren Programmen liefern sie
manchmal gar kein Ergebnis (nicht genug Speicher) oder sie zeigen sehr viele
Fehlersituationen auf, deren genauere Analyse zeigt, dass angenommene Zustände in der Praxis nicht auftreten können. Da Livelocks und Starvation viele
unterschiedliche Ursachen und Auswirkungen haben, gibt es dafür auch keine
klaren formalen Definitionen, sodass sie formalen Beweisen kaum zugänglich
sind. Daher bleibt nur das Testen, trotz aller Schwierigkeiten.
Vorgefertigte Lösungen für die nebenläufige Programmierung beruhen großteils auf bekannten Techniken, die nicht oder kaum anfällig für Verletzungen
der Liveness-Properties sind. Genau deswegen sollten wir sie bevorzugen. Sie
wurden ausgiebig getestet, auch im praktischen Einsatz in unzähligen Program262
5.3 Nebenläufige Programmierung in Java
men. Trotzdem können auch bei Verwendung vorgefertigter Klassen LivenessProperties verletzt sein. Solche Probleme treten ja nicht nur an einzelnen Programmstellen auf, sondern resultieren aus dem Zusammenspiel unterschiedlicher
Programmteile. Wir müssen das gesamte Programm betrachten, nicht nur kleine Teile. Am besten folgen wir Empfehlungen, die aus Erfahrungen resultieren.
Empfehlungen zur nebenläufigen Programmierung in Java im herkömmlichen
Stil sind in [23] zu finden, aktuellere Programmiertechniken in [13].
Objektorientierte Sicht. Das von Java unterstützte Basiskonzept für Nebenläufigkeit, das Monitor-Konzept, ist schon recht alt [14, 6] und wurde nur leicht
verändert, um es an Java anzupassen. Objektorientierte Programmiertechniken
werden kaum unterstützt: Synchronisation wird weder als zu Objektschnittstellen gehörend betrachtet, noch in Untertypbeziehungen berücksichtigt – abgesehen von Zusicherungen, um die wir uns selbst kümmern müssen. Vorgefertigte
Lösungen haben zwar eine Verschiebung hin zu eher funktionalen Denkweisen
bewirkt, an der Problematik im Grunde aber nichts geändert. Auch heute ist es
schwierig, gute objektorientierte Programme mit Nebenläufigkeit zu schreiben.
Um Synchronisation in Untertypbeziehungen einzubeziehen, müssen wir vor
allem Client-kontrollierte History-Constraints berücksichtigen. Synchronisation
bewirkt ja Einschränkungen auf der Reihenfolge, in der Methoden abgearbeitet werden. Genau solche Einschränkungen werden durch Client-kontrollierte
History-Constraints dargestellt. Das impliziert, dass Objekte von Untertypen
Nachrichten zumindest in allen Reihenfolgen verarbeiten können müssen, in
denen Objekte von Obertypen sie verarbeiten können. Andernfalls wäre das
Ersetzbarkeitsprinzip verletzt. Das heißt auch, dass Methoden in Untertypen
über wait, notify und notifyAll nicht stärker synchronisiert sein dürfen als
entsprechende Methoden in Obertypen. Nur wenn bereits die Methode im Obertyp in einer bestimmten Situation wait aufruft, darf das auch die Methode im
Untertyp, muss aber nicht. Wenn die Methode im Obertyp in einer bestimmten
Situation notify bzw. notifyAll aufruft, dann muss dies auch die Methode im Untertyp machen; sie darf diese Methoden auch in anderen Situationen
aufrufen. Konkrete Situationen für Synchronisation sind nicht in Schnittstellen
beschrieben und dort manchmal kaum beschreibbar. Daher kann es schwierig
sein, sich an diese Bedingungen zu halten. Dort wo komplexe Synchronisation notwendig ist, sollten wir deswegen unter den heutigen Gegebenheiten auf
Ersetzbarkeit verzichten. Die wichtigste Empfehlung bei der Planung der Synchronisation ist daher, diese so lokal und einfach wie möglich zu gestalten.
Abhängigkeiten, die durch die notwendige Synchronisation in die Software
eingeführt werden, stehen auch der Vererbung oft im Weg [26]. Dafür gibt es
zwar einige Lösungsansätze, die aber allesamt nicht überzeugen können, vor
allem weil zumindest einige davon in Widerspruch zur Ersetzbarkeit stehen.
Ein weiteres Problem ergibt sich daraus, dass wir bei der Faktorisierung der
Software nach objektorientierten Gesichtspunkten anders vorgehen müssen als
bei der Zerlegung von Aufgaben im Hinblick auf Nebenläufigkeit. Wenn wir die
objektorientierten Gesichtspunkte in den Mittelpunkt stellen, ergeben sich häu263
5 Applikative Programmierung und Parallelausführung
fig so starke Abhängigkeiten zwischen den Teilaufgaben, dass Nebenläufigkeit
kaum sinnvoll einsetzbar ist. Andererseits führt eine Zerlegung nach Gesichtspunkten der Nebenläufigkeit leicht zu sehr niedrigem Klassenzusammenhalt und
längerfristig hohem Wartungsaufwand wegen nötiger Refaktorisierungen.
5.4 Prozesse und Interprozesskommunikation
Prozesse werden vom Betriebssystem verwaltet (siehe Abschnitt 2.4.2). Die Erzeugung von Prozessen sowie die Interprozesskommunikation kann nur abhängig vom Betriebssystem betrachtet werden. Wir beziehen uns hier auf Linux.
Viele Betriebssysteme haben wie Linux ihre Wurzeln in Unix, sodass sich die
Unterschiede in Grenzen halten. Wir beschäftigen uns zunächst mit dem Erzeugen neuer Prozesse in Linux von einer Shell aus. Danach betrachten wir den
Umgang mit Dateien und Pipelines aus Java-Sicht. Wir beschränken uns auf
die einfachsten Formen der Interprozesskommunikation.
5.4.1 Erzeugen von Prozessen in einer Shell
Unter Linux arbeiten wir üblicherweise mit einem Terminal-Fenster, in dem
„bash“ als Kommandozeileninterpreter (kurz „Shell“ genannt) läuft, um Kommandos in den Computer einzugeben. Das erste Terminal-Fenster mit Shell,
das wir beim Einloggen bekommen, wird (in Anlehnung an die Steuerkonsole früher Rechnergenerationen) häufig „Konsole“ genannt. Zum Starten einer
Programmausführung tippen wir den Programmnamen ein und schließen die
Eingabe mittels „Enter“ (oder „Return“) ab. Die Shell sucht darauf hin in
den ihr bekannten Verzeichnissen nach einer ausführbaren Datei dieses Namens
und erzeugt einen neuen Prozess, der den Programmtext in der Datei in den
Hauptspeicher lädt und ausführt. Statt durch ihren Namen können wir die ausführbare Datei auch durch ihren Dateipfad bestimmen. Beispielsweise führen
ls und /usr/bin/ls das Programm in der gleichen Datei aus (um den Inhalt
des Arbeitsverzeichnisses am Bildschirm auszugeben). Auch relative Dateipfade
sind erlaubt, beispielsweise ./ls wenn das Arbeitsverzeichnis /usr/bin ist.
Nach dem Programmnamen oder Dateipfad können, durch White-Space (also Leerzeichen oder Tab-Zeichen) getrennt, beliebig viele Kommandozeilenargumente (und Flags bzw. Optionen, die auch nur Argumente sind) folgen, die
als Zeichenketten an den neuen Prozess übergeben werden. Es hängt vom ausgeführten Programm ab, ob und wie diese Argumente in die Programmausführung einfließen. Z. B. wird das Kommando java Test arg1 arg2 den JavaInterpreter (java) starten, an den die Kommandozeilenargumente Test, arg1
und arg2 übergeben werden; der Interpreter wird Test als Namen der übersetzten Java-Klasse (also Test.class) verstehen, in den dem Interpreter bekannten
Verzeichnissen nach einer Datei dieses Namens suchen und die Methode main in
dieser Klasse ausführen, wobei die restlichen Kommandozeilenargumente arg1
und arg2 Einträge eines Arrays sind, das als Argument an main übergeben
wird. Das Java-Programm bestimmt, ob und wie dieses Array verwendet wird.
264
5.4 Prozesse und Interprozesskommunikation
Der Java-Interpreter führt übersetzte Java-Programme also auf ähnliche Weise aus, wie die Shell ausführbare Programme zur Ausführung bringt. Es gibt
aber wesentliche Unterschiede: Die Shell erzeugt für die Programmausführung
einen neuen Prozess, der die Programmausführung bestmöglich von der Ausführung anderer Prozesse auf dem gleichen Computer abschirmt und davon
ausgeht, dass die ausführbare Datei Maschinencode enthält, der direkt vom
Prozessor verstanden wird. Der Java-Interpreter läuft hingegen in dem Prozess,
der beim Start des Interpreters erzeugt wurde und interpretiert das übersetzte Java-Programm selbst, mehrere vom Interpreter geladene Java-Klassen und
im Interpreter erzeugte Threads sind nicht voneinander abgeschirmt. Moderne Java-Interpreter enthalten zwar selbst kleine Compiler (JIT- bzw. Just-inTime-Compiler), die Teile des JVM-Codes in Maschinencode übersetzen, aber
am Prinzip ändert sich nichts, alle geladenen Klassen und Threads existieren
noch immer (ohne Abschirmung voneinander) im gleichen Prozess.
Für die einfache Kommunikation mit der Außenwelt bekommt jeder Prozess
automatisch drei Ein- und Ausgabekanäle zugeordnet: die Standardeingabe, die
Standardausgabe und die Fehlerausgabe. Während ein durch eine Shell gestarteter Prozess läuft, wird alles, was wir in die Shell eintippen, an die Standardeingabe des Prozesses weitergeleitet. Alles, was der Prozess in die Standard- und
Fehlerausgabe schreibt, wird durch die Shell im Terminal-Fenster angezeigt. In
einem Java-Programm wird die Standardeingabe als System.in angesprochen,
die Standardausgabe als System.out und die Fehlerausgabe als System.err.
Diese Ein- und Ausgabekanäle werden häufig umgeleitet (redirect), also statt
mit der Shell mit einer anderen Quelle oder einem anderen Ziel verbunden. Um
das zu bewerkstelligen, versteht die Shell eine Reihe von Symbolen bzw. Operatoren. Hier ist eine kleine Auswahl an Beispielen basierend auf dem Programm
cat (für andere Programme funktioniert es nach dem gleichen Schema), Detailinformation bekommen wir etwa durch man cat und man bash (bzw. man sh
oder man csh, etc., je nach verwendeter Shell):
cat file cat liest Inhalt der über das Kommandozeilenargument festgelegten Datei file und gibt ihn in die Standardausgabe aus, keine Umleitung.
cat <file erreicht gleiches Ergebnis wie voriges Beispiel auf andere Weise:
cat hat kein Kommandozeilenargument und liest daher aus der Standardeingabe, Standardeingabe ist auf den Inhalt der Datei file umgeleitet,
dieser Inhalt wird in die Standardausgabe ausgegeben.
cat file >file2 Standardausgabe wird zur Datei file2 umgeleitet. Daher
wird keine Ausgabe im Terminal-Fenster angezeigt, sondern die Ausgabe
in die neu erzeugte Datei file2 geschrieben. Danach enthält file2 eine
Kopie von file. Fehlermeldungen (etwa wenn file nicht existiert) werden
im Terminal-Fenster angezeigt (weil nur die Standardausgabe, nicht die
Fehlerausgabe umgeleitet wird). file und file2 dürfen nicht gleich sein.
cat file >>file2 wie im vorigen Beispiel, abgesehen davon, dass die Ausgabe hinten an file2 angehängt wird, falls file2 schon existiert.
265
5 Applikative Programmierung und Parallelausführung
cat file &>file2 so wie >, aber sowohl die Standard- als auch die Fehlerausgabe wird in die neue Datei file2 umgeleitet.
cat file &>>file2 so wie >>, aber sowohl die Standard- als auch die Fehlerausgabe wird an die Datei file2 angehängt.
cat <file >file2 sowohl die Standardeingabe als auch die Standardausgabe ist umgeleitet.
In einer einzigen Kommandozeile können auch mehrere Prozesse gleichzeitig
gestartet werden. Eine sehr effiktive Möglichkeit dazu bieten Pipelines. Beispielsweise startet cat file | wc einen Prozess für cat file und einen weiteren Prozess für wc, wobei beide Prozesse gleichzeitig (bei ausreichend vielen
Recheneinheiten parallel, sonst überlappt bzw. pseudo-parallel) ausgeführt werden. Die Besonderheit bei Pipelines besteht darin, dass die Standardausgabe
des ersten Prozesses mit der Standardeingabe des zweiten Prozesses verbunden
ist. Im Beispiel gibt cat file den Inhalt von file in seine Standardausgabe
aus und wc liest diesen Inhalt aus seiner Standardeingabe und gibt die Anzahl der Zeichen, Wörter und Zeilen in seine Standardausgabe aus, die mit
dem Terminal-Fenster verbunden ist; der Inhalt der Datei erscheint nicht im
Teminal-Fenster. In cat <file | wc >file2 liest cat den Inhalt von file
aus seiner Standardeingabe und der Output von wc landet in der Datei file2.
6
Über mehrere Vorkommen von „|“ können wir auch mehr als zwei Prozesse
miteinander verknüpfen, wobei jeweil Standardausgaben mit Standardeingaben
benachbarter Prozesse verbunden sind. Wenn wir Prozesse mit „|&“ statt „|“
verknüpfen, wird auch die Fehlerausgabe des links stehenden Prozesses mit der
Standardeingabe des rechts stehenden Prozesses verbunden; davon wird eher
selten Gebrauch gemacht, weil wir Fehlermeldungen (von allen in einer Pipeline miteinander verknüpften Prozessen) häufig im Terminal-Fenster sehen und
nicht als Input weiterleiten wollen.
Während ein normaler von der Shell aus gestarteter Prozess (genannt Vordergrundprozess) läuft, ist die Standardeingabe des Prozesses mit dem TerminalFenster verbunden, damit wir über die Tastatur Eingaben machen können. Zu
dieser Zeit kann die Shell keine weiteren Befehle von der Tastatur entgegennehmen. Weitere Befehle müssen warten, bis der Prozess beendet ist, unabhängig
davon, ob der Prozess tatsächlich Eingaben über die Tastatur entgegennimmt.
Wenn der Prozess keine Eingaben entgegennimmt (etwa weil die Standardeingabe umgeleitet ist), gibt es oft keinen Grund, auf die Beendigung des Prozesses
zu warten. Wenn wir das Zeichen & an das Ende einer Kommandozeile setzen,
etwa cat file &, starten wir einen Hintergrundprozess. Dabei wartet die Shell
nicht auf die Beendigung des Prozesses, sondern ist sofort nach dem Start des
Prozesses bereit, weitere Kommandos entgegenzunehmen. Die Standard- und
Fehlerausgabe ist (wenn nicht umgeleitet) weiterhin mit dem Terminal-Fenster
verbunden, wodurch sich die Ausgaben mehrerer Prozesse im gleichen Fenster
6Das ist eine abgekürzte Sprechweise. Ausführlich müssten wir von der Standardausgabe des
Prozesses, der cat ausführt und dem Output des Prozesses, der wc ausführt, sprechen.
266
5.4 Prozesse und Interprozesskommunikation
überlappen können. Programme, die zur Benutzerinteraktion eigene Fenster öffnen, werden üblicherweise als Hintergrundprozesse gestartet.
So wie beliebig viele Prozesse in mehreren Zeilen der Shell hintereinander
gestartet werden können, können mehrere Kommandos auch durch „;“ voneinander getrennt in nur einer Zeile hingeschrieben werden, um mehrere Prozesse
hintereinander zu starten (wobei sich ein eventuell am Ende vorhandenes „&“ auf
die ganze Zeile bezieht). Es gibt weitere Möglichkeiten der Aneinanderreihung,
die den Return-Status von Prozessen in die Steuerung einbeziehen. Am Ende der
Ausführung gibt jeder Prozess als Return-Status einen ganzzahligen Wert zurück, den Wert 0 um eine fehlerfreie Ausführung anzuzeigen, einen anderen Wert
um einen Fehler zu melden. In Java wird die Ausführung des Interpreters beispielsweise durch einen Aufruf von System.exit(...) beendet, wobei das Argument den Return-Status festlegt. Wir können in der Shell die Erzeugung von
zwei Prozessen mittels „&&“ verknüpfen, wenn der zweite Prozess nur dann und
erst dann erzeugt werden soll, wenn der erste Prozess mit einem Return-Status
von 0 beendet wurde. Beispielsweise führt cat file >file2 && wc <file2
zunächst den cat-Prozess aus und erst nachdem dieser Prozess erfolgreich beendet wurde und file2 erzeugt hat, wird ein zweiter Prozess gestartet, der mittels
wc die Wörter in file2 zählt. Endet der erste Prozess mit einem Return-Status
ungleich 0, wird der zweite Prozess gar nicht gestartet. Bei einer Verknüpfung
mit „||“ statt „&&“ wird der zweite Prozess nur dann gestartet, wenn der erste
Prozess einen Return-Status ungleich 0 geliefert hat.
Die Mächtigkeit der Shell wird durch Expansion von Pfadnamen erhöht. Damit können wir durch kurze Ausdrücke umfangreiche Listen von Pfadnamen als
Kommandozeilenargumente erzeugen. Beispielsweise steht cat * für eine Kommandozeile, die nach cat die Liste aller Datei- und Verzeichnisnamen im aktuellen Arbeitsverzeichnis enthält, die Inhalte aller dieser Dateien werden ausgegeben. Konkret steht „*“ für beliebige Zeichenketten, die in üblichen Datei- und
Verzeichnisnamen vorkommen, die also keine Trennzeichen wie White-Space,
„/“, Klammern und Ähnliches enthalten. Das Zeichen „?“ steht für ein einziges solches Zeichen und [abc] für eines der drei Zeichen „a“, „b“ und „c“
(beliebige aufgezählte Zeichen), wobei auch Ranges wie in [a-c] vorkommen
können (gleichbedeutend mit [abc]). So steht A*[a-zI].java für jede Datei
im aktuellen Verzeichnis, deren Name mit „A“ beginnt und mit einem Kleinbuchstaben oder „I“ vor der Extension .java endet; der Name kann „.“ auch
mehrfach enthalten. Auch längere Pfadnamen können angegeben werden, etwa
*/*/*.java für alle Dateien mit der Endung .java in Unterverzeichnissen von
Unterverzeichnissen vom Arbeitsverzeichnis. Alle diese Namen stehen in beliebiger Reihenfolge durch White-Space getrennt hintereinander, wodurch sie als
Kommandozeilenargumente eines Prozesses dienen. Wir haben hier nur Beispiele gegeben. Es gibt zahlreiche weitere Formen der Expansion von Pfadnamen
für unterschiedliche Zwecke. Durch Expansionen ergibt sich das Problem, dass
Zeichen wie „*“ nicht mehr einfach nur für diesen Buchstaben stehen. Wenn wir
nur den Buchstaben haben wollen, müssen wir ihn als „\*“ darstellen. EscapeZeichen wie „\“ können problematisch sein; in der Praxis ergeben sich häufig
falsche Expansionen durch vergessene oder überzählige Escape-Zeichen.
267
5 Applikative Programmierung und Parallelausführung
Wir können einfache Hochkomma-Zeichen verwenden, um Zeichenketten vor
ungewollter Expansion zu schützen. Beispielsweise steht ’a * 2’ einfach nur
für ein einziges Kommandozeilenargument bestehend aus diesen 5 Zeichen, ganz
ohne Expansion. Wie wir sehen, kann damit ein einzelnes Argument auch Leerzeichen enthalten, obwohl Leerzeichen normalerweise mehrere Argumente voneinander trennen. In doppelten Hochkomma-Zeichen wie in "a * 2" sind ebenso
Leerzeichen einfach darstellbar, aber Zeichen wie „*“ werden dennoch expandiert. Eine Besonderheit sind Kommandozeilenargumente in verkehrten einfachen Hochkomma-Zeichen, etwa ‘cat file‘. Dabei wird ein Prozess erzeugt,
der cat file ausführt und die Standardausgabe dieses Prozesses als Liste von
Kommandozeilenargumenten betrachtet; jedes (durch White-Space getrennte)
Wort in file wird dadurch zu einem Kommandozeilenargument. Daher gibt
cat ‘cat file‘ die Inhalte aller Dateien aus, deren Namen in file stehen.
Die Shell ist mehr als nur ein einfacher Kommandozeileninterpreter, sie ist ein
Interpreter für eine vollständige Programmiersprache. Jedes Kommando ist eine
Anweisung in dieser Sprache. Die Shell kennt Variablen, vordefinierte Befehle,
Kontrollstrukturen und sogar definierbare Funktionen. Viele Programme sind
in der Sprache der Shell geschrieben, sogenannte Shell-Skripte (meist in Dateien mit der Endung .sh). Wir können Shell-Skripte als normale Textdateien
schreiben, durch Änderung der Zugriffsrechte über das Dateisystem als „ausführbar“ deklarieren (etwa durch chmod u+x script.sh) und wie ein normales
Programm ausführen, das in einer neuen Shell die Kommandos des Skripts abarbeitet. Auch ohne ausführbar zu sein, können wir durch . script.sh dafür
sorgen, dass die Befehle in script.sh in der aktuellen Shell ausgeführt werden.
Alles, was in einem Shell-Skript stehen kann, kann auch direkt in die Kommandozeile getippt werden. Wir wollen hier nicht die gesamte Sprache betrachten,
sondern nur einige wenige Beispiele.
Shell-Variablen sind beliebige Namen (außer reservierten Namen), denen wir
einen Wert zuweisen. Einige Variablen haben spezielle Bedeutungen. Z. B. ist
PATH eine Variable, die eine Liste von Pfadnamen enthält (getrennt durch „:“),
in denen die Shell bei Programmaufrufen in der gegebenen Reihenfolge nach
ausführbaren Programmen sucht. Wir können uns den Inhalt der Variablen
durch echo $PATH (entspricht echo ${PATH}) anzeigen lassen. Ein „$“ vor
einem Variablennamen steht für den Inhalt der Variablen. echo ist ein Befehl der
Shell (das bedeutet, zur Ausführung wird kein eigener Prozess erzeugt), der die
Argumente in die Standardausgabe schreibt. Es wird also der Inhalt von $PATH
im Terminal-Fenster angezeigt, etwa /usr/local/bin:/bin:/usr/bin. Nach
Ausführung von PATH=/home/me/bin:$PATH (eine Zuweisung) ist der Inhalt
von $PATH vorne um einen Dateipfad erweitert.7 Die Menge aller Variablen und
ihrer Werte wird durch set (ohne Argumente) angezeigt.
Bedingte Anweisungen if ...; then ...; else ...; fi kommen häufig
vor und sind etwas flexibler einsetzbar, aber nicht ganz so einfach handhab7Diese Änderung wirkt sich nur lokal in der Shell aus, nicht in einer eventuell vorhandenen übergeordneten Shell. Um auch die übergeordnete Shell zu beeinflussen, müssten wir
export PATH=/home/me/bin:$PATH schreiben.
268
5.4 Prozesse und Interprozesskommunikation
bar wie die Alternativen „&&“ und „||“. Dabei ist die Bedingung nach if ein
Prozess, dessen Return-Status 0 für Wahr und jeder andere Wert für Falsch
steht. Nach then und else können beliebig viele Kommandos kommen. Statt
„;“ ist überall auch ein Zeilenumbruch möglich. Als Bedingung wird häufig
test ... verwendet, ein Programm, das über Kommandozeilenargumente viele unterschiedliche einfache Vergleiche durchführen kann. Beispielsweise gibt
test x = y nur dann 0 zurück, wenn die Argumente x und y gleiche Zeichenketten sind. Weil das häufig vorkommt, gibt es für solche bedingte Anweisungen
auch eine spezielle Syntax: if [ x = y ]; then ...; fi (der else-Zweig
kann in jeder if-Anweisung dabei stehen oder weggelassen werden).
Wenn viele gleichartige Prozesse zu erzeugen sind, kommt die for-Schleife
zum Einsatz. Ein Beispiel: for i in *.java; do javac $i; done übersetzt
alle .java-Dateien im Arbeitsverzeichnis jeweils in einem eigenen Prozess, eine Datei nach der anderen. Dabei ist i eine Shell-Variable. In jedem Schleifendurchlauf erhält i den Wert eines Arguments nach in, wodurch es so viele Schleifendurchläufe wie .java-Dateien im Arbeitsverzeichnis gibt; in jedem
Durchlauf ist der Wert von i ein anderer Dateiname. Nach do stehen beliebig viele Befehle, die nacheinander ausgeführt werden. Wir können auch Hintergrundprozesse starten: for i in *.java; do (javac $i &); done übersetzt Dateien gleichzeitig (und Fehlermeldungen werden unvorhersehbar überlappt). Die runden Klammern sind nötig, weil „&“ nur am Ende eines Kommandos stehen darf, um den Prozess im Hintergrund zu starten. Diese Klammern
bewirken aber auch, dass jeder Hintergrundprozess in einer eigenen Shell läuft,
sodass wir die Prozesse nicht über die Shell, in der wir for aufgerufen haben,
kontrollieren können. Für Fälle, in denen Hintergrundprozesse in der gleichen
Shell laufen sollen, gibt es das coproc-Kommando, das aber deutlich schwieriger handhabbar ist und auf das wir hier daher nicht näher eingehen. Folgende
Variante lenkt Standard- und Fehlerausgaben in einzelne Dateien um:
for i in *.java; do (javac $i &>‘basename $i .java‘.out &); done
Dabei entfernt basename die Endung .java aus dem Dateinamen, die danach
durch .out ersetzt wird; Fehlermeldungen bei der Übersetzung von A.java landen also in A.out. Schleifen sind nicht auf Dateipfade eingeschränkt. Nach in
können beliebige Listen von Argumenten stehen, über die die Schleifenvariable
laufen soll. Beispielsweise kann die Schleifenvariable über alle Wörter in einer
Datei laufen: for f in ‘cat file‘; do javac $f.java; done lässt javac
auf jedem Namen in file (erweitert um die Endung .java) laufen.
5.4.2 Umgang mit Dateien und I/O-Strömen in Java
Der prinzipielle Umgang mit Kommandozeilenargumenten, üblichen Ein- und
Ausgabekanälen und Dateien in Java sollte uns schon bekannt sein:
• Die Klassenmethode main, die den Startpunkt der Ausführung eines JavaProgramms darstellt, nimmt ein Array von Zeichenketten als Parameter.
Der erste, vom Java-Interpreter veranlasste Aufruf dieser Methode über269
5 Applikative Programmierung und Parallelausführung
gibt in diesem Array die Kommandozeilenargumente in der Reihenfolge,
in der sie bei der Prozesserzeugung angegeben wurden.
• Aus der Standardeingabe ist über das Objekt vom Typ InputStream in
der Variablen System.in lesbar. Häufig lesen wir nicht direkt daraus, sondern etwa über einen Scanner, der durch new Scanner(System.in) erzeugt wurde, oder aus einem durch new ObjectInputStream(System.in)
erzeugten Strom (siehe unten).
• In die Standardausgabe und die Fehlerausgabe ist über je ein Objekt
vom Typ PrintStream in den Variablen System.out und System.err
schreibbar. Durch die benutzerfreundliche Schnittstelle wird häufig direkt
in diese Ströme geschrieben, z. B. mittels println. Als Standardausgabe
wird auch häufig in einen durch new ObjectOutputStream(System.out)
erzeugten Strom geschrieben (siehe unten).
• Alle Arten von Dateien werden nach dem Öffnen auf relativ einheitliche
Weise über diverse Arten von Strömen (nicht zu verwechseln mit Java-8-
Streams, die auf andere Weise verwendet werden) gelesen und geschrieben
und sollten nach der Verwendung auch wieder geschlossen werden. Beim
Umgang mit Dateien können stets Ausnahmen ausgelöst werden, die abgefangen werden müssen. Die Ströme unterscheiden sich in ihrer Richtung
(nur lesen oder nur schreiben), nach Ihrer Kodierung (Bytes als rohe Daten oder auf diverse Arten codierte Zeichen vom Typ char), nach der
Pufferung (mit einem Zwischenspeicher ausgestattete gepufferte und direkt mit dem Betriebssystem verbundene ungepufferte Ströme) und nach
den von ihnen unterstützten Zugriffsmethoden.
• Ungepufferte Ein- und Ausgabe wird gewählt, wenn es darauf ankommt,
dass alle Daten rasch über das Betriebssystem verarbeitet werden, etwa
wenn Output zeilenweise ohne Verzögerung für einen Benutzer sichtbar
werden soll (weil vielleicht weiterer Input davon abhängt). Bei direkter
Benutzerinteraktion trifft das meist zu. Gepufferte Ein- und Ausgabe ist
dagegen insgesamt effizienter und wird in Situationen gewählt, in denen
nur in Ausnahmefällen eine sofortige Ausgabe nötig ist. Das trifft zu,
wenn große Datenmengen verarbeitet werden und Input meist nicht von
davor erfolgtem Output abhängt. Ein Aufruf von flash() erzwingt die
sofortige Ausgabe von Output. Spätestens am Programmende werden alle
geschriebenen Daten an das Betriebssystem weitergeleitet. Viele Arten
von Strömen sind ungepuffert. Über die Klassen BufferedInputStream,
BufferedOutputStream, BufferedReader und BufferedWriter werden
ungepufferte Ströme zu gepufferten Strömen.
• Ein- und Ausgabekanäle können nur rohe Daten (Bytes) übertragen. Im
Allgemeinen ist nicht spezifiziert, in welcher Form diese Daten kodiert
sind. Innerhalb von Java sind Zeichen immer im UTF-16-Format dargestellt. Wenn Zeichen übertragen werden sollen, empfiehlt es sich, Ströme
270
5.4 Prozesse und Interprozesskommunikation
der Typen Readable und Writer und deren Untertypen zu verwenden, die
nötigenfalls automatisch für die Änderung der Kodierung vom bzw. zum
extern verwendeten Format sorgen, wobei die externe Kodierung in der
Regel bei der Erzeugung des Stroms angegeben werden muss. Aber auch
Methoden in PrintStream und Scanner können für nötige Änderungen
der Kodierung sorgen. Wenn keine Zeichenketten, sondern Daten anderer
Art übertragen werden sollen, stehen Ströme der Typen InputStream und
OutputStream und deren Untertypen zur Verfügung. Wir müssen selbst
für passende Datenformate sorgen oder diese Aufgabe vordefinierten Klassen überlassen.
• Außer bei Zugriffen über Scanner und PrintStream ist es bei allen Verwendungen von Strömen nötig, die Ausnahme IOException (oder Untertypen davon) abzufangen. Da es schwierig ist, gleichzeitig Ausnahmen
abzufangen und zu garantieren, dass Ströme am Ende der Verwendung
wieder über close geschlossen werden, bietet sich die Verwendung der
try-With-Resources-Anweisung an, die automatisch für das Schließen am
Ende sorgt. Alle Klassen für die Ein- und Ausgabe implementieren das
dafür nötige Interface AutoCloseable. Beispiel:
try (FileReader fr = new FileReader(path);
BufferedReader br = new BufferedReader(fr)) {
... // use br, automatically closed at end of try block
}
catch (IOException ex) {
...
}
• Die Klasse java.io.File bietet umfangreiche Funktionalität zur Darstellung von Dateien und zur Verwendung von Verzeichnissen. Als Ergänzung
bieten sich die Klassen im Paket java.nio.file an, die brauchbare Lösungen für sehr viele in der Praxis auftretende Aufgaben im Zusammenhang mit Dateien und Verzeichnissen bereitstellen.
Für den Umgang mit Dateien ist es unerlässlich zu wissen, in welchem Format eingelesene Daten dargestellt sind oder ausgegebene Daten dargestellt werden sollen. Wenn es sich um Dateien mit Texten (Zeichen) handelt, ist es vergleichsweise einfach, eine Kodierung für das externe Format anzugeben, beispielsweise über den Konstruktor von InputStreamReader oder FileReader.
Es muss ein Standardname für die Kodierung als String angegeben werden, etwa "UTF-8" oder "ISO-8859-1". Darauf kann verzichtet werden, wenn es sich
um die Default-Codierung auf dem jeweiligen Betriebssystem handelt. Bei einer
falsch angegebenen Kodierung sind einzelne Zeichen (vor allem Umlaute) nicht
korrekt lesbar. Meist empfiehlt es sich, bei der Default-Kodierung zu bleiben,
wenn alle Datenquellen und -ziele am gleichen Rechner liegen.
Wenn Daten nicht als Texte, sondern in einer anderen Form, etwa als beliebige
Objekte vorliegen, wird es schwieriger. Es muss für die Umwandlung zwischen
271
5 Applikative Programmierung und Parallelausführung
der internen Darstellung und dem externen Format gesorgt werden. Manchmal
ist es verlockend, von toString erzeugte Zeichenketten als externes Format anzusehen, weil dadurch keine weitere Methode zur Umwandlung des internen in
ein externes Format nötig ist. Wenn das Ergebnis von toString alle Informationen enthält, die ein Leser dieser Daten zum Neuaufbau einer entsprechenden
internen Datenstruktur benötigt, ist das durchaus machbar. Wir müssen in diesem Fall nur eine zusätzliche Methode (oder einen Konstruktor) schreiben, der
aus der Zeichenkette wieder ein Objekt des gleichen Typs erstellen kann. Einer
solchen Vorgehensweise stehen jedoch häufig zwei Schwierigkeiten gegenüber:
• Das Ergebnis von toString ist dafür vorgesehen, für Menschen gut lesbar
zu sein und keine für diesen Zweck unnötige Information zu enthalten. Oft
sind in dieser Darstellung nicht alle Informationen enthalten, die für einen
Wiederaufbau eines Objekts nötig wären. Andererseits ist beschreibender
Text vorhanden, der aus Sicht einer Maschine bedeutungslos ist und den
Neuaufbau eines Objekts erschwert.
• Umwandlungen vom internen Format ins externe sowie vom externen ins
interne müssen effizient erfolgen und die Menge an Daten, die zu übertragen sind, soll klein sein. Daher soll das Binärformat, das in den internen
Daten vorliegt, im externen Format möglichst direkt erhalten bleiben.
Vollständig erhalten bleiben kann das Format jedoch nicht, weil unterschiedliche Maschinen unterschiedliche Binärformate verwenden und Referenzen durch etwas anderes ersetzt werden müssen.
In der parallelen Programmierung sind Datenformate häufig einfach strukturiert, etwa Listen von Zahlen, die in jeweils 4 Bytes dargestellt sind. Wir können
also jeweils vier Bytes in einem Byte-Strom als eine Zahl auffassen. Allerdings
müssen wir festlegen, in welcher Reihenfolge die Bytes in einer Zahl liegen. Je
nach Maschine gibt es andere natürliche Reihenfolgen (etwa Big-Endian versus
Little-Endian). Welche Festlegung wir treffen ist egal, solange alle Maschinen,
die sich Daten teilen, von der gleichen Festlegung ausgehen. Wir könnten die
Umwandlungen über eigene Methoden selbst realisieren, aber mit vorgefertigten
Klassen und Methoden geht es einfacher.
Die Umwandlung von Daten vom internen zum externen Format heißt Serialisierung, die Umwandlung vom externen zum internen Format Deserialisierung.
In Java dient das Interface Serializable (das keine Methoden enthält) zum
Kennzeichnen von Typen, deren Instanzen eine Form der automatischen Serialisierung und Deserialisierung unterstützen. Die Klassen ObjectInputStream
und ObjectOutputStream erweitern InputStream und OutputStream um Funktionalität zur automatischen Deserialisierung und Serialisierung von Objekten,
sodass wir uns nicht um Details der Darstellung kümmern müssen.8 Die Methode writeObject(...) in ObjectOutputStream schreibt ein beliebiges Objekt in
einer serialisierten Form als Folge von Bytes in die Ausgabe, vorausgesetzt das
Objekt und alle im Objekt referenzierten Objekte sind vom Typ Serializable.
8Weitere Methoden dienen zum Serialisieren und Deserialisieren elementarer Typen.
272
5.4 Prozesse und Interprozesskommunikation
Auf diese Weise erzeugte Byte-Folgen werden mittels readObject() aus einem
Objekt von ObjectInputStream gelesen, wobei die Bytes automatisch wieder
in Objekte der richtigen Typen umgewandelt werden, vorausgesetzt die richtigen Klassen dieser Objekte sind vorhanden. Das klingt sehr einfach und ist
für entsprechend vorbereitete Objekte auch tatsächlich so einfach. In der Praxis
funktioniert das aber nur für solche Objekte gut, die eine klar abgegrenzte Menge an Daten enthalten und nicht zu sehr mit dem Gesamtsystem verwoben sind.
Wird ein Objekt serialisiert, werden automatisch auch alle vom Objekt referenzierten weiteren Objekte serialisiert; im Extremfall könnten das alle Objekte
eines Systems sein. Wir müssen also darauf achten, dass das nicht passiert. Die
serialisierbaren Daten müssen vom restlichen System möglichst gut getrennt
bleiben. Generell werden als static oder transient deklarierte Variablen bei
der Serialisierung nicht berücksichtigt. Das reicht aber nicht immer. Manchmal
möchten wir steuern können, welche Daten in welcher Form serialisiert werden. Dazu ist es möglich, in den Klassen der zu serialisierenden Objekte Methoden mit vorgegebenen Signaturen (benannt readObject, writeObject und
readObjectNoData) zu implementieren, um die eigentliche Arbeit zu erledigen.
Automatische Serialisierung und Deserialisierung über ObjectInputStream
und ObjectOutputStream setzt voraus, dass auf beiden Seiten einer Datenverbindung Java eingesetzt wird und die gleichen Java-Klassen vorhanden sind. Ist
das nicht gegeben, müssen wir eine eigene Darstellungsform finden, die von beiden Seiten verstanden wird. Wo es auf bestmögliche Effizienz ankommt, werden
wir kaum ohne ein passendes Binärformat auskommen, das auf Besonderheiten
der zu übertragenden Daten eingeht und die Datenmenge klein hält.
Häufig ist bestmögliche Effizienz bei der Datenübertragung nicht so wichtig,
dagegen aber ein mehr oder weniger standardisiertes Format der übertragenen
Daten von großer Bedeutung. Es kommen vor allem Formate zum Einsatz,
die auf für Menschen lesbare Texte aufbauen und die Struktur der Texte so
einschränken, dass auch Maschinen sie gut lesen können. Standardisiert und
zum Datenaustausch im Internet weit verbreitet ist XML, ein Datenformat für
semistrukturierte Daten, also Daten, die in der Lage sind, ihre eigene Struktur
zu beschreiben. XML ist auf vielfältige Weise einsetzbar und wird durch eine
große Palette an Werkzeugen in vielen unterschiedlichen Programmiersprachen
gut unterstützt, die Menge der zu übertragenden Daten kann aber relativ groß
sein. In letzter Zeit wird auch JSON (JavaScript-Object-Notation) häufig als
Format für den Datenaustausch gewählt, nicht nur zusammen mit JavaScript,
weil die Daten weniger umfangreich als in XML, aber trotzdem für Menschen
gut lesbar sind. Wir wollen hier nur kurz erwähnen, dass derartige Formate
natürlich auch von Java unterstützt werden und Informationen dazu im Internet
leicht auffindbar sind, gehen aber nicht näher darauf ein.
Shell-Variablen der Shell, von der aus der Java-Interpreter gestartet wurde, sind von Java aus zugreifbar: Ein Aufruf von System.getEnv() gibt eine
Datenstruktur vom Typ Map<String, String> zurück, die jede Shell-Variable
(als Key) in den Wert abbildet, den diese Variable hat. Ebenso gibt es eine
Methode System.getEnv(...), der wir den Namen einer Shell-Variablen als
String übergeben und die den Wert dieser Variablen zurückgibt (oder null
273
5 Applikative Programmierung und Parallelausführung
wenn dieser Variablen kein Wert zugeordnet ist). Neben Kommandozeilenargumenten bieten Shell-Variablen daher eine weitere Möglichkeit, Daten von der
Shell aus an ein Java-Programm weiterzureichen. Shell-Variablen werden vor
allem dann verwendet, wenn die zu übergebenden Daten über viele Aufrufe des
Java-Interpreters hinweg gleich bleiben, während sich die Werte von Kommandozeilenargumenten meist von Aufruf zu Aufruf ändern.
Ein Aufruf der Methode Runtime.getRuntime() gibt das einzige Objekt von
Runtime im aktuell ausgeführten Java-Interpreter zurück. Dieses Objekt bietet
uns eine Schnittstelle zur Ablaufumgebung an. Beispielsweise lässt sich durch
die Methode availableProcessors() die Anzahl der vom Java-Interpreter
nutzbaren Prozessor-Kerne erfragen, und freeMemory() liefert die Größe des
verbleibenden freien Speichers. Ein Aufruf von gc() hat in älteren Interpretern
die Ausführung einer Garbage-Collection veranlasst, um nicht mehr zugreifbare Objekte aus dem Speicher zu entfernen; heute läuft ein Garbage-Collector
fast immer im Hintergrund mit und der Aufruf ist nur eine Empfehlung an den
Garbage-Collector, verstärkt nach freigebbarem Speicher zu suchen.
Für die parallele Programmierung besonders interessant ist die Methode
exec(...), verfügbar in mehreren Varianten, die einen neuen Prozess erzeugt
(nicht nur einen Thread). Beispielsweise erzeugt
Process p = Runtime.getRuntime().exec("java -cp ~/java Test")
einen Prozess, der die übergebene Zeichenkette als Programmaufruf mit Kommandozeilenargumenten interpretiert. Hier wird ein neuer Java-Interpreter gestartet, der die übersetzte Java-Klasse Test im Verzeichnis ~/java ausführt.9
Über die Variable p vom Typ Process sind Verbindungen zum neuen Prozess
herstellbar. So können wir mittels p.getOutputStream() auf einen Strom vom
Typ OutputStream zugreifen, der über eine Pipeline mit der Standardeingabe
des neuen Prozesses verbunden ist, durch den wir dem Prozess Daten übermitteln. Durch p.getInputStream() bekommen wir einen Strom, der mit der Standardausgabe des Prozesses verbunden ist, dessen Ausgabe wir lesen. Entsprechend steht p.getErrorStream() für den Strom vom Typ InputStream, über
den wir die Fehlerausgabe lesen. Manchmal brauchen wir p.waitFor(), um
auf die Beendigung des Prozesses zu warten; zurückgegeben wird der ReturnStatus. Mittels p.destroy() kann der Prozess abgebrochen werden.
5.4.3 Beispiel zu parallelen Prozessen
Hier ist ein Beispiel zur Demonstration der Prozesserzeugung und Interprozesskommunikation in Java. Wie in Par in Abschnitt 2.4.3 werden Primzahlen mittels „Sieb des Eratosthenes“ berechnet, diesmal jedoch über Prozesse, die über
Pipelines kommunizieren. Ein Prozess, der als controller fungiert, startet eine vorgegebene Zahl an Prozessen, die als worker die eigentliche Rechenarbeit
9-cp ~/java ist eine Option, die der Java-Interpreter (als Kommandozeilenargument) versteht und die den Class-Path angibt, also das Verzeichnis, in dem nach einer Klasse entsprechenden Namens gesucht wird. Dabei steht ~ für das Home-Verzeichnis des aktuellen
Users; ~user würde für das Home-Verzeichnis des Users user stehen.
274
5.4 Prozesse und Interprozesskommunikation
leisten und mit dem controller über die Standardein- und -ausgabe kommunizieren. Der controller führt das gleiche Java-Programm aus wie jeder
worker, jedoch wird der controller ohne Kommandozeilenargumente gestartet, während jeder worker seine eindeutige Nummer (von 0 bis zur Anzahl der
worker-Prozesse minus eins) als Kommandozeilenargument bekommt. Hier ist
der Programmtext, in dem main anhand des Vorhandenseins eines Kommandozeilenarguments auf die Methoden worker und controller verzweigt:
import java.io.*;
public class ParProc {
public static final long MAX = 1L << 30; // primes up to MAX
public static final int PROC = 8; // how many worker processes
private static final long[] prims = new long[60000000];
private static int top = 2;
private static void worker(int nr) throws IOException {
boolean nothing = true; // no prime number found in cycle
long limit = 9L; // no larger prime numbers checkable
try (DataInputStream in = new DataInputStream(
new BufferedInputStream(System.in));
DataOutputStream out = new DataOutputStream(System.out)
) {
for (long n = 5L + 2 * nr; n <= MAX; n += PROC * 2) {
while (n > limit) {
if (nothing) {
out.writeLong(limit + 1L);
out.flush();
}
nothing = true;
limit = prims[top++] = in.readLong();
limit *= limit;
}
int i = 2; // check if n is a prime number
for (long p = 3L; n % p != 0; p = prims[i++]) {
if (p * p > n) { // n is a prime number
out.writeLong(n);
out.flush();
nothing = false;
break;
}
}
}
out.writeLong(MAX + 1L);
}
}
275
5 Applikative Programmierung und Parallelausführung
private static void controller() throws IOException {
final DataOutputStream[] outs = new DataOutputStream[PROC];
final DataInputStream[] ins = new DataInputStream[PROC];
final long[] delivered = new long[PROC];
final long sqrtMax = (long) Math.sqrt(MAX);
for (int i = 0; i < PROC; i++) {
Process p = Runtime.getRuntime().exec("java ParProc " + i);
outs[i] = new DataOutputStream(p.getOutputStream());
ins[i] = new DataInputStream(new BufferedInputStream(
p.getInputStream()));
}
for (int i=0; i<PROC; i++) delivered[i] = ins[i].readLong();
boolean done = false;
while (true) {
int proc = 0;
long min = delivered[0];
for (int i = 1; i < PROC; i++)
if (delivered[i] < min) min = delivered[proc = i];
if (min > MAX) break;
if ((min & 1) != 0) {
if (!done) {
for (DataOutputStream out : outs) {
out.writeLong(min);
out.flush();
}
if (min > sqrtMax) done = true;
}
prims[top++] = min;
}
delivered[proc] = ins[proc].readLong();
}
System.out.println(top);
}
public static void main(String[] args) throws IOException {
prims[0] = 2L;
prims[1] = 3L;
if (args.length == 0) controller();
else worker(Integer.valueOf(args[0]));
}
}
Das Array prims enthält die in aufsteigender Reihenfolge bekannten Primzahlen, wobei 2 und 3 fix vorgegeben sind. Untersuchen wir zunächst, was ein
worker macht: Wenn PROC den Wert 8 hat, dann untersucht der worker mit der
276
5.4 Prozesse und Interprozesskommunikation
Nummer 0 nur die Zahlen 5, 21, 37, . . . auf ihre Primzahleigenschaft, der worker
mit der Nummer 1 die Zahlen 7, 23, 39, . . . und so weiter, wodurch mit 8 workerProzessen alle ungeraden Zahlen ab 5 abgedeckt sind. Wurde eine Primzahl gefunden (durch Divisionsversuche durch alle Zahlen ab 3 in prims bis zur Wurzel
der untersuchten Zahl), wird sie in die Standardausgabe geschrieben, von wo
sie der controller liest und weiterverarbeitet. Als Grundlage kann der worker
nur Zahlen verwenden, die in prims stehen. Aus der Standardeingabe können
bei Bedarf weitere Primzahlen gelesen und in das Array eingefügt werden; der
controller versorgt die worker-Prozesse mit entsprechendem Input. Die Variable limit enthält das Quadrat der größten bisher in prims vorhandenen
Primzahl; mit dem Sieb sind nur Primzahlen kleiner als limit ermittelbar. Bevor untersucht werden kann, ob eine Zahl n eine Primzahl ist, muss n <= limit
sichergestellt sein und bei Bedarf eine weitere Primzahl aus der Standardeingabe gelesen und zu prims hinzugefügt werden, wodurch auch limit vergrößert
wird. Natürlich kann controller nur Primzahlen verschicken, die vorher von
einem worker-Prozess ermittelt wurden. Es könnte passieren, dass controller
und worker gegenseitig auf das Eintreffen von Daten warten. Damit das nicht
passiert, schreibt der worker eine Information in die Standardausgabe, anhand
der der controller feststellen kann, bis zu welcher Zahl schon alle Primzahlen
gemeldet wurden. Jede ausgegebene Primzahl ist eine solche Information. Wenn
der worker seit der letzten aus der Standardeingabe gelesenen Primzahl keine
Primzahl gemeldet hat, gibt er limit + 1 aus – eine gerade Zahl größer 2, sicher keine Primzahl. Sobald alle Zahlen bis MAX überprüft sind, wird MAX + 1
in die Standardausgabe geschrieben und der Prozess beendet.
Der controller erzeugt worker-Prozesse, liest von den worker-Prozessen
gelieferte Daten, bereitet daraus eine sortierte Folge von Primzahlen, legt diese in prims ab und gibt sie an worker weiter. Neue Prozesse werden mittels
Runtime.getRuntime().exec(...) erstellt, wobei das Argument von exec
den vom Prozess ausgeführten Programmaufruf darstellt. Es wird ein JavaInterpreter gestartet, der ParProc mit i als Kommandozeilenargument ausführt. ParProc.class muss im Arbeitsverzeichnis liegen. Die Arrays outs und
ins enthalten Eingabe- und Ausgabeströme, die jeweils mit der Standardeinund -ausgabe eines worker-Prozesses über eine Pipeline verbunden sind. Das
Array delivered enthält zuletzt aus diesen Eingabeströmen gelesene Werte,
also solche, die worker-Prozesse in ihre Standardausgaben geschrieben haben.
In einer Schleife wird das Array mit den ersten Werten initialisiert. Nun werden
Primzahlen in sortierter Reihenfolge verarbeitet. Dazu wird ständig wiederholt
• nach dem kleinsten Wert min in delivered gesucht,
• die Schleife abgebrochen falls min > MAX ist (dann sind wir fertig),
• min an alle worker-Prozesse geschickt (über Ströme in outs) und in prims
abgelegt falls min ungerade ist ((min & 1) != 0),
• der gerade bearbeitete Wert in delivered durch den nächsten Wert aus
dem Strom ersetzt.
277
5 Applikative Programmierung und Parallelausführung
Zur Vermeidung unnötiger Kommunikation wird mit Hilfe der Variablen done
sichergestellt, dass an die worker-Prozesse nur eine einzige Primzahl größer
als sqrtMax (der Wurzel aus MAX) verschickt wird. Primzahlen oberhalb von
sqrtMax werden zur Primzahlberechnung nicht benötigt, aber zumindest eine Zahl größer als sqrtMax wird von worker-Prozessen benötigt, um zu erkennen, dass schon alle nötigen Primzahlen vorliegen. Zur Vereinfachung gibt
controller nur die Zahl der gefundenen Primzahlen aus, aber alle Primzahlen
im gewünschten Wertebereich liegen vor und können weiterverarbeitet werden.
Aus diesem Beispiel können wir Folgendes lernen:
• Eine Schwierigkeit besteht darin, die Kommunikation zwischen den Akteuren so zu organisieren, dass es zu keinen Programmzuständen kommt,
in denen Akteure unendlich lange auf Daten von anderen Akteuren warten. Wir müssen das Programmverhalten genau analysieren, um das sicherzustellen; einfache Argumentationsketten sind meist nicht zielführend. Schon kleine Änderungen können bedeutende Auswirkungen haben.
• Wir verwenden DataInputStream und DataOutputStream als Typen der
I/O-Streams. Über solche Ströme lassen sich elementare Daten, in unserem Fall long-Werte, recht effizient in einem Binärformat übertragen,
ohne sie zu Zeichenketten zu konvertieren und dann wieder zurückzukonvertieren. Es muss nur sichergestellt werden, dass Daten im gleichen
Format gelesen wie geschrieben werden. Da alle Daten mit writeLong
geschrieben werden, müssen sie mit readLong gelesen werden.
• Nach jedem Aufruf von writeLong folgt flush, um die Daten sofort weiterzuverarbeiten. Es reicht in diesem Fall nicht, sich darauf zu verlassen,
dass Schreibbefehle an ungepufferte Ströme gleich an das Betriebssystem
weitergereicht werden, da auch Betriebssysteme zur Effizienzsteigerung
Pufferung verwenden. Meist werden Daten bei Erreichen eines Zeilenendes tatsächlich übertragen, was für die zeilenweise Kommunikation von
Texten sehr gut geeignet ist. Hier werden jedoch rohe Binärdaten übertragen, es gibt also keine Zeilenenden. Daher ist flush nötig.
• Es hängt von vielen Faktoren ab, ob gepufferte oder ungepufferte Ströme
vorteilhaft sind. Geschrieben wird hier über ungepufferte Ströme, gelesen
über gepufferte Ströme. Wenn es auf Effizienz ankommt, empfiehlt es sich,
sowohl mit gepufferten als auch ungepufferten Ströme Laufzeitmessungen
durchzuführen und die effizientere Variante zu wählen. Mit etwas Erfahrung lässt sich die bessere Variante zwar recht gut prognostizieren, aber
manchmal führt die Intuition in die Irre.
• Mittels Runtime.getRuntime().exec(...) ist es in Java einfach, neue
Prozesse zu erzeugen. Aber der Parameter von exec gibt nur den Namen
oder den Dateipfad eines Programms sowie Kommandozeilenargumente
an. Damit ergibt sich bei Weitem nicht die Mächtigkeit einer Shell wie
bash. Der Grund liegt in der Systemunabhängigkeit von Java. Um die
278
5.4 Prozesse und Interprozesskommunikation
Mächtigkeit der Shell zu nutzen, etwa zwecks Umleitung der Ein- oder
Ausgabe oder dem Aufbau komplexer Pipelines, wird häufig ein ShellSkript aufgerufen. Das geht auf Kosten der Portabilität, weil Shell-Skripts
stark vom Betriebssystem abhängen.
• Die Fehlersuche ist in parallelen Systemen sehr aufwändig. Beispielsweise
werden in ParProc nur Fehlermeldungen vom controller in der Fehlerausgabe sichtbar, Fehlermeldungen der worker-Prozesse gehen verloren.
Wenn p ein Objekt vom Typ Process ist, das einen worker-Prozess darstellt, könnten wir über p.getErrorStream() die Fehlermeldungen dieses
worker-Prozesses lesen. Es erfordert jedoch komplexe Koordination, dies
so zu bewerkstelligen, dass der Rest des Programms nicht darunter leidet. Viel einfacher wäre es, die Fehlerausgaben der worker-Prozesse auf
Dateien umzulenken. Über Methoden von Process können wir feststellen, ob ein Prozess überhaupt noch läuft. Wir können unnötig gewordene
Prozesse auch abbrechen. Jedoch erfordert auch das Koordinationsaufwand, weil abgebrochene Prozesse noch für eine gewisse Zeit weiterlaufen
können und beim Abbrechen von Prozessen Pipelines brechen, was zu
zusätzlichen Exceptions führen kann.
Obiges Programm wurde entwickelt, um die Interprozesskommunikation auf
einfache Weise zu demonstrieren. Zur effizienten Primzahlberechnung ist es noch
nicht optimal. Hier sind einige Verbesserungsvorschläge:
• Bei großen Datenmengen ist ein achtsamer Umgang mit dem Speicherverbrauch nötig. Das Array prims hat eine fixe Größe, für controller gleich
wie für worker. Aber worker müssen nur Primzahlen bis zur Wurzel von
MAX speichern, könnten also mit weniger Speicher auskommen.
• Durch Berücksichtigung von Eigenschaften der konkreten Aufgabe lässt
sich der Aufwand reduzieren. Für PROC kann eine beliebige positive Zahl
gewählt werden. Bei manchen Werten von PROC (z. B. 5) haben manche
worker (etwa jener mit Nummer 0) sehr wenig zu tun, weil nach einer
ersten Primzahl alle weiteren zu untersuchenden Zahlen Vielfache davon
sind (5, 15, 25, . . . ). Das trifft immer zu, wenn der Anfangswert und
PROC durch die gleiche Primzahl teilbar ist. Dieses Wissen könnten wir
für vorzeitige Abbrüche nutzen, oder so integrieren, dass entsprechende
Prozesse gar nicht erzeugt werden.
• Ineffiziente Algorithmen können den Aufwand in die Höhe treiben. Der in
controller verwendete Algorithmus zur Suche des Minimums ist primitiv. Hier wäre mehr Effizienz möglich.
• Die Vermeidung von Engpässen ist eine sehr effiktive Möglichkeit zur
Effizienzsteigerung. Bei einer größeren Zahl an worker-Prozessen wird
controller zu einem Engpass. Wir sollten nach einer Möglichkeit suchen, dessen Funktionalität auf mehrere Prozesse aufzuteilen.
279
5 Applikative Programmierung und Parallelausführung
• Unnötig viel Kommunikation wirkt sich störend auf die Laufzeit aus.
controller schickt gleiche Daten an unterschiedliche worker-Prozesse.
Über Shells (z. B. bash) ist es möglich, File-Descriptoren zu duplizieren
und damit den gleichen Ausgabestrom mit mehreren Eingabeströmen zu
verbinden. Das würde den Umfang gesendeter Daten reduzieren.
• Eine unnötig kleine Granularität verschickter Datenpakete treibt die Belastung des Systems in die Höhe. Die Sortierung der Primzahlen garantiert,
dass schon alle Primzahlen bis zu einer bekannten Zahl gefunden wurden.
Würden wir ein anderes Kriterium verwenden, könnten wir die Daten in
größere Blöcke zusammenfassen und damit den Kommunikationsaufwand
(vor allem die häufigen Aufrufe von flush) reduzieren.
• Es stellt sich stets die Frage, wie gut der gewählte Ansatz zur Erfüllung
der Aufgabe geeignet ist. Vielleicht ist eine andere Aufteilung der pro
worker zu bearbeitenden Daten vorteilhaft. Das können wir nur sehen,
wenn wir mehrere erfolgversprechende Ansätze ausprobieren.
• Grundannahmen sind zu überdenken, auch die, dass die Aufgabe durch
Kommunikation über Pipelines gelöst werden soll. Alle worker-Prozesse
verwenden die gleichen Daten. Shared-Memory sollte dafür besser einsetzbar sein als das Senden vieler Daten über Pipelines.
Das sind nur einige Hinweise darauf, in welche Richtungen Überlegungen zur
Verbesserung des Programms gehen könnten. Der Fantasie sind hier keine Grenzen gesetzt. Die parallele Programmierung ist gerade deswegen ein spannendes
Gebiet, weil es scheinbar unendlich viele Möglichkeiten gibt, die Laufzeit eines Programms noch weiter zu verringern oder die pro Zeiteinheit verarbeitete
Datenmenge weiter zu erhöhen.
280
6 Entwurfsmuster und
Entscheidungshilfen
Software-Entwurfsmuster, kurz Entwurfsmuster (Design-Patterns) dienen der
Wiederverwendung kollektiver Erfahrung in der Softwareentwicklung. Wir wollen exemplarisch einige häufig verwendete Entwurfsmuster betrachten. Dabei
konzentrieren wir uns, den Themen der Lehrveranstaltung entsprechend, auf
Implementierungsaspekte und erwähnen andere in der Praxis wichtige Aspekte
nur am Rande. Die Idee der Software-Entwurfsmuster gründet sich im Wesentlichen auf ein weithin bekanntes Buch (Gang-of-Four-Buch, kurz GoF-Buch),
das allen Interessierten empfohlen wird [12]:
E. Gamma, R. Helm, R. Johnson and J. Vlissides. Design Patterns:
Elements of Reusable Object-oriented Software. Addison-Wesley,
Reading, Massachusetts, 1994.
Es gibt eine Reihe neuerer Ausgaben und Übersetzungen in andere Sprachen, die
ebenso empfehlenswert sind. Wir betrachten nur einen kleinen Teil der im Buch
beschriebenen und in der Praxis häufig eingesetzten Entwurfsmuster, ergänzt
um neuere Varianten und Entwicklungen.
6.1 Grundsätzliches und Muster für Verhalten
Erfahrung ist eine wertvolle Ressource zur effizienten Erstellung und Wartung
von Software. Am effizientesten ist es, gewonnene Erfahrungen in Programmcode auszudrücken und diesen Code direkt wiederzuverwenden. Aber in vielen
Fällen funktioniert Code-Wiederverwendung nicht. In diesen Fällen müssen wir
zwar den Code neu schreiben, können dabei aber auf bestehende Erfahrungen
zurückgreifen und darauf verzichten, immer wieder „das Rad neu zu erfinden“.
In erster Linie betrifft diese Art der Wiederverwendung die persönliche Erfahrung. Aber auch kollektive Erfahrung ist von großer Bedeutung. Gerade für
den Austausch kollektiver Erfahrung können Hilfsmittel nützlich sein. Entwurfsmuster sind das bekannteste Hilfsmittel in diesem Bereich. Wir können heute
davon ausgehen, dass so gut wie alle Leute in der Softwareentwicklung die
wichtigsten Entwurfsmuster kennen und in der täglichen Arbeit immer wieder
darauf zurückgreifen.
Entwurfsmuster geben im Softwareentwurf häufig wiederholt auftauchenden
Problemstellungen und deren Lösungen Namen, damit einfacher darüber gesprochen werden kann. Außerdem beschreiben Entwurfsmuster, welche Eigenschaften wir uns von bestimmten Lösungen erwarten dürfen. Wer einen ganzen
281
6 Entwurfsmuster und Entscheidungshilfen
Katalog möglicher Lösungen für eine Aufgabe entweder in schriftlicher Form
oder nur abstrakt vor Augen hat, kann gezielt jene Lösung wählen, deren Eigenschaften der zu entwickelnden Software am ehesten entgegenkommen. Kaum
eine Lösung wird nur gute Eigenschaften haben. Häufig wird jene Lösung gewählt, deren Nachteile am ehesten für akzeptabel gehalten werden.
Wir betrachten den üblichen Aufbau von Entwurfsmustern und danach drei
Beispiele, die wir in ihren Grundzügen schon kennen und die Ihre Schwerpunkte
im Objektverhalten haben: Visitor, Iterator und Template-Method.
6.1.1 Aufbau von Entwurfsmustern
Jedes Entwurfsmuster besteht hauptsächlich aus diesen vier Elementen:
Name: Der Name ist wichtig, damit wir in einem einzigen Begriff ein Problem,
dessen Lösung und Konsequenzen daraus ausdrücken können. Damit wird
die Kommunikation im Softwareentwurf auf eine höhere Ebene verlagert;
wir müssen nicht mehr jedes Detail einzeln ansprechen. Der Name steht
für eine Abstraktion, diesmal nicht bezogen auf ein Konzept in einem
konkreten Programm, sondern bezogen auf ein ganz allgemeines Konzept
im Softwareentwurf unabhängig von konkreten Programmen oder Programmiersprachen.1 Es ist nicht leicht, dass alle Leute in der Softwareentwicklung sich auf einen gemeinsamen Namen für ein Entwurfsmuster
einigen und das gleiche Verständnis dafür entwickeln, was der Name ausdrückt. Die in der Praxis verwendeten Namen müssen sich im Laufe der
Zeit gegenüber anderen durchsetzen.
Beispielsweise haben wir in Abschnitt 4.4.2 das Visitor-Pattern, kurz den
Visitor kennen gelernt. Ohne lange darüber nachdenken zu müssen, sollten
wir diesen Begriff gleich mit mehrfachem dynamischem Binden, Visitorund Element-Klassen, einer grundlegenden Implementierungstechnik dahinter, der Möglichkeit zur Vermeidung dynamischer Typabfragen und
Typumwandlungen, aber auch dem Problem der hohen Anzahl an Methoden verbinden können. Erst dadurch, dass uns so viel dazu einfällt,
wird der Begriff zu einem geeigneten Namen für ein Entwurfsmuster. Typisch ist auch die Abstraktion über eine konkrete Problemstellung: Es geht
nicht nur um fressende Tiere, sondern um einen breiten Anwendungsbereich, der auch kovariante Probleme einschließt. Wegen der Breite und
Wichtigkeit des Anwendungsbereichs wurde das Visitor-Pattern (wie alle
1Eine gewisse Abhängigkeit von Programmiersprachen ist insofern schon gegeben, als je
nach Sprache unterschiedliche Implementierungstechniken zum Einsatz kommen, die zu
unterschiedlichen Konsequenzen führen können. Wenn solche Unterschiede entscheidend
sind, werden sie als Teil des Entwurfsmusters beschrieben. Eine Abhängigkeit von Programmierparadigmen ist dadurch häufig gegeben. Entwurfsmuster wurden ursprünglich
ausschließlich für die objektorientierte Programmierung entwickelt und haben dort noch
immer ihr Hauptanwendungsgebiet. Inzwischen gibt es auch Entwurfsmuster, die in anderen Paradigmen von Bedeutung sind. Paradigmen bestimmen, wie wichtig bestimmte
Entwurfsmuster dafür sind. Aber die allgemeinen Aussagen sind unabhängig von Paradigmen. Sie sind jedoch in manchen Paradigmen von größerer Relevanz als in anderen.
282
6.1 Grundsätzliches und Muster für Verhalten
wichtigen Entwurfsmuster) in der Fachliteratur eingehend analysiert, mit
ähnlichen Techniken verglichen und häufig angezweifelt. Heute kennen wir
mehrere Varianten, auf die wir hier nicht näher eingehen. Gerade diese
umfangreiche Diskussion hat den Begriff erst wirklich etabliert. Genaugenommen verbinden wir mit dem Begriff nicht mehr nur eine einzige, eng
umrissene Technik, sondern eine ganze Fülle ähnlicher Lösungsansätze in
einem Anwendungsbereich, deren Eigenschaften gut bekannt sind.
Problemstellung: Das ist die Beschreibung des Problems zusammen mit dessen
Umfeld. Daraus geht hervor, unter welchen Bedingungen das Entwurfsmuster überhaupt anwendbar ist. Bevor wir ein Entwurfsmuster in Betracht
ziehen, müssen wir uns überlegen, ob die zu lösende Aufgabe mit dieser
Beschreibung übereinstimmt.
Beispielsweise empfiehlt sich der Visitor dann, wenn „viele unterschiedliche, nicht verwandte Operationen auf einer Objektstruktur realisiert werden sollen, sich die Klassen der Objektstruktur nicht verändern, häufig
neue Operationen auf der Objektstruktur integriert werden müssen oder
ein Algorithmus über die Klassen einer Objektstruktur verteilt arbeitet,
aber zentral verwaltet werden soll.“ Das klingt nicht nur kompliziert, sondern ist es auch. In der Praxis müssen wir uns schon recht intensiv mit
der Problemstellung und den Einsatzmöglichkeiten beschäftigen, bevor
wir ein Gefühl dafür bekommen, in welchen Situationen die Verwendung
eines Entwurfsmusters angebracht ist. Mit wenig Erfahrung kennen wir oft
nur eine oder einige wenige Einsatzmöglichkeiten. Durch den praktischen
Einsatz, aber auch durch theoretische Überlegungen und einschlägige Literatur lernen wir im Laufe der Zeit immer weitere Einsatzmöglichkeiten
kennen, bis wir das gesamte Einsatzgebiet abschätzen können.
Lösung: Das ist die Beschreibung einer bestimmten Lösung der Problemstellung. Die Beschreibung ist so allgemein wie möglich gehalten, damit sie
leicht an unterschiedliche Situationen angepasst werden kann. Sie enthält
jene Einzelheiten, die zu den beschriebenen Konsequenzen führen, aber
nicht mehr. Manchmal sind mehrere unterschiedliche Lösungsvarianten
beschrieben (oft als „Implementierungsdetails“ bezeichnet), die zu unterschiedlichen Konsequenzen führen können, wobei die Unterschiede nicht
groß genug sind, um die Einführung eigener Namen zu rechtfertigen.
Im Beispiel des Visitor-Patterns enthält die Beschreibung Erklärungen dafür, wie die Klassenstrukturen aussehen, welche Abhängigkeiten zwischen
den Klassen bestehen und wie sich bestimmte Methoden darin verhalten.
Meist gibt es nicht nur eine einzige „empfohlene“ Struktur, sondern mehrere, einander ähnliche Varianten. Wir können jene Variante wählen, die
am ehesten zur konkreten Aufgabenstellung passt. Je nach Entwurfsmuster kann aus einer mehr oder weniger breiten Palette an möglichen Implementierungsdetails gewählt werden. Gerade diese Freiheiten machen ein
Entwurfsmuster aus. Ohne breite Auswahlmöglichkeiten wäre eine Klasse
besser geeignet, die wir vorgefertigt in ein Programm einbinden können.
283
6 Entwurfsmuster und Entscheidungshilfen
Konsequenzen: Das ist eine Liste von Eigenschaften der Lösung. Wir können
sie als Liste der Vor- und Nachteile betrachten, müssen aber aufpassen,
da ein und dieselbe Eigenschaft in manchen Situationen einen Vorteil
darstellt, in anderen einen Nachteil und in wieder anderen irrelevant ist.
Eine wichtige Eigenschaften von Visitor in der betrachteten Version besteht darin, unerwünschte dynamische Typabfragen und Typumwandlungen durch dynamisches Binden zu ersetzen. Damit lässt sich die Wartbarkeit verbessern. Wir können flexibel auf Programmänderungen reagieren,
die sonst oft größere Wartungsprobleme verursachen. Eine meist negative
Eigenschaft ist die große Anzahl an Methoden bei komplexeren Klassenstrukturen. Für vielfaches dynamisches Binden und viele Klassen ist Visitor einfach nicht geeignet. Für zweifaches dynamisches Binden und wenige
Klassen ist es dagegen gut geeignet. Die vollständige Liste der bekannten Konsequenzen ist lang. Häufig hängen Konsequenzen von bestimmten
Implementierungsdetails ab.
Entwurfsmuster scheinen die Lösung vieler Probleme zu sein, da nur aus einem Katalog von Mustern gewählt werden muss, um eine ideale Lösung für ein
Problem zu finden. Tatsächlich lassen sich Entwurfsmuster häufig so miteinander kombinieren, dass alle gewünschten Eigenschaften abgedeckt sind. Leider
führt der exzessive Einsatz von Entwurfsmustern oft zu einem unerwünschten
Effekt: Das Programm wird sehr komplex und undurchsichtig. Damit ist die
Programmerstellung langwierig und die Wartung schwierig, obwohl die über
den Einsatz der Entwurfsmuster erzielten Eigenschaften anderes versprechen.
Wir sollen also genau abwägen, ob es sich im Einzelfall auszahlt, eine bestimmte
Eigenschaft auf Kosten der Programmkomplexität zu erzielen. Die Softwareentwicklung bleibt auch dann eher eine Kunst als ein Handwerk, wenn Entwurfsmuster eingesetzt werden.
Faustregel: Entwurfsmuster sollen zur Abschätzung der Konsequenzen von Designentscheidungen eingesetzt werden, können aber nur
in begrenztem Ausmaß und mit Vorsicht als Bausteine zur Erzielung
bestimmter Eigenschaften dienen.
6.1.2 Visitor
Visitor ist ein gutes Beispiel zur Vorstellung eines Entwurfsmusters, weil wir es
schon kennen und es eher einfach ist. Heute wird meist eine Variante beschrieben, die der Verwendung in Abschnitt 4.4.2 entspricht. Zuerst betrachten wir
diese Variante, danach kurz die ursprüngliche Variante im GoF-Buch.
Visitor (deutsch Besucher) ist anwendbar, wenn
• viele unterschiedliche, nicht verwandte Operationen auf einer Objektstrutur realisiert werden sollen,
• sich die Klassen der Objektstruktur nicht ändern,
284
6.1 Grundsätzliches und Muster für Verhalten
• häufig neue Operationen auf der Objektstruktur integriert werden müssen
oder
• ein Algorithmus über die Klassen einer Objektstruktur verteilt arbeitet,
aber zentral verwaltet werden soll.
In Abschnitt 4.4.2 war der letzte Grund für die Anwendung von Visitor ausschlaggebend. Zur Beschreibung der meisten Entwurfsmuster folgt hier ein typisches Anwendungsbeispiel. Da wir schon mit einem Beispiel vertraut sind,
verzichten wir hier darauf.
Es folgt die Veranschaulichung der Struktur des Entwurfsmusters durch ein
Diagramm. Die oben genannte Objektstruktur von Visitor entspricht dem Typ
Element und dessen Untertypen:
ConcreteElementA
accept(Visitor v)
ConcreteElementB
accept(Visitor v)
Element
accept(Visitor v)
✁
✁
❆
❆
Visitor
visitA(ConcreteElementA x)
visitB(ConcreteElementB x)
ConcreteVisitor1
visitA(ConcreteElementA x)
visitB(ConcreteElementB x)
ConcreteVisitor2
visitA(ConcreteElementA x)
visitB(ConcreteElementB x)
✁
✁
❆
❆
Wir stellen Klassen (als allgemeines Konzept, schließen in Java z. B. auch Interfaces ein) als Kästchen dar, die die Namen der Klassen in Fettschrift enthalten.2
Durch einen waagrechten Strich getrennt können Namen von Methoden (mit
2Solche Diagramme ähneln UML-Diagrammen. Viele Diagramme zur Beschreibung von Entwurfsmustern sind älter als der UML-Standard, weshalb es kleine Unterschiede zu heute
üblichen UML-Diagrammen gibt. Wir verwenden hier wegen ihrer Kompaktheit die im
GoF-Buch verwendete Form.
285
6 Entwurfsmuster und Entscheidungshilfen
einer Parameterliste) und Variablen (ohne Parameterliste) in den Klassen in
nicht-fetter Schrift angegeben sein. Namen von abstrakten Klassen und Methoden sind kursiv dargestellt, konkrete Klassen und Methoden nicht kursiv.
Unterklassen sind mit deren Oberklassen durch Striche und Dreiecke, deren
Spitzen zu den Oberklassen zeigen, verbunden. Es wird implizit angenommen,
dass jede solche Vererbungsbeziehung gleichzeitig auch eine Untertypbeziehung
ist. Eine strichlierte Linie mit einem Pfeil zwischen Klassen bedeutet, dass eine
Klasse ein Objekt der Klasse, zu der der Pfeil zeigt, erzeugen kann (wird für
Visitor nicht benötigt). Eine durchgezogene Linie mit Pfeil deutet eine Referenz
an. Namen im Programmcode können sich von den Namen in der Grafik unterscheiden. Namen in der Grafik helfen dem intuitiven Verständnis der Struktur
und ermöglichen Diskussionen darüber. Daher sollten wir diese Namen kennen,
auch wenn im Programmcode andere Namen verwendet werden.
Visitor hat unter anderem folgende Eigenschaften:
• Neue Operationen lassen sich leicht durch die Definition neuer Untertypen
von Visitor hinzufügen.
• Verwandte Operationen werden im Visitor zentral verwaltet und von
Visitor-fremden Operationen getrennt.
• Ein Visitor kann mit Objekten aus voneinander unabhängigen Klassenhierarchien arbeiten.
• Die gute Erweiterungsmöglichkeit der Klassen unterhalb von Visitor muss
mit einer schlechten Erweiterbarkeit der Klassen der konkreten Elemente
erkauft werden. Müssen neue konkrete Elemente hinzugefügt werden, so
führt dies dazu, dass viele Methoden implementiert werden müssen.
• Häufig wird angeführt, dass die visit-Methoden nicht einfach auf konkrete
Elemente zugreifen können; oft können dies Parameter der visit-Methoden
ausgleichen, wodurch es auf Implementierungsdetails ankommt, inwieweit
das relevant ist.
Im GoF-Buch war Visitor ursprünglich etwas anders beschrieben: Die acceptMethoden rufen visit-Methoden nicht direkt in den entsprechenden VisitorKlassen auf. Stattdessen verwalten Element-Klassen dynamische Listen von Visitors und leiten Aufrufe an entsprechende Listeneinträge weiter. Das ist zwar
eine flexible Variante, aber eine, die in der Praxis eher selten verwendet wird,
unter anderem, weil die Verwaltung der Listen Schwierigkeiten bereiten kann.
Hier zeigt sich, dass Entwurfsmuster oft erst nach längeren Diskussionen stabil
werden. Es stellt sich die Frage, ob das im GoF-Buch beschriebene Entwurfsmuster vielleicht etwas ganz anderes ist als das hier beschriebene. Bei genauerer
Betrachtung ist das nur ein Implementierungsdetail. Wir können Details der Implementierung relativ stark abändern und ausweiten, ohne die Einsatzgebiete
und Eigenschaften wesentlich zu ändern. Das macht ein stabiles Entwurfsmuster
aus. Wir haben es wirklich mit einem abstrakten Muster zu tun, nicht nur mit
286
6.1 Grundsätzliches und Muster für Verhalten
einer stark vereinfachten Beschreibung einer Implementierung. Von allen Implementierungen, auf die die Beschreibung des Entwurfsmusters zutrifft (auch
wenn sie sich sehr weit von einer üblichen Implementierung entfernen), können
wir erwarten, dass sie die Eigenschaften dieses Musters haben.
6.1.3 Iterator
Als weiteres, gut bekanntes Beispiel betrachten wir nun Iteratoren auf der Ebene eines Entwurfsmusters. Name und Problemstellung lassen sich kurz so umreißen: Ein Iterator, auch Cursor genannt, ermöglicht den sequentiellen Zugriff auf
die Elemente eines Aggregats (das ist eine Sammlung von Elementen, beispielsweise eine Collection), ohne die innere Darstellung des Aggregats offenzulegen.
Dieses Entwurfsmuster ist verwendbar, um
• auf die Inhalte eines Aggregats zugreifen zu können, ohne die innere Darstellung offen legen zu müssen,
• mehrere (gleichzeitige bzw. überlappende) Abarbeitungen der Elemente
in einem Aggregat zu ermöglichen,
• eine einheitliche Schnittstelle für die Abarbeitung verschiedener Aggregatstrukturen zu haben, also um polymorphe Iterationen zu unterstützen.
Wegen der Bekanntheit verzichten wir auf ein Beispiel.
Die Struktur eines Iterators sieht wie in der folgenden Grafik aus:
Aggregate
iterator()
ConcreteAggregate
iterator()
Iterator
next()
hasNext()
ConcreteIterator
next()
hasNext()
✁
✁
❆
❆
✁
✁
❆
❆
✛
✲
Die abstrakte Klasse oder das Interface Iterator definiert eine Schnittstelle für
den Zugriff auf Elemente sowie deren Abarbeitung. Die Klasse „ConcreteIterator“ implementiert diese Schnittstelle und verwaltet die aktuelle Position in der
Abarbeitung. Die abstrakte Klasse oder das Interface Aggregate3 definiert eine
3Aggregat (bzw. englisch Aggregate) hat sich als Fachbegriff etabliert. In der Kommunikation sollen wir diese Fachbegriffe verwenden (statt konkreter Namen wie „Iterable“ oder
Umschreibungen wie „Collection“), weil dadurch ohne weitere Erläuterungen klar ist, dass
wir dabei die Eigenschaften des Entwurfsmusters im Kopf haben. Aus diesem Grund unterscheiden sich Klassen- und Methodennamen oft bewusst von entsprechenden Namen
in Entwurfsmustern.
287
6 Entwurfsmuster und Entscheidungshilfen
Schnittstelle für die Erzeugung eines neuen Iterators (Iterable<T> in Java).
Die Klasse „ConcreteAggregate“ implementiert diese Schnittstelle. Ein Aufruf
von „iterator“ erzeugt üblicherweise ein neues Objekt von „ConcreteIterator“,
was durch den strichlierten Pfeil angedeutet ist. Um die aktuelle Position im Aggregat verwalten zu können, braucht jedes Objekt von „ConcreteIterator“ eine
Referenz auf das entsprechende Objekt von „ConcreteAggregate“, angedeutet
mittels durchgezogenem Pfeil.
Iteratoren haben drei wichtige Eigenschaften:
• Sie unterstützen unterschiedliche Varianten in der Abarbeitung von Aggregaten. Für komplexe Aggregate wie beispielsweise Bäume gibt es zahlreiche Möglichkeiten, in welcher Reihenfolge die Elemente abgearbeitet
werden. Es ist leicht, mehrere Iteratoren für unterschiedliche Reihenfolgen auf demselben Aggregat zu implementieren.
• Iteratoren vereinfachen die Schnittstelle von Aggregate, da Zugriffsmöglichkeiten, die über Iteratoren bereitgestellt werden, durch die Schnittstelle von Aggregate nicht unterstützt werden müssen. Die in obiger Struktur in der Klasse Iterator enthaltenen Methoden stellen nur eine Mindestanforderung dar. Daneben kann es weitere Methoden geben, die Aggregate zusätzlich vereinfachen. Beispielsweise enthält das in den JavaStandardbibliotheken vordefinierte Interface Iterator auch eine Methode
remove, um das aktuelle Element zu entfernen.
• Auf ein und demselben Aggregat können gleichzeitig mehrere Abarbeitungen stattfinden, da jeder Iterator selbst den aktuellen Abarbeitungszustand verwaltet. Gelegentlich finden wir Iterator-ähnlichen Code, in dem
der Abarbeitungszustand im Aggregat und nicht im Iterator verwaltet
wird. Solcher Code widerspricht dem hier vorgestellten Entwurfsmuster,
da zwingend gefordert ist, dass auf demselben Aggregat mehrere gleichzeitige Abarbeitungen möglich sein müssen.
Es gibt zahlreiche Möglichkeiten zur Implementierung von Iteratoren. Hier
sind einige Anmerkungen zu Implementierungsvarianten:
• Wir können zwischen internen und externen Iteratoren unterscheiden. Interne Iteratoren kontrollieren selbst, wann die nächste Iteration erfolgt,
bei externen Iteratoren bestimmt die Anwendung, wann sie das nächste Element abarbeiten möchte. Bei internen Iteratoren liegt die Schleife (oder Rekursion), mit der das Aggregat durchlaufen wird, innerhalb
der Iterator-Implementierung, bei externen Iteratoren außerhalb. Die Methoden „next“ und „hasNext“ sind nur bei externen Iteratoren öffentlich
sichtbar, bei internen Iteratoren bleiben sie nach außen verborgen (oder
existieren nur indirekt in versteckter Form). In Java ist beispielsweise jeder Iterator, der mittels iterator() erzeugt wird, ein externer Iterator.
Wenn wir dagegen etwa über eine Collection oder in einem Spliterator
mittels forEach(...) iterieren, verwenden wir einen internen Iterator.
288
6.1 Grundsätzliches und Muster für Verhalten
Auch map(...) in Java-8-Streams ist ein interner Iterator. Die Methode iterator in Aggregate kann in einer Implementierung also auch etwa
forEach oder map heißen. Bei der Erzeugung übergeben wir einem internen Iterator eine Operation (z. B. in Form eines Lambdas), die vom
Iterator auf die einzelnen Elemente angewandt wird.
Externe Iteratoren sind flexibler als interne Iteratoren. Zum Beispiel ist es
mit externen Iteratoren leicht, zwei Aggregate miteinander zu vergleichen.
Mit internen Iteratoren ist das schwieriger. Andererseits sind interne Iteratoren oft einfacher zu verwenden, da eine Anwendung die Logik für die
Iterationen (also die Schleife) nicht braucht. Interne Iteratoren spielen vor
allem in der funktionalen Programmierung eine große Rolle, da es dort
gute Unterstützung für die Übergabe von Funktionen bei der IteratorErzeugung gibt und externe Schleifen problematisch sind. In der objektorientierten Programmierung wurden bisher hauptsächlich externe Iteratoren eingesetzt. Seit der Einführung von Lambdas und Java-8-Streams
gibt es auch in Java interne Iteratoren von hoher Qualität, wodurch sich
das bald ändern könnte. Schließlich bieten interne Iteratoren eine einfache Möglichkeit zur parallelen Verarbeitung großer Mengen voneinander
unabhängiger Daten, während externe Iteratoren die Parallelverarbeitung
eher erschweren.
• Oft ist es schwierig, externe Iteratoren auf Sammlungen von Elementen
zu verwenden, wenn diese Elemente in komplexen Beziehungen zueinander stehen. Durch die sequentielle Abarbeitung geht die Struktur dieser
Beziehungen verloren. Beispielsweise erkennen wir an einem vom Iterator
zurückgegebenen Element nicht mehr, an welcher Stelle in einem Baum
das Element steht. Wenn die Beziehungen zwischen den Elementen bei der
Abarbeitung benötigt werden, ist es meist einfacher, interne statt externer
Iteratoren zu verwenden oder ganz auf Iteratoren zu verzichten.
• Der Algorithmus zum Durchwandern eines Aggregats muss nicht immer
im Iterator definiert sein. Häufig wird er vom Aggregat bereitgestellt.
Wenn der Iterator den Algorithmus definiert, ist es leichter, mehrere Iteratoren mit unterschiedlichen Algorithmen zu verwenden. In diesem Fall
ist es auch leichter, Teile eines Algorithmus in einem anderen Algorithmus wiederzuverwenden. Andererseits müssen die Algorithmen oft private Implementierungsdetails des Aggregats verwenden. Das geht natürlich
leichter, wenn die Algorithmen im Aggregat definiert sind. In Java können wir Iteratoren durch innere Klassen in Aggregaten definieren, wie
zum Beispiel den Iterator in der Klasse List (siehe Abschnitt 4.1.2). Dies
ermöglicht dem Iterator, auf private Details des Aggregats zuzugreifen.
Allerdings wird dadurch die ohnehin schon starke Abhängigkeit zwischen
Aggregat und Iterator noch stärker. Trotzdem sind innere Klassen in diesem Fall meist vorteilhaft.
• Es kann gefährlich sein, ein Aggregat zu verändern, während es von einem
Iterator durchwandert wird. Wenn Elemente dazugefügt oder entfernt
289
6 Entwurfsmuster und Entscheidungshilfen
werden, passiert es leicht, dass Elemente nicht oder doppelt abgearbeitet
werden. Eine scheinbar einfache Lösung besteht darin, die Elemente des
Aggregats bei der Iterator-Erzeugung zu kopieren. Aus praktischer Sicht
ist diese Lösung meist viel zu aufwändig. Häufig möchten wir, dass Iteratoren Änderungen des Aggregats „sehen“, also Änderungen nicht ignorieren. Es ist strittig, ob ein Iterator auf einer Kopie der Daten überhaupt
als Iterator auf dem Original angesehen werden kann. Ein robuster Iterator erreicht das Ziel ohne Kopieren der Daten. Es ist aufwändig, robuste
Iteratoren zu schreiben. Probleme hängen von der Art des Aggregats ab.
• Aus Gründen der Allgemeinheit ist es oft praktisch, Iteratoren auch auf
leeren Aggregaten bereitzustellen. In einer Anwendung müssen wir die
Schleife nur so lange ausführen, so lange es Elemente gibt – bei leeren
Aggregaten daher nie – ohne eine eigene Behandlung für den Spezialfall
zu benötigen. Das gilt auch für interne Iteratoren. Operationen auf Java-8-
Streams können meist gut mit leeren Strömen umgehen. Der Wegfall von
Sonderbehandlungen macht Programme kürzer und weniger fehleranfällig.
6.1.4 Template-Method
Eine Template-Method definiert das Grundgerüst eines Algorithmus in einer
Operation, überlässt die Implementierung einiger Schritte aber einer Unterklasse. Template-Methods erlauben einer Unterklasse, bestimmte Schritte zu
überschreiben, ohne die Struktur des Algorithmus zu ändern.
Dieses Entwurfsmuster ist anwendbar
• um den unveränderlichen Teil eines Algorithmus nur einmal zu implementieren und es Unterklassen zu überlassen, den veränderbaren Teil des
Verhaltens festzulegen;
• wenn gemeinsames Verhalten mehrerer Unterklassen (zum Beispiel im Zuge einer Refaktorisierung) in einer einzigen Klasse lokal zusammengefasst
werden soll, um Duplikate im Code zu vermeiden;
• um mögliche Erweiterungen in Unterklassen zu kontrollieren, beispielsweise durch Template-Methods, die Hooks als primitive Operationen (siehe
die unten stehende Strukturzeichnung) aufrufen und nur das Überschreiben dieser Hooks (keiner anderer Methoden) in Unterklassen ermöglichen.
Ein Hook ist eine Methode mit einer Default-Implementierung, die dafür vorgesehen ist, in Untertypen überschrieben zu werden. Im Gegensatz zu einer abstrakten Methode muss ein Hook aber nicht überschrieben werden. Die DefaultImplementierung hat in der Regel keinen Effekt, macht also nichts und gibt nur
einen Wert zurück, der keinen Effekt andeutet (etwa 0 wenn eine Zahlensumme
gebildet werden soll oder 1 für ein Zahlenprodukt).
Wir haben Template-Method in Abschnitt 3.3.2 eingesetzt, um zu zeigen, wie
wir die direkte Code-Wiederverwendung unterstützen können. Das entspricht
dem ersten Punkt in obiger Liste von Einsatzszenarien.
290
6.1 Grundsätzliches und Muster für Verhalten
Die Struktur dieses Entwurfsmusters ist recht einfach:
AbstractClass
templateMethod()
primitiveOperation1()
primitiveOperation2()
ConcreteClass
primitiveOperation1()
primitiveOperation2()
✁
✁
❆
❆
Die (meist abstrakte) Klasse AbstractClass definiert (möglicherweise abstrakte)
primitive Operationen und implementiert als „templateMethod“ das Grundgerüst des Algorithmus, das die primitiven Operationen aufruft. Jede von der
„templateMethod“ aufgerufende Methode wird als primitive Operation bezeichnet und stellt einen Schritt in der Ausführung der „templateMethod“ dar. Die
Klasse „ConcreteClass“ implementiert (einige) primitive Operationen, erbt die
„templateMethod“ aber unverändert.
Template-Methods haben unter anderem folgende Eigenschaften:
• Sie stellen eine fundamentale Technik zur direkten Wiederverwendung
von Programmcode dar. Sie sind vor allem in Klassenbibliotheken und
Frameworks sinnvoll, weil sie gemeinsames Verhalten faktorisieren.
• Sie führen zu einer Umkehrung der üblichen Kontrollstruktur, die manchmal als Hollywood-Prinzip bezeichnet wird („Don’t call us, we’ll call you“).
Das bedeutet, die Oberklasse ruft Methoden der Unterklasse auf – nicht
wie in den meisten Fällen umgekehrt.
• „templateMethod“ ruft folgende Arten von primitiven Operationen auf
(wobei die in einer bestimmten „templateMethod“ aufgerufenen Methoden häufig alle von der gleichen Art sind):
– konkrete Operationen in „AbstractClass“, also Operationen, die ganz
allgemein auch für Unterklassen sinnvoll sind;
– abstrakte primitive Operationen, die einzelne Schritte im Algorithmus ausführen (und in „ConcreteClass“ implementiert sind);
– Hooks, also Operationen mit in „AbstractClass“ definiertem DefaultVerhalten, das in Unterklassen überschrieben werden kann,
– Factory-Methods, also Methoden, die in Unterklassen neue Objekte
erzeugen und zurückgeben und damit die Template-Method auch zu
einem anderen Entwurfsmuster werden lassen – siehe Abschnitt 6.2.1.
291
6 Entwurfsmuster und Entscheidungshilfen
Es muss genau spezifiziert sein, welche Operationen Hooks sind (dürfen
überschrieben werden), welche abstrakt sind (müssen überschrieben werden) und welche nur in „AbstractClass“ implementiert sein sollen. Für die
effektive Wiederverwendung ist es wichtig, dass alle Beteiligten wissen,
welche Operationen dafür vorgesehen sind, in Unterklassen überschrieben
zu werden. Alle Operationen, bei denen dies Sinn macht, sollen Hooks
oder abstrakte Methoden sein, da es beim Überschreiben anderer Operationen leicht zu Fehlern kommt.
Die primitiven Operationen, die von der Template-Methode aufgerufen werden, sind (wenn AbstractClass kein Interface ist) häufig protected Methoden,
damit sie nicht in unerwünschten Zusammenhängen aufrufbar sind. Primitive
Operationen, die überschrieben werden müssen, sind als abstract deklariert.
„templateMethod“ selbst, also die Methode, die den Algorithmus implementiert, soll nicht überschrieben werden. Sie kann (wie alle nicht-abstrakten Methoden in AbstractClass außer Hooks) final sein.
Ein Ziel bei der Entwicklung einer Template-Methode sollte sein, die Anzahl
der primitiven Operationen möglichst klein zu halten. Je mehr Operationen
überschrieben werden müssen, desto komplizierter wird die direkte Wiederverwendung von AbstractClass.
6.2 Erzeugende Entwurfsmuster
Erzeugende Entwurfsmuster beschäftigen sich mit der Erzeugung neuer Objekte auf eine Art und Weise, die weit über die Möglichkeiten der Verwendung von
new in Java hinausgeht. Entwurfsmuster sind für die Objekterzeugung deswegen
besonders interessant, weil die Objekterzeugung eng mit der Parametrisierung
verknüpft ist – siehe Abschnitt 1.3.2. Wir betrachten drei recht einfache erzeugende Entwurfsmuster: Factory-Method, Prototype und Singleton. Diese Entwurfsmuster wurden gewählt, da sie zeigen, dass die in Programmiersprachen
vorgegebenen Möglichkeiten oft mit relativ einfachen Programmiertechniken
erweiterbar sind.
6.2.1 Factory Method
Der Zweck einer Factory-Method, auch Virtual-Constructor genannt, ist die
Definition einer Schnittstelle für die Objekterzeugung, wobei Unterklassen entscheiden, von welcher Klasse die erzeugten Objekte sein sollen. Die tatsächliche
Erzeugung der Objekte wird in Unterklassen verschoben.
Als Beispiel für eine Anwendung der Factory-Method können wir uns ein
System zur Verwaltung von Dokumenten unterschiedlicher Arten (Texte, Grafiken, Videos, etc.) vorstellen. Dabei gibt es eine (abstrakte) Klasse DocCreator
mit der Aufgabe, neue Dokumente anzulegen. Nur in einer Unterklasse, der die
Art des neuen Dokuments bekannt ist, kann die Erzeugung tatsächlich durchgeführt werden. Wie in NewDocManager ist der genaue Typ des zu erzeugenden
Objekts zur Übersetzungszeit oft unbekannt, sodass ein new nicht ausreicht:
292
6.2 Erzeugende Entwurfsmuster
public interface Document { ... }
public class Text implements Document { ... }
... // classes Picture, Video, ...
public interface DocCreator {
Document create();
}
public class TextCreator implements DocCreator {
public Document create() { return new Text(); }
}
... // classes PictureCreator, VideoCreator, ...
public class NewDocManager {
private DocCreator c = ...;
public void set(DocCreator c) { this.c = c; }
public Document newDoc() { return c.create(); }
}
In diesem Beispiel ist der Typ des zu erzeugenden Objekts unter Zuhilfenahme
eines Objekts von DocCreator in einer Variablen als zentraler Ablage festgelegt. Aus Gründen der Einfachheit haben die Konstruktoren der Dokumente
hier keine Parameter. Wenn Sie welche hätten, dann könnten entsprechende
Argumente auf zahlreiche Arten festgelegt werden:
• Argumente von allgemeinem Interesse (nicht spezifisch für bestimmte Dokumente) können an newDoc übergeben und über create an den (nicht
näher bekannten) Konstruktor weitergeleitet werden.
• Wir können Argumente an zentraler Stelle ablegen. Eine Variable wie c
in NewDocManager eignet sich dafür nur für Argumente von allgemeinem
Interesse, die über create an den (nicht näher bekannten) Konstruktor
weitergeleitet werden können. Argumente, die nur für bestimmte Dokumente sinnvoll sind, können wir direkt in Objekten der entsprechenden
Untertypen von DocCreator ablegen.
• Am einfachsten ist es, für bestimmte Dokumente spezifische, aber unveränderliche Argumente fix in die Methode create einzucodieren.
Generell ist das Entwurfsmuster anwendbar wenn
• eine Klasse Objekte erzeugen soll, deren Klasse aber nicht kennt;
• eine Klasse möchte, dass ihre Unterklassen die Art der Objekte bestimmen, welche die Klasse erzeugt;
• Klassen Verantwortlichkeiten an eine von mehreren Unterklassen delegieren und das Wissen, an welche Unterklasse delegiert wird, lokal gehalten
werden soll;
• die Allokation und Freigabe von Objekten zentral in einer Klasse verwaltet
werden soll.
293
6 Entwurfsmuster und Entscheidungshilfen
Das Entwurfsmuster hat folgende Struktur:
ConcreteProduct
✁
✁
❆
❆
Product
ConcreteCreator
factoryMethod()
✁
✁
❆
❆
factoryMethod()
anOperation()
Creator
✛
Die (oft abstrakte) Klasse Product ist (wie Document im Beispiel) ein gemeinsamer Obertyp aller Objekte, die von der Factory-Method erzeugt werden können.
Die Klasse „ConcreteProduct“ ist eine bestimmte Unterklasse davon, beispielsweise Text. Die abstrakte Klasse Creator enthält neben anderen Operationen
die factoryMethod als (meist abstrakte) Methode. Diese Methode kann von außen, aber auch beispielsweise in „anOperation“ von der Klasse selbst verwendet
werden. Eine Unterklasse „ConcreteCreator“ implementiert die factoryMethod.
Ausführungen dieser Methode erzeugen neue Objekte von „ConcreteProduct“.
Factory-Methods haben unter anderem folgende Eigenschaften:
• Sie bieten (durch abstrakte Methoden oder Hooks) Anknüpfungspunkte
für Unterklassen, indem sie genau vorgeben, welche Methoden für das
Überschreiben vorgesehen sind – siehe Abschnitt 6.1.4. Das führt zu einer
Umkehrung der Abhängigkeiten: Oberklassen hängen von Unterklassen
ab, nicht (nur) Unterklassen von Oberklassen (Hollywood-Prinzip). Die
Erzeugung eines neuen Objekts mittels Factory-Method ist fast immer
flexibler als die direkte Objekterzeugung. Vor allem wird die Entwicklung
von Unterklassen vereinfacht.
• Sie verknüpfen parallele Typhierarchien, die Creator-Hierarchie mit der
Product-Hierarchie. Z. B. ist die Typstruktur bestehend aus Document,
Text und so weiter äquivalent zu der, die von den Typen DocCreator,
TextCreator und so weiter gebildet wird – für jedes „ConcreteProduct“
ein „ConcreteCreator“ und umgekehrt. Dies kann unter anderem bei kovarianten Problemen hilfreich sein. Beispielsweise erzeugt eine Methode
generateFood in der Klasse Animal nicht direkt Futter einer bestimmten
Art, sondern liefert in der Unterklasse Cow ein neues Objekt von Grass
und in Tiger eines von Meat zurück. Meist sind parallele Klassenhierarchien (wegen der vielen Klassen) aber unerwünscht.
Zur Implementierung dieses Entwurfsmusters können wir die factoryMethod
in Creator entweder als abstrakte Methode realisieren, oder als Default eine
294
6.2 Erzeugende Entwurfsmuster
Implementierung dafür vorgeben (das ist ein Hook). Im ersten Fall muss Creator
keine Klasse kennen, die als „ConcreteProduct“ verwendbar ist, dafür sind alle
konkreten Unterklassen gezwungen, die factoryMethod zu implementieren. Im
zweiten Fall kann Creator selbst zu einer konkreten Klasse werden, gibt aber
Unterklassen die Möglichkeit, die factoryMethod zu überschreiben.
Es ist oft sinnvoll, der factoryMethod Parameter mitzugeben, die bestimmen,
welche Art von Produkt zu erzeugen ist. In diesem Fall bietet die Möglichkeit
des Überschreibens mehr Flexibilität, ist aber keine unabdingbare Voraussetzung. In Java bietet es sich an, der factoryMethod ein Lambda als Parameter
zu übergeben, das die eigentliche Objekterzeugung übernimmt. Dadurch ergibt
sich eine deutliche Vereinfachung. Im Grunde ändert die Verwendung von Lambdas nicht viel an der Struktur der Factory-Method: Jedes Lambda entspricht
einer anonymen inneren Klasse als „ConcreteCreator“ und das für das Lambda
verwendete funktionale Interface dem Creator, die factoryMethod selbst kann
irgendwo stehen. Nur der Schreibaufwand wird erheblich verringert.
Hier ist eine Anwendung einer Factory-Method mit Lazy-Initialization:
public abstract class Creator {
private Product product = null;
protected abstract Product createProduct();
public Product getProduct() {
if (product == null)
product = createProduct();
return product;
}
}
Ein neues Objekt wird nur einmal erzeugt. Die Methode getProduct gibt bei
jedem Aufruf dasselbe Objekt zurück.
Ein Nachteil des Entwurfsmusters besteht in der Notwendigkeit, viele Unterklassen von Creator zu erzeugen, die nur new mit einem bestimmten „ConcreteProduct“ aufrufen. Die Erstellung dieser Klassen ist lästig. Mit Lambdas lässt
sich zumindest der Schreibaufwand reduzieren.
6.2.2 Prototype
Das Entwurfsmuster Prototype dient dazu, die Art eines neu zu erzeugenden
Objekts durch ein Prototyp-Objekt zu spezifizieren. Neue Objekte werden durch
Kopieren dieses Prototyps erzeugt.
Zum Beispiel können wir in einem System, in dem verschiedene Arten von
Polygonen wie Dreiecke und Rechtecke vorkommen, ein neues Polygon durch
Kopieren eines bestehenden Polygons erzeugen. Das neue Polygon hat dieselbe Klasse wie das Polygon, von dem die Kopie erstellt wurde. An der Stelle
im Programm, an der der Kopiervorgang aufgerufen wird (etwa in einem Zeichenprogramm), muss diese Klasse nicht bekannt sein. Das neue Polygon kann,
vielleicht durch Ändern seiner Größe oder Position, einen vom kopierten Polygon verschiedenen Zustand erhalten:
295
6 Entwurfsmuster und Entscheidungshilfen
public Polygon duplicate(Polygon orig) {
Polygon copy = orig.clone();
copy.move(X_OFFSET, Y_OFFSET);
return copy;
}
Generell ist dieses Entwurfsmuster anwendbar, wenn ein System unabhängig
davon sein soll, wie seine Produkte erzeugt, zusammengesetzt und dargestellt
werden, und wenn
• die Klassen, von denen Objekte erzeugt werden sollen, erst zur Laufzeit
bekannt sind, oder
• vermieden werden soll, eine Hierarchie von Creator-Klassen zusammen
mit einer parallelen Hierarchie von Product-Klassen zu erzeugen (also
Factory-Method vermieden werden soll), oder
• jedes Objekt einer Klasse nur wenige unterschiedliche Zustände haben
kann; es ist oft einfacher, für jeden möglichen Zustand einen Prototyp
zu erzeugen und diese Prototypen zu kopieren, als Objekte durch new zu
erzeugen und dabei passende Zustände anzugeben.
Das Entwurfsmuster hat folgende Struktur. Ein durchgezogener Pfeil bedeutet, dass jedes Objekt der Klasse, von der der Pfeil ausgeht, auf ein Objekt der
Klasse, auf die der Pfeil zeigt, verweist. Die entsprechende Variable hat den
Namen, mit dem der Pfeil bezeichnet ist.
Client
operation()
Prototype
clone()
ConcretePrototype1
clone()
ConcretePrototype2
clone()
✁
✁
❆
❆
prototype ✲
Die (möglicherweise abstrakte) Klasse Prototype spezifiziert (wie Polygon im
Beispiel) eine (möglicherweise abstrakte) Methode clone, um sich selbst zu kopieren. Die konkreten Unterklassen (wie Dreieck und Rechteck) überschreiben diese Methode. Die Klasse „Client“ entspricht im Beispiel dem Zeichenprogramm mit der Methode duplicate. Zur Erzeugung eines neuen Objekts
wird clone in Prototype oder durch dynamisches Binden in einem Untertyp von
Prototype aufgerufen.
Prototypen haben unter anderem folgende Eigenschaften:
296
6.2 Erzeugende Entwurfsmuster
• Sie verstecken die konkreten Produktklassen vor den Anwendern („Client“) und reduzieren damit die Anzahl der Klassen, die Anwender kennen
müssen. Die Anwender müssen nicht geändert werden, wenn neue Produktklassen dazukommen oder geändert werden.
• Prototypen können auch zur Laufzeit jederzeit dazugegeben und weggenommen werden. Im Gegensatz dazu darf die Klassenstruktur zur Laufzeit
in der Regel nicht verändert werden.
• Sie erlauben die Spezifikation neuer Objekte durch änderbare Werte. In
hochdynamischen Systemen kann neues Verhalten durch Objektkomposition (das Zusammensetzen neuer Objekte aus mehreren bestehenden Objekten) statt durch die Definition neuer Klassen erzeugt werden, beispielsweise durch die Spezifikation von Werten in Objektvariablen. Verweise auf
andere Objekte in Variablen ersetzen dabei Vererbung. Die Erzeugung einer Kopie eines Objekts ähnelt der Erzeugung einer Klasseninstanz. Der
Zustand eines Prototyps kann sich (wie der jedes beliebigen Objekts) jederzeit ändern, während Klassen zur Laufzeit unveränderlich sind.
• Sie vermeiden eine übertrieben große Anzahl an Unterklassen. Im Gegensatz zur Factory-Method ist es nicht nötig, parallele Klassenhierarchien
zu erzeugen.
• Sie erlauben die dynamische Konfiguration von Programmen. In Programmiersprachen wie C++ ist es nicht möglich, Klassen dynamisch zu laden.
Prototypes erlauben ähnliches auch in diesen Sprachen.
Für dieses Entwurfsmuster ist es notwendig, dass jede konkrete Unterklasse
von Prototype die Methode clone implementiert. Gerade das ist aber oft schwierig, vor allem, wenn Klassen aus Klassenbibliotheken Verwendung finden, oder
wenn es zyklische Referenzen gibt.
Um die Verwendung dieses Entwurfsmusters zu fördern, haben die Entwickler
von Java die Methode clone bereits in Object vordefiniert. Damit ist clone
in jeder Java-Klasse vorhanden und kann überschrieben werden. Die DefaultImplementierung in Object erzeugt flache Kopien von Objekten, das heißt, der
Wert jeder Variable in der Kopie ist identisch mit dem Wert der entsprechenden
Variable im kopierten Objekt. Wenn die Werte von Variablen nicht identisch
sondern nur gleich sein sollen, muss clone für jede Variable aufgerufen werden. Zur Erzeugung solcher tiefer Kopien muss die Default-Implementierung
überschrieben werden. Um unerwünschte Kopien von Objekten in Java zu vermeiden, gibt die Default-Implementierung von clone nur dann eine Kopie des
Objekts zurück, wenn die Klasse des Objekts das Interface Cloneable implementiert. Andernfalls löst clone eine Ausnahme aus.
Eine Implementierung von clone zur Erzeugung tiefer Kopien kann sehr
komplex sein. Das Hauptproblem stellen zyklische Referenzen dar. Wenn clone
einfach nur naiv rekursiv auf zyklische Strukturen angewandt wird, ergibt sich
eine Endlosrekursion, die zum Programmabbruch aus Speichermangel führt.
297
6 Entwurfsmuster und Entscheidungshilfen
Dieses Problem ist lösbar, indem wir eine Liste bereits kopierter Objekte mitführen und abbrechen, wenn wir auf ein schon kopiertes Objekt treffen. Das
Mitführen einer Liste erfordert einen Parameter der Methode, weshalb die vorimplementierte parameterlose Methode clone() dafür nicht geeignet ist. Ähnliche Probleme ergeben sich, wenn Objekte ausgegeben und wieder eingelesen
werden sollen. Das vordefinierte Interface Serializable in Java hilft bei der
Erstellung entsprechender Umformungen.
Es ist schwer, den Überblick über ein System zu behalten, das viele Prototypen enthält. Das gilt vor allem für Prototypen, die zur Laufzeit dazukommen.
Zur Lösung dieses Problems haben sich Prototyp-Manager bewährt, das sind
assoziative Datenstrukturen (kleine Datenbanken), in denen nach geeigneten
Prototypen gesucht wird.
Oft ist es notwendig, nach Erzeugung einer Kopie den Objektzustand zu
verändern. Im Gegensatz zu Konstruktoren kann „clone“ auf Grund des Ersetzbarkeitsprinzips meist nicht mit passenden Argumenten aufgerufen werden.
In diesen Fällen ist es nötig, dass die Klassen Methoden zur Initialisierung
beziehungsweise zum Ändern des Zustands bereitstellen.
Prototype ist als Entwurfsmuster vor allem in eher statisch typisierten Sprachen wie C++ und Java sinnvoll. In dynamisch typisierten Sprachen wie Smalltalk und Python wird ähnliche Funktionalität bereits direkt von der Sprache
unterstützt. Es gibt sehr dynamische objektorientierte Sprachen, die kein Klassenkonzept bereitstellen und in denen neue Objekte ausschließlich durch Kopieren bestehender Objekte eingeführt werden, etwa die Sprache Self [34]. Diese
Sprache wurde und wird zwar praktisch gar nicht verwendet, hatte aber großen
Einfluss auf die Entwicklung aktueller Sprachen.
6.2.3 Singleton
Das Entwurfsmuster Singleton sichert zu, dass eine Klasse nur eine Instanz hat
und erlaubt globalen Zugriff auf dieses Objekt.
Wir können uns zahlreiche Anwendungsmöglichkeiten vorstellen. Beispielsweise soll in einem System nur ein Drucker-Spooler existieren. Eine einfache
Lösung besteht in der Verwendung einer globalen Variable. Aber globale Variablen verhindern nicht, dass mehrere Objekte der Klasse erzeugt werden. Wir
können die Klasse selbst für die Verwaltung ihres einzigen Objekts verantwortlich machen. Das ist die Aufgabe des Singleton-Patterns.
Dieses Entwurfsmuster ist anwendbar wenn
• es genau ein Objekt einer Klasse geben soll und dieses global zugreifbar
sein soll;
• die Klasse durch Vererbung erweiterbar sein soll und Anwender die erweiterte Klasse ohne Änderungen verwenden können sollen.
Auf Grund der scheinbaren Einfachheit dieses Entwurfsmusters verzichten wir
auf eine grafische Darstellung. Ein Singleton besteht nur aus einer gleichnamigen Klasse mit einer statischen Methode instance, die das einzige Objekt der
298
6.2 Erzeugende Entwurfsmuster
Klasse zurückgibt. Obwohl die Erklärung so einfach ist, sind einige Probleme
bei der Implementation kaum zu lösen, weswegen heute oft von der Verwendung dieses Entwurfsmusters abgeraten wird. Konkret wird in abgewandelten
Varianten häufig auf die Unterstützung von Vererbung verzichtet.
Singleton im ursprünglichen Sinn hat unter anderem folgende Eigenschaften:
• Der Zugriff auf das einzige Objekt kann kontrolliert werden.
• Durch Verzicht auf globale Variablen werden unnötige Namen und weitere
unangenehme Eigenschaften globaler Variablen vermieden.
• Vererbung wird unterstützt (jedoch nicht in abgewandelten Varianten).
• Es wird verhindert, dass irgendwo Instanzen außerhalb der Kontrolle der
Klasse erzeugt werden. Konstruktoren sind in der Regel nicht public.
• Prinzipiell sind auch mehrere Instanzen erzeugbar. Wir können die Entscheidung zugunsten nur eines Objekts im System jederzeit ändern und
auch die Erzeugung mehrerer Objekte ermöglichen. Die Klasse hat weiterhin vollständige Kontrolle darüber, wie viele Objekte erzeugt werden.
• Auf das von instance zurückgegebene (nur einmal existierende) Objekt
kann über Objektmethoden durch dynamisches Binden flexibler zugegriffen werden als wenn statt diesem Objekt eine Klasse mit statischen Methoden verwendet worden wäre.
Einfache Implementierungen dieses Entwurfsmusters bereiten keine Schwierigkeiten, wie folgendes Beispiel mit Initialisierung beim ersten Zugriff zeigt:
public class Singleton {
private static Singleton singleton = null;
private Singleton() {} // no object creation from outside
public static Singleton instance() {
if (singleton == null)
singleton = new Singleton();
return singleton;
}
}
Der leere private Konstruktor hat ausschließlich den Zweck zu verhindern,
dass automatisch ein leerer public Konstruktor eingeführt wird.
Häufig ist es sinnvoll, mehrere Implementierungen eines Singletons (nur im
ursprünglichen Sinn) zur Verfügung zu stellen. Das heißt, die Klasse Singleton
hat Unterklassen. Beispielsweise gibt es mehrere Implementierungen für DruckerSpooler, im System darf trotzdem immer nur ein Drucker-Spooler aktiv sein.
Im Programm kann eine der Alternativen gewählt werden.
Überraschenderweise ist die Implementierung eines solchen Singletons recht
schwierig. Die folgende Lösung, bei der nur der erste Aufruf von instance die
zu verwendende Alternative wählt, ist noch am einfachsten, wenn auch wegen
der unflexibel vorgegebenen Fallunterscheidung nicht zufriedenstellend:
299
6 Entwurfsmuster und Entscheidungshilfen
public class Singleton {
private static Singleton singleton = null;
private Singleton() { ... }
public static Singleton instance(int kind) {
if (singleton == null)
switch (kind) {
case 1: singleton = new SingletonA(); break
case 2: singleton = new SingletonB(); break
default: singleton = new Singleton();
}
return singleton;
}
}
public class SingletonA extends Singleton {
private SingletonA() { ... }
}
public class SingletonB extends Singleton {
private SingletonB() { ... }
}
Nach Erzeugung des Objekts hat kind keinerlei Bedeutung mehr, wodurch ein
Aufrufer ein Objekt einer anderen Art zurückbekommen kann, als im Parameter
angegeben. Würden wir das Objekt in der Klassenvariable singleton durch ein
neues Objekt ersetzen, hätte ein früherer Aufrufer von instance ein anderes
Objekt erhalten; das wäre kein Singleton.
Um die feste Verdrahtung der Alternativen in Singleton zu vermeiden, können wir instance in den Untertypen implementieren:
public class Singleton {
protected static Singleton singleton = null;
private Singleton() { ... }
public static Singleton instance() {
if(singleton==null) singleton = new Singleton();
return singleton;
}
}
public class SingletonA extends Singleton {
private SingletonA() { ... }
public static Singleton instance() {
if(singleton==null) singleton = new SingletonA();
return singleton;
}
}
Die gewünschte Alternative ist wählbar, indem der erste Aufruf von instance in
der entsprechenden Klasse durchgeführt wird. Alle weiteren Aufrufe geben stets
das im ersten Aufruf erzeugte Objekt zurück. Jetzt ist nicht mehr die Klasse
300
6.3 Entwurfsmuster für Struktur
Singleton alleine für die Existenz nur eines Objekts verantwortlich, sondern
alle Unterklassen müssen mitspielen und instance passend implementieren.
Es gibt einige weitere Lösungen für dieses Problem, die aber alle ihre eigenen Nachteile haben. Daher wird Singleton heute kaum mehr in dieser Form
eingesetzt. Stattdessen werden entsprechende Aufgaben meist ohne Untertypen
gelöst, also das einzige Objekt einer Klasse über eine globale Variable bereitgestellt, in Java über eine Konstante (das ist eine static final Variable).
Beispiele dazu haben wir etwa in Abschnitt 5.2.1 gesehen.
6.3 Entwurfsmuster für Struktur
Wir betrachten Decorator und Proxy als zwei einfache Vertreter häufig gebrauchter struktureller Entwurfsmuster, also solche, die die Programmstruktur
beeinflussen. Diese Muster können ähnlich aufgebaut sein, unterscheiden sich
aber in ihrer Verwendung und ihren Eigenschaften.
6.3.1 Decorator
Das Entwurfsmuster Decorator, auch Wrapper genannt, gibt Objekten dynamisch zusätzliche Verantwortlichkeiten (siehe Abschnitt 2.2.3). Decorators stellen eine flexible Alternative zur Vererbung bereit.
Manchmal möchten wir einzelnen Objekten zusätzliche Verantwortlichkeiten
geben, nicht aber der ganzen Klasse. Zum Beispiel möchten wir einem Fenster
am Bildschirm Bestandteile wie einen Scroll-Bar geben, anderen Fenstern aber
nicht. Es ist sogar üblich, dass der Scroll-Bar dynamisch während der Verwendung eines Fensters nach Bedarf dazukommt und wieder weggenommen wird:
public interface Window {
void show(String text);
}
public class WindowImpl implements Window {
public void show(String text) { ... }
}
public abstract class WinDecorator implements Window {
protected Window win;
public void show(String text) { win.show(text); }
}
public class ScrollBar extends WinDecorator {
public ScrollBar(Window w) { win = w; }
public void scroll(int lines) { ... }
public Window noScrollBar() {
Window w = win;
win = null; // no longer usable
return w;
}
}
301
6 Entwurfsmuster und Entscheidungshilfen
Window w = new WindowImpl(); // no scroll bar
ScrollBar s = new ScrollBar(w); // add scroll bar
w = s; // s aware of scroll bar, w not
w.show("Text"); // no matter if scroll bar or not
s.scroll(3); // works only with scroll bar
w = s.noScrollBar(); // remove scroll bar
Im Allgemeinen ist dieses Entwurfsmuster anwendbar
• um dynamisch Verantwortlichkeiten zu einzelnen Objekten hinzuzufügen,
ohne andere Objekte dadurch zu beeinflussen;
• für Verantwortlichkeiten, die wieder entzogen werden können;
• wenn Erweiterungen einer Klasse durch Vererbung unpraktisch sind, beispielsweise um eine sehr große Zahl an Unterklassen zu vermeiden, oder
weil die Programmiersprache oder ein Programm in einem speziellen Fall
keine Vererbung unterstützt (etwa bei final Klassen).
Das Entwurfsmuster hat folgende Struktur, wobei der Pfeil mit einem Kästchen für Aggregation steht (eine Referenz auf ein Objekt, dessen Bestandteil
das die Referenz enthaltende Objekt ist).
ConcreteComponent
operation()
Decorator
operation()
Component
operation()
ConcreteDecoratorA
operation()
addedState
ConcreteDecoratorB
operation()
addedBehavior()
✁
✁
❆
❆
✁
✁
❆
❆
✟❍
❍✟
component
✛
Die abstrakte Klasse bzw. das Interface Component (entspricht Window) definiert eine Schnittstelle für Objekte, an die Verantwortlichkeiten dynamisch
hinzugefügt werden können. Die Klasse „ConcreteComponent“ ist, wie beispielsweise WindowImpl, eine konkrete Unterklasse davon. Die (abstrakte) Klasse Decorator (WinDecorator im Beispiel) definiert eine Schnittstelle für Verantwortlichkeiten, die dynamisch zu Komponenten hinzugefügt werden können. Jedes
302
6.3 Entwurfsmuster für Struktur
Objekt dieses Typs enthält eine Referenz namens „component“ (bzw. win im
Beispiel) auf ein Objekt des Typs Component, das ist das Objekt, zu dem die
Verantwortlichkeit hinzugefügt ist. Unterklassen von Decorator sind konkrete
Klassen, die bestimmte Funktionalität wie beispielsweise Scroll-Bars bereitstellen. Sie definieren neben den Methoden, die bereits in Component definiert sind,
weitere Methoden und Variablen, welche die zusätzliche Funktionalität verfügbar machen. Wird eine Methode, die in Component definiert ist, aufgerufen, so
wird dieser Aufruf einfach an das Objekt, das über „component“ referenziert
ist, weitergegeben.
Decorators haben folgende Eigenschaften:
• Sie bieten mehr Flexibilität als statische Vererbung. Wie bei statischer
Erweiterung einer Klasse durch Vererbung werden Verantwortlichkeiten
hinzugefügt. Anders als bei Vererbung erfolgt das Hinzufügen der Verantwortlichkeiten zur Laufzeit und zu einzelnen Objekten, nicht ganzen
Klassen. Die Verantwortlichkeiten können auch jederzeit wieder weggenommen werden.
• Sie vermeiden Klassen, die bereits weit oben in der Typhierarchie mit Methoden und Variablen überladen sind. Es ist nicht notwendig, dass „ConcreteComponent“ die volle gewünschte Funktionalität enthält, da durch
das Hinzufügen von Dekoratoren gezielt neue Funktionalität verfügbar
gemacht werden kann.
• Objekte von Decorator und die dazugehörenden Objekte von „ConcreteComponent“ sind nicht identisch. Beispielsweise hat ein Fenster-Objekt,
auf das über einen Dekorator zugegriffen wird, eine andere Identität als
das Fenster-Objekt selbst (ohne Dekorator) oder dasselbe Fenster-Objekt,
auf das über einen anderen Dekorator zugegriffen wird. Bei Verwendung
dieses Entwurfsmusters sollen wir uns nicht auf Objektidentität verlassen.
• Sie führen zu vielen kleinen Objekten. Ein Design, das Dekoratoren häufig verwendet, führt nicht selten zu einem System, in dem es viele kleine
Objekte gibt, die einander ähneln. Solche Systeme sind zwar einfach konfigurierbar, aber schwer zu verstehen und zu warten.
Wenn es nur eine Dekorator-Klasse gibt, kann die abstrakte Klasse Decorator
weglassen und statt dessen die konkrete Klasse verwendet werden. Bei mehreren Dekorator-Klassen zahlt sich die abstrakte Klasse aus: Alle Methoden, die
bereits in Component definiert sind, müssen in den Dekorator-Klassen auf gleiche Weise überschrieben werden. Sie rufen einfach dieselbe Methode in „component“ auf. Man muss diese Methoden nur einmal in der abstrakten Klasse
überschreiben. Von den konkreten Klassen werden sie geerbt.
Die Klasse oder das Interface „Component“ soll so klein wie möglich gehalten
werden. Dies kann dadurch erreicht werden, dass „Component“ wirklich nur die
notwendigen Operationen, aber keine Daten definiert. Daten und Implementierungsdetails sollen erst in „ConcreteComponent“ vorkommen. Andernfalls
werden Dekoratoren umfangreich und ineffizient.
303
6 Entwurfsmuster und Entscheidungshilfen
Dekoratoren eignen sich gut dazu, die Oberfläche beziehungsweise das Erscheinungsbild eines Objekts zu erweitern. Sie sind nicht gut für inhaltliche Erweiterungen geeignet. Auch für Objekte, die von Grund auf umfangreich sind,
eignen sich Dekoratoren kaum. Für solche Objekte sind andere Entwurfsmuster, beispielsweise Strategy, besser geeignet. Auf diese Entwurfsmuster wollen
wir hier aber nicht eingehen.
6.3.2 Proxy
Ein Proxy, auch Surrogate genannt, stellt einen Platzhalter für ein anderes
Objekt dar und kontrolliert Zugriffe darauf.
Es gibt zahlreiche, sehr unterschiedliche Anwendungsmöglichkeiten für Platzhalterobjekte. Ein Beispiel ist ein Objekt, dessen Erzeugung teuer ist, weil umfangreiche Daten geladen werden. Wir erzeugen das eigentliche Objekt erst,
wenn es wirklich gebraucht wird. Stattdessen verwenden wir in der Zwischenzeit einen Platzhalter, der erst bei Bedarf durch das eigentliche Objekt ersetzt
wird. Falls nie auf die Daten zugegriffen wird, ersparen wir uns den Aufwand
der Objekterzeugung:
public interface Something {
void doSomething();
}
public class ExpensiveSomething implements Something {
public void doSomething() { ... }
}
public class VirtualSomething implements Something {
private ExpensiveSomething real = null;
public void doSomething() {
if (real == null)
real = new ExpensiveSomething();
real.doSomething();
}
}
Jedes Platzhalterobjekt enthält einen Zeiger auf das eigentliche Objekt (sofern
dieses existiert) und leitet in der Regel Nachrichten an das eigentliche Objekt
weiter, möglicherweise nachdem weitere Aktionen gesetzt wurden. Einige Nachrichten werden manchmal auch direkt vom Proxy behandelt.
Das Entwurfsmuster ist anwendbar, wenn eine intelligentere Referenz auf ein
Objekt als ein simpler Zeiger nötig ist. Hier sind einige übliche Situationen, in
denen ein Proxy eingesetzt werden kann (keine vollständige Aufzählung):
Remote-Proxies sind Platzhalter für Objekte, die in anderen Namensräumen
(zum Beispiel auf Festplatten oder auf anderen Rechnern) existieren.
Nachrichten an die Objekte werden von den Proxies über komplexere
Kommunikationskanäle weitergeleitet.
304
6.3 Entwurfsmuster für Struktur
Virtual-Proxies erzeugen Objekte bei Bedarf, wie in obigem Beispiel. Da die
Erzeugung eines Objekts aufwendig sein kann, wird sie so lange hinausgezögert, bis es wirklich einen Bedarf dafür gibt.
Protection-Proxies kontrollieren Zugriffe auf Objekte. Derartige Proxies sind
sinnvoll, wenn Objekte je nach Zugreifer oder Situation unterschiedliche
Zugriffsrechte haben sollen.
Smart-References ersetzen einfache Zeiger. Sie können bei Zugriffen zusätzliche Aktionen ausführen. Typische Verwendungen sind
• das Mitzählen der Referenzen auf das eigentliche Objekt, damit das
Objekt entfernt werden kann, wenn es keine Referenz mehr darauf
gibt (Reference-Counting);
• das Laden von persistenten Objekten in den Speicher, wenn das erste
Mal darauf zugegriffen wird (wobei die Unterscheidung zu VirtualProxies manchmal unklar ist);
• das Zusichern, dass während des Zugriffs auf das Objekt kein gleichzeitiger Zugriff durch einen anderen Thread erfolgt (beispielsweise
durch Setzen eines „Locks“).
Es gibt zahlreiche weitere Einsatzmöglichkeiten. Der Phantasie sind hier kaum
Grenzen gesetzt.
Die Struktur dieses Entwurfsmusters ist recht einfach:
RealSubject
request()
Proxy
request()
Subject
request()
✁
✁
❆
❆
✛ realSubject
Die abstrakte Klasse oder das Interface Subject ist eine gemeinsame Schnittstelle für Objekte von „RealSubject“ und „Proxy“. Objekte von „RealSubject“
und „Proxy“ können gleichermaßen verwendet werden, wo ein Objekt von Subject erwartet wird. Die Klasse „RealSubject“ definiert die eigentlichen Objekte,
die durch die Proxies (Platzhalter) repräsentiert werden. Die Klasse „Proxy“
definiert schließlich die Proxies. Diese Klasse
• verwaltet eine Referenz „realSubject“, über die ein Proxy auf Objekte von
„RealSubject“ (oder auch andere Objekte von Subject) zugreifen kann;
• stellt eine Schnittstelle bereit, die der von Subject entspricht, damit ein
Proxy als Ersatz des eigentlichen Objekts verwendet werden kann;
305
6 Entwurfsmuster und Entscheidungshilfen
• kontrolliert Zugriffe auf das eigentliche Objekt und kann für dessen Erzeugung oder Entfernung verantwortlich sein;
• hat weitere Verantwortlichkeiten, die von der Art abhängen.
Es kann mehrere unterschiedliche Klassen für Proxies geben. Zugriffe auf Objekte von „RealSubject“ können durch mehrere Proxies (möglicherweise unterschiedlicher Typen) kontrolliert werden, die in Form einer Kette bzw. Liste
miteinander verbunden sind.
In obiger Grafik zur Struktur des Entwurfsmusters zeigt ein Pfeil von „Proxy“
auf „RealSubject“. Das bedeutet, „Proxy“ muss „RealSubject“ kennen. Dies ist
z. B. notwendig, wenn ein Proxy Objekte von „RealSubject“ erzeugen soll. In
anderen Fällen reicht es, wenn „Proxy“ nur Subject kennt, der Pfeil also auf
Subject zeigt.
In der Implementierung müssen wir beachten, wie ein Objekt referenziert
wird, das in einem anderen Namensraum liegt oder noch gar nicht existiert.
Für nicht existierende Objekte könnten wir zum Beispiel null verwenden und
für Objekte in einer Datei den Dateinamen.
Ein Proxy kann die gleiche Struktur wie ein Decorator haben. Aber Proxies
dienen einem ganz anderen Zweck als Decorators: Ein Decorator erweitert ein
Objekt um zusätzliche Verantwortlichkeiten, während ein Proxy den Zugriff
auf das Objekt kontrolliert. Damit haben diese Entwurfsmuster auch gänzlich
unterschiedliche Eigenschaften.
6.4 Entscheidungshilfen
Schon zu Beginn dieses Kapitels haben wir festgehalten, dass Entwurfsmuster
nicht als Regeln missverstanden werden dürfen, an die wir uns halten müssen
oder sollten. Sie sind keine Regeln, zumindest nicht in dem Sinn, wie wir in
vielen Teilen des Skriptums Faustregeln gesehen haben. Trotzdem helfen sie uns,
Entscheidungen zu treffen. Zunächst betrachten wir, wie wir Entscheidungen
auf der Basis von Entwurfsmustern treffen können. Danach beschäftigen wir
uns ganz allgemein damit, wie die Einhaltung von Richtlinien oder Faustregeln
in der Programmierung zu verstehen ist.
6.4.1 Entwurfsmuster als Entscheidungshilfen
Seit der Entwicklung der Software-Entwurfsmuster sind schon einige Jahrzehnte
vergangen, wobei die Idee der Entwurfsmuster aus dem Bereich der Architektur (Bauwesen, nicht Computer-Architektur) stammt und wesentlich älter ist.
Der Begriff Software-Entwurfsmuster hatte in der Informatik von Anfang an
einen positiven Beigeschmack, was dazu führte, dass er für Unterschiedliches
eingesetzt wurde. Im Wesentlichen lassen sich zwei Sichtweisen unterscheiden:
Wertend: Als Entwurfsmuster werden nur solche abstrakte Konzepte bezeichnet, die überwiegend positive Eigenschaften in ein Programm bringen.
306
6.4 Entscheidungshilfen
Dementsprechend wird es als vorteilhaft angesehen, möglichst viele Entwurfsmuster in einem Programm vorzufinden. Natürlich ist nicht jedes
Konzept gut. Zur Unterscheidung der schlechten von den guten Konzepten wurde der Begriff Anti-Pattern eingeführt. Wir wollen im Programm
möglichst wenige Anti-Pattern finden.
Nicht wertend: Entwurfsmuster sind für sich (also außerhalb des Kontexts eines bestimmten Programms) weder gut noch schlecht. Es handelt sich
nur um eine benannte Beschreibung eines Problems, eines Lösungsansatzes und von Konsequenzen, die daraus folgen. Fast jedes Entwurfsmuster
wird sowohl erwünschte als auch unerwünschte Konsequenzen haben. Ob
der Einsatz eines Entwurfsmusters insgesamt als vorteilhaft angesehen
wird oder nicht, hängt vor allem von den Gewichtungen ab, die wir den
Konsequenzen in einer bestimmten Anwendung beimessen. Begriffe wie
Anti-Pattern ergeben kaum Sinn, abgesehen vielleicht für die ganz wenigen Muster, die eindeutig nur negative Eigenschaften haben.
Es wird selten klar gesagt, ob der Begriff Entwurfsmuster wertend oder nicht
wertend gebraucht wird. Meist steht eine der beiden Sichtweisen im Vordergrund, aber die andere schwingt auch mit. Wenn wir ein Entwurfsmuster betrachten, besonders wenn es sich um eine Kurzbeschreibung auf einer Webseite
handelt, müssen wir darauf achten, welche Sichtweise wahrscheinlich dahinter
steckt. Viele Leute bevorzugen kurze Beschreibungen mit möglichst einfachen
Aussagen dazu, ob ein Muster verwendet werden soll oder nicht. Deswegen finden Suchmaschinen häufig vereinfachte Beschreibungen, die stark wertend sind.
Oft werden nur wenige Konsequenzen als „Vorteile“ und „Nachteile“ angerissen, ohne die Frage zu stellen, welche Kriterien für die beabsichtigte Anwendung
relevant sind. Darin liegt eine Gefahr, die wir nicht unterschätzen sollten.
Aus dem Einsatz von Entwurfsmustern in der Achitektur ist bekannt, dass
Ergebnisse selten gut sind. Auf der Basis von Entwurfsmustern entwickelte Bauten sind vergleichsweise komplex und wenig ansprechend, sie wirken ideenlos.
Letzteres trifft genau den Punkt: Es steckt keine Idee dahinter, sondern nur
das mehr oder weniger willkürliche Zusammenwürfeln fertiger Muster. In der
Programmierung wurden ähnliche Erfahrungen gemacht: Aus Entwurfsmustern
zusammengesetzte Programme sind umfangreich, haben keine klare Struktur
und aus den Beschreibungen der Entwurfsmuster ableitbare Eigenschaften sind
selten wirklich gegeben. Das Wesentliche (die Idee) scheint zu fehlen.
Hinter ideenlosen Programmen kann ein falscher Ansatz im Umgang mit
Entwurfsmustern stecken. Entwurfsmuster können die Idee nicht ersetzen, sie
können nur helfen, die Idee zu beurteilen. Erst die Idee lässt die Einzelteile
(auch die Entwurfsmuster) so miteinander in Beziehung treten, dass ein in sich
konsistentes Gesamtgefüge entsteht. Mit einer guten Idee ergibt es sich nicht
selten, dass in einem kurzen, einfachen Programmstück mehrere typische Entwurfsmuster stecken, obwohl das bei der Entwicklung nicht beabsichtigt war.
Die Entwurfsmuster ergeben sich wie von selbst und sind komplex ineinander
verstrickt; ohne Idee liegen die Entwurfsmuster quasi flach nebeneinander, ohne
307
6 Entwurfsmuster und Entscheidungshilfen
sich zu überschneiden. Wenn die Entwurfsmuster sich nicht überschneiden, können wir aus Konsequenzen aus einzelnen Mustern nur wenig Rückschlüsse auf
die Qualität des gesamten Programms ziehen. Bei komplex ineinander verstrickten Entwurfsmustern sind auch die Konsequenzen eng ineinander verzahnt, wodurch die Programmqualität selbst (bzw. die Qualität der Idee) sich in den
Konsequenzen widerspiegelt. Wir müssen aufpassen, wenn wir von der Eigenschaft „komplex“ sprechen: Gerade bei einfachen Ideen und entsprechend einfachen Programmen sind Entwurfsmuster komplex ineinander verstrickt; wenn
Entwurfsmuster nicht komplex ineinander verstrickt sind, kann das Programm
im Vergleich dazu ziemlich komplex und umfangreich sein, weil viel Code nötig ist, um die unabhängigen Muster doch irgendwie miteinander zu kombinieren. Entwurfsmuster, die komplex ineinander verzahnt sind, müssen wir fast
zwangsläufig nicht wertend betrachten; das heißt, wir dürfen nicht die Anwesenheit eines Musters selbst als Qualitätsmerkmal betrachten, sondern wir müssen
die gewichteten Konsequenzen als Basis für die Beurteilung heranziehen. Ohne
Verzahnung der Muster ist es egal, ob wir sie als wertend oder nicht wertend
betrachten, weil ohnehin kaum Rückschlüsse auf die Qualität möglich sind.
Aus obigen Überlegungen folgt, wie eine erfolgreiche Herangehensweise an
den Entwurf einer Software aussehen könnte. Wir setzen voraus, dass wir den
Bedarf schon genau analysiert haben, also wissen, welche Anforderungen an die
Software gestellt werden. Jetzt brauchen wir die entscheidende Idee. Das heißt,
mit den Anforderungen im Blick müssen wir eine Organisationsform des gesamten Programms finden, die eine einheitliche gemeinsame Klammer über alle zu
entwickelnden Programmteile stülpt. Diese Klammer oder Grobstruktur muss
möglichst einfach und ganz auf die Gesamtheit der Anforderungen ausgerichtet
sein, darf also nicht einzelne Anforderungen stark überbewerten oder vergessen.
Die Gesamtheit der Anforderungen ist mehr als die Summe der Anforderungen.
Wir brauchen ein intuitives Verständnis für die gemeinsamen typischen Merkmale aller Anforderungen, die die zu entwickelnde Software von anderer Software abhebt und ihr einen eigenen Charakter verleiht. Wir können nicht allgemein
sagen, worin die Gemeinsamkeiten in den Anforderungen bestehen, weil das von
Projekt zu Projekt sehr verschieden ist. Es kann ein bestimmtes Bedienkonzept
sein, ein bestimmer Umgang mit Daten, ein bestimmter Programmierstil, was
auch immer. Hier ist Kreativität und Intuition gefragt, Intuition, die aus der
Erfahrung kommt. Damit kommen indirekt Entwurfsmuster ins Spiel, weil Entwurfsmuster uns erlauben, Erfahrungen auszutauschen und auf eine bewusste
Ebene zu ziehen. Jetzt dürfen wir aber nicht den Fehler machen, den Entwurf
bzw. die Idee auf eine zu kleine Menge an Entwurfsmustern auszurichten und
uns zu früh willkürlich auf bestimmte Muster festzulegen. Vielmehr müssen
wir uns darauf verlassen, dass wir uns durch die intensive Beschäftigung mit
Software-Entwürfen und Entwurfsmustern eine ausreichend gute Intuition angeeignet haben. Indirekt bedeutet das, dass unsere Intuition aus einer Vielzahl
von Entwurfsmustern kommt (nicht nur den wenigen, die häufig öffentlich diskutiert werden), ohne uns dessen bewusst zu sein. Mit einer guten Idee wissen
wir, wie das Projekt zu einem guten Abschluss geführt werden kann. Ohne Idee
tappen wir hilflos im Dunkeln und müssen weiter nach einer Idee suchen.
308
6.4 Entscheidungshilfen
Eine Idee ist nur ein erster Schritt. Um sicher zu gehen, werden wir mehrere alternative Ideen entwickeln und miteinander vergleichen. Erst hier kommen
Entwurfsmuster nicht nur unbewusst ins Spiel, sondern werden ganz gezielt eingesetzt. Mit einer konkreten Idee im Hinterkopf können wir erkennen, welche
uns bekannten (nicht wertenden) Entwurfsmuster in einem entsprechenden Programm stecken werden. Ebenso auf der Idee und den Anforderungen beruhend
können wir entscheiden, wie relevant bestimmte Kriterien für uns am Ende sein
werden, wir können die Konsequenzen aus den Entwurfsmustern also gewichten. Das gibt uns ein Werkzeug für die Beurteilung verschiedener Ideen. Damit
alleine ist es noch nicht getan, weil sich, wie oben beschrieben, Konsequenzen aus einzelnen Entwurfsmustern nicht immer problemlos auf die Qualität
des gesamten Programms übertragen lassen. Es gibt ein Beurteilungskriterium,
das alle anderen Kriterien überwiegt, nämlich die erwartete Gesamtkomplexität
des Programms. Eine Idee, die zu einem einfacheren Programm führt, ist fast
immer vorteilhaft, egal was eine Beurteilung auf Basis von Entwurfsmustern ergibt. Vergleiche von Ideen über Entwurfsmuster sind also in der Regel nur dann
sinnvoll, wenn die Ideen zu einigermaßen gleich geringer Komplexität führen.
Wie oben argumentiert, beruhen unsere Ideen unbewusst meist auch auf Erfahrungen, die von Entwurfsmustern kommen. Es spricht nichts dagegen, diese
unbewussten Abhängigkeiten auf eine bewusste Ebene zu ziehen. Wir wissen,
welche Anwendungen von Entwurfsmustern mit vergleichsweise hoher Wahrscheinlichkeit zu schlechter Software führen, nämlich solche, die nicht auf natürliche Weise gut in das gesamte Programm eingebunden sind, sondern über
speziellen Code aufwendig eingebunden werden müssen. Wenn uns eine solche
Situation auffällt, können wir bewusst etwas dagegen tun. Wir müssen unsere
Idee weiterentwickeln, sodass dieses Problem nicht mehr auftritt. Das heißt, wir
müssen auf das Entwurfsmuster verzichten oder einen Weg (durch Überarbeiten
der Idee) finden, wie wir es auf natürliche Weise integrieren können.
Entwurfsmuster können also sehr wohl das sein, was der Name besagt: ein
Werkzeug, um uns beim Entwurf eines Systens zu leiten. Der richtige Umgang
damit will jedoch geübt sein. Es reicht auf keinen Fall, ein Stück Software nur
durch additives Kombinieren einiger uns sinnvoll erscheinender Entwurfsmuster
zu entwerfen. Ohne zielführende Idee als gemeinsame Klammer über dem Entwurf könnte ein solches Vorgehen in einer Katastrophe enden. Ein bewusster
Umgang mit Entwurfsmustern kann helfen, eine gute Idee zu finden. Allerdings
ist es dafür nicht ausreichend, Entwurfsmuster nur oberflächlich zu kennen. Sie
müssen tief in unserem Unterbewusstsein verankert sein, bevor wir Sie wirklich
produktiv einsetzen können.
6.4.2 Richtlinien in der Entscheidungsfindung
Wir kennen eine große Zahl unterschiedlicher Regeln, Konventionen und Richtlinien, die darauf abzielen, uns beim Entwurf von Programmen zu unterstützen.
Hier ist eine (unvollständige) Zusammenstellung, jeweils mit den wichtigsten
Zielsetzungen und Konsequenzen bei Verstößen dagegen:
309
6 Entwurfsmuster und Entscheidungshilfen
• Syntax- und Semantikregeln einer Programmiersprache sind mehr oder
weniger standardisiert und sorgen dafür, dass alle dazugehörigen Werkzeuge Programme auf die gleiche Weise verstehen. Natürlich müssen auch
wir uns beim Programmieren an diese Regeln halten; eine Regelverletzung
führt meist zu einem nicht lauffähigen Programm oder schweren Fehlern
bei der Programmausführung.
• Allgemeine Konventionen wie z. B. Namenskonventionen helfen uns beim
Lesen von Programmen, können aber auch dazu dienen, die Vertrauenswürdigkeit von Programmtexten abzuschätzen. Die Nichteinhaltung der
Konventionen kann durch verminderte Lesbarkeit die Wartung erschweren und vereinzelt durch Missverständnisse zu Fehlern führen. Schwerwiegendere Folgen kann durch Nichteinhaltung entstehendes mangelndes
Vertrauen haben, das zu zusätzlichen Programmtexten für Überprüfungen
oder als Alternativen zu vorhandenen Programmtexten führen kann.
• Konventionen, die für Projekte, Firmen, Frameworks oder Bibliotheken
spezifisch sind, haben verschiedenartige Hintergründe mit unterschiedlichen Auswirkungen bei Nichteinhaltung. Einerseits sind Ziele und Auswirkungen ähnlich denen allgemeiner Konventionen, wobei neben der Lesbarkeit häufig auch die Teambildung eine Rolle spielt. Es gibt auch Konventionen, deren Einhaltung für die Funktionalität der Software entscheidend ist, deren Nichteinhaltung zu schwerwiegenden Fehlern führen kann.
Insbesondere bei Konventionen im Zusammenhang mit Annotationen, Reflexion und aspektorientierter Programmierung ist das der Fall.
• Wir haben zahlreiche Faustregeln angeführt, eine Internet-Recherche wird
uns eine schier endlose Liste an Faustregeln bescheren. Faustregeln sollen
uns helfen, bei der Wahl zwischen verschiedenen Optionen in bestimmten
Situationen jene zu finden, die am erfolgversprechendsten ist. Es gibt keinerlei Garantie, dabei die beste oder auch nur eine gute Wahl zu treffen.
Mangels ausreichender Information über die Konsequenzen einer Entscheidung zum Zeitpunkt der Entscheidungsfindung verlassen wir uns dennoch
gerne auf Faustregeln. Unter der Voraussetzung, dass Faustregeln gut gewählt sind, laufen wir Gefahr, bei Nichtbefolgung in vielen Entscheidungen deutlich mehr Fehlentscheidungen zu treffen als bei Befolgung.
• Softwareentwurfsmuster geben uns ein Werkzeug in die Hand, das es uns
erlaubt, bei der Wahl zwischen verschiedenen Optionen in bestimmten Situationen die Konsequenzen einer Entscheidung zum Zeitpunkt der Entscheidungsfindung mit einer relevanten Wahrscheinlichkeit richtig vorherzusehen. Wie Faustregeln bieten auch Softwareentwurfsmuster keine zuverlässigen Aussagen, sondern nur zufallsbehaftete Entscheidungsgrundlagen. Im Gegensatz zu Faustregeln ermöglichen Softwareentwurfsmuster
viel genauere Abschätzungen möglicher Konsequenzen und erlauben uns,
die Wichtigkeit einzelner Kriterien für die zu entwickelnde Software in die
Entscheidungsfindung einzubeziehen.
310
6.4 Entscheidungshilfen
• Eine nicht zu unterschätzende Grundlage für eine Entscheidungsfindung
ist die persönliche Expertise (bzw. die Summe gesammelter Erfahrungen).
Auf den ersten Blick ist Expertise nicht sofort als Menge von Regeln erkennbar, dennoch hängen die meisten von uns getroffenen Entscheidungen davon ab. Im Gegensatz zu Faustregeln und Softwareentwurfsmustern
können wir unsere Expertise meist nicht in ausreichender Qualität in Form
von Regeln ausformulieren. Dennoch steckt dahinter viel Wissen, das auf
Wahrscheinlichkeiten beruht. Mit ausreichend Erfahrung können wir uns
häufig auf unsere Expertise verlassen und Entscheidungen rasch und dennoch mit hoher Wahrscheinlichkeit richtig treffen, aber es werden (auch
mit sehr viel Erfahrung) immer auch einige Entscheidungen dabei sein,
die eindeutig falsch sind.
Es stellt sich die Frage, wie wir mit diesen vielen Regeln, Konventionen und
Richtlinien umgehen sollen, insbesondere dann, wenn sie sich teilweise widersprechen. Bei Syntax- und Semantikregeln, aber auch bei Konventionen, egal
ob allgemein oder spezifisch, sollte die Antwort klar sein: Wir müssen uns ganz
genau daran halten. Diese Regeln und Konventionen sind so gestaltet, dass sie
sich nicht widersprechen, sodass die Befolgung immer möglich sein sollte. Auch
wenn wir oft nicht wissen, welche Überlegung hinter einer Regel oder Konvention steckt, können wir davon ausgehen, dass sich das jemand genau überlegt
hat. Die Nichteinhaltung kann nur negative Konsequenzen nach sich ziehen,
keine positiven.
Faustregeln, Entwurfsmuster und persönliche Expertisen sind Syntax- und
Semantikregeln sowie Konventionen unterzuordnen, da sie auf Wahrscheinlichkeiten des Eintritts bestimmter Situationen beruhen, meist weit weg von Gewissheit. Dennoch sind sie wertvoll. Faustregeln und Softwareentwurfsmuster
spiegeln allgemeine Erfahrungen wider, Expteritsen persönliche Erfahrungen.
Faustreglen und Softwareentwurfsmuster müssen von uns internalisiert werden,
bevor sie als unsere persönlichen Expertisen effizient als Entscheidungsgrundlagen herangezogen werden. Faustregeln und Softwareentwurfsmuster dienen
aber auch dazu, eigene Expertisen ständig zu hinterfragen und darauf hin zu
überprüfen, wie gut sie in sich konsistent sind.
Verschiedene Faustregeln, Entwurfsmuster und persönliche Expertisen können sich gegenseitig widersprechen. Entscheidungsprozesse sind daher komplexer als das Befolgen einer großen Menge an Regeln. Letztendlich ist immer die
persönliche Expertise ausschlaggebend für eine Entscheidung.
Programmierparadigmen und persönliche Programmierstile spielen eine wesentliche Rolle. Programmierparadigmen können wir als großteils in sich konsistente Mengen an Faustregeln betrachten, persönliche Programmierstile als die
von Paradigmen beieinflussten persönlichen Expertisen. Jede Person hat aber
nur eine Menge an persönlichen Expertisen, die Summe aller Expertisen in vielen Bereichen. Trotzdem kann eine Person einmal in einem Stil (nach einem
Paradigma) programmieren, dann wieder in einem anderen. Das widerspricht
sich nicht. Die persönliche Expertise umfasst auch die Fähigkeit, zwischen unterschiedlichen Paradigmen umzuschalten. Wir sind in der Lage, zu erkennen,
311
6 Entwurfsmuster und Entscheidungshilfen
wann welches Paradigma den größten Erfolg verspricht. Das ist wesentlich mehr
als nur die Summe der Erfahrungen in einzelnen Bereichen. Die Lehrveranstaltung „Programmierparadigmen“ zielt(e) darauf ab, die persönliche Expertise
auf dem Gebiet der Programmierung so aufzubauen, dass bestimmte Paradigmen und Stile zur Lösung einer Programmieraufgabe ganz bewusst gewählt
werden können, nicht nur nach dem Zufallsprinzip.