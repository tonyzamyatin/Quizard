// TODO: Add parameters, optimize and test!
{
    "flashcards": {
        "active": true,
        "manual": false,
        "number_to_generate": 10
    },
    "tokens": {
        // For texts longer than 3k tokens text splitting is used:
        "prompt_limit": 3000,
        "window_size": 2400,
        "window_overlap": 400

        // Optimal parameters:
        // 3.000, 2.400 and 400 when using the 4k model
        // _____, 10.000 and 10.400 when using the 16k model
    },
    "model": {
        "name": "gpt-3.5-turbo",
        "temperature": 0.8,
        "max_tokens": 1000,
        "top_p": 1.0,
        "frequency_penalty": 0.0,
        "presence_penalty": 0.0
    }
}
